apiVersion: v1
items:
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      checksum/cm: 9156c689cecc9c1147df3672959659693b08b4c335adc717836ea9bc0cc75160
      checksum/cmd-params: bcbb2496303699a508a41b49a033d6f92d273aba139ec132105f461a1d84fa46
    creationTimestamp: "2024-07-19T17:25:51Z"
    generateName: argocd-application-controller-
    labels:
      app.kubernetes.io/component: application-controller
      app.kubernetes.io/instance: argocd
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: argocd-application-controller
      app.kubernetes.io/part-of: argocd
      app.kubernetes.io/version: v2.11.5
      apps.kubernetes.io/pod-index: "0"
      controller-revision-hash: argocd-application-controller-5f449f6b88
      helm.sh/chart: argo-cd-7.3.9
      statefulset.kubernetes.io/pod-name: argocd-application-controller-0
    name: argocd-application-controller-0
    namespace: argocd
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: argocd-application-controller
      uid: c144e4db-249f-4ac8-a0e9-112d85b17cc3
    resourceVersion: "17862364"
    uid: 2fbe5f6a-6384-4b87-97c2-9e9631056004
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app.kubernetes.io/name: argocd-application-controller
            topologyKey: kubernetes.io/hostname
          weight: 100
    automountServiceAccountToken: true
    containers:
    - args:
      - /usr/local/bin/argocd-application-controller
      - --metrics-port=8082
      env:
      - name: ARGOCD_CONTROLLER_REPLICAS
        value: "1"
      - name: ARGOCD_APPLICATION_CONTROLLER_NAME
        value: argocd-application-controller
      - name: ARGOCD_RECONCILIATION_TIMEOUT
        valueFrom:
          configMapKeyRef:
            key: timeout.reconciliation
            name: argocd-cm
            optional: true
      - name: ARGOCD_HARD_RECONCILIATION_TIMEOUT
        valueFrom:
          configMapKeyRef:
            key: timeout.hard.reconciliation
            name: argocd-cm
            optional: true
      - name: ARGOCD_RECONCILIATION_JITTER
        valueFrom:
          configMapKeyRef:
            key: timeout.reconciliation.jitter
            name: argocd-cm
            optional: true
      - name: ARGOCD_REPO_ERROR_GRACE_PERIOD_SECONDS
        valueFrom:
          configMapKeyRef:
            key: controller.repo.error.grace.period.seconds
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER
        valueFrom:
          configMapKeyRef:
            key: repo.server
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_TIMEOUT_SECONDS
        valueFrom:
          configMapKeyRef:
            key: controller.repo.server.timeout.seconds
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATION_CONTROLLER_STATUS_PROCESSORS
        valueFrom:
          configMapKeyRef:
            key: controller.status.processors
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATION_CONTROLLER_OPERATION_PROCESSORS
        valueFrom:
          configMapKeyRef:
            key: controller.operation.processors
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATION_CONTROLLER_LOGFORMAT
        valueFrom:
          configMapKeyRef:
            key: controller.log.format
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATION_CONTROLLER_LOGLEVEL
        valueFrom:
          configMapKeyRef:
            key: controller.log.level
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATION_CONTROLLER_METRICS_CACHE_EXPIRATION
        valueFrom:
          configMapKeyRef:
            key: controller.metrics.cache.expiration
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_TIMEOUT_SECONDS
        valueFrom:
          configMapKeyRef:
            key: controller.self.heal.timeout.seconds
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_PLAINTEXT
        valueFrom:
          configMapKeyRef:
            key: controller.repo.server.plaintext
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_STRICT_TLS
        valueFrom:
          configMapKeyRef:
            key: controller.repo.server.strict.tls
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATION_CONTROLLER_PERSIST_RESOURCE_HEALTH
        valueFrom:
          configMapKeyRef:
            key: controller.resource.health.persist
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APP_STATE_CACHE_EXPIRATION
        valueFrom:
          configMapKeyRef:
            key: controller.app.state.cache.expiration
            name: argocd-cmd-params-cm
            optional: true
      - name: REDIS_SERVER
        valueFrom:
          configMapKeyRef:
            key: redis.server
            name: argocd-cmd-params-cm
            optional: true
      - name: REDIS_COMPRESSION
        valueFrom:
          configMapKeyRef:
            key: redis.compression
            name: argocd-cmd-params-cm
            optional: true
      - name: REDISDB
        valueFrom:
          configMapKeyRef:
            key: redis.db
            name: argocd-cmd-params-cm
            optional: true
      - name: REDIS_USERNAME
        valueFrom:
          secretKeyRef:
            key: redis-username
            name: argocd-redis
            optional: true
      - name: REDIS_PASSWORD
        valueFrom:
          secretKeyRef:
            key: auth
            name: argocd-redis
            optional: true
      - name: REDIS_SENTINEL_USERNAME
        valueFrom:
          secretKeyRef:
            key: redis-sentinel-username
            name: argocd-redis
            optional: true
      - name: REDIS_SENTINEL_PASSWORD
        valueFrom:
          secretKeyRef:
            key: redis-sentinel-password
            name: argocd-redis
            optional: true
      - name: ARGOCD_DEFAULT_CACHE_EXPIRATION
        valueFrom:
          configMapKeyRef:
            key: controller.default.cache.expiration
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_ADDRESS
        valueFrom:
          configMapKeyRef:
            key: otlp.address
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_INSECURE
        valueFrom:
          configMapKeyRef:
            key: otlp.insecure
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_HEADERS
        valueFrom:
          configMapKeyRef:
            key: otlp.headers
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATION_NAMESPACES
        valueFrom:
          configMapKeyRef:
            key: application.namespaces
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_CONTROLLER_SHARDING_ALGORITHM
        valueFrom:
          configMapKeyRef:
            key: controller.sharding.algorithm
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATION_CONTROLLER_KUBECTL_PARALLELISM_LIMIT
        valueFrom:
          configMapKeyRef:
            key: controller.kubectl.parallelism.limit
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_K8SCLIENT_RETRY_MAX
        valueFrom:
          configMapKeyRef:
            key: controller.k8sclient.retry.max
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_K8SCLIENT_RETRY_BASE_BACKOFF
        valueFrom:
          configMapKeyRef:
            key: controller.k8sclient.retry.base.backoff
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATION_CONTROLLER_SERVER_SIDE_DIFF
        valueFrom:
          configMapKeyRef:
            key: controller.diff.server.side
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_IGNORE_NORMALIZER_JQ_TIMEOUT
        valueFrom:
          configMapKeyRef:
            key: controller.ignore.normalizer.jq.timeout
            name: argocd-cmd-params-cm
            optional: true
      image: quay.io/argoproj/argocd:v2.11.5
      imagePullPolicy: IfNotPresent
      name: application-controller
      ports:
      - containerPort: 8082
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: metrics
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /app/config/controller/tls
        name: argocd-repo-server-tls
      - mountPath: /home/argocd
        name: argocd-home
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-glpxs
        readOnly: true
      workingDir: /home/argocd
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: argocd-application-controller-0
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: argocd-application-controller
    serviceAccountName: argocd-application-controller
    subdomain: argocd-application-controller
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir: {}
      name: argocd-home
    - name: argocd-repo-server-tls
      secret:
        defaultMode: 420
        items:
        - key: tls.crt
          path: tls.crt
        - key: tls.key
          path: tls.key
        - key: ca.crt
          path: ca.crt
        optional: true
        secretName: argocd-repo-server-tls
    - name: kube-api-access-glpxs
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:16Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-07-19T17:25:51Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:22Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:22Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-07-19T17:25:51Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://8107a0e14e85bc40bfc3ae9c85feebdc8fa51862cd3e1ae3c77ccf738db09259
      image: quay.io/argoproj/argocd:v2.11.5
      imageID: docker-pullable://quay.io/argoproj/argocd@sha256:a39a3dd97da2ff325a06bb4a6ed3e84ccacc297740ec38afa50fb15bda2bf7f0
      lastState: {}
      name: application-controller
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2024-12-23T13:36:10Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 10.244.1.127
    podIPs:
    - ip: 10.244.1.127
    qosClass: BestEffort
    startTime: "2024-07-19T17:25:51Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      checksum/cmd-params: bcbb2496303699a508a41b49a033d6f92d273aba139ec132105f461a1d84fa46
    creationTimestamp: "2024-07-19T17:25:51Z"
    generateName: argocd-applicationset-controller-56d4d6458b-
    labels:
      app.kubernetes.io/component: applicationset-controller
      app.kubernetes.io/instance: argocd
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: argocd-applicationset-controller
      app.kubernetes.io/part-of: argocd
      app.kubernetes.io/version: v2.11.5
      helm.sh/chart: argo-cd-7.3.9
      pod-template-hash: 56d4d6458b
    name: argocd-applicationset-controller-56d4d6458b-krz9z
    namespace: argocd
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: argocd-applicationset-controller-56d4d6458b
      uid: 85e1a1a4-44c7-4049-be7c-dccb964c4dfe
    resourceVersion: "17862484"
    uid: 7a156a92-541d-4ef3-80d6-94616c2d5b91
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app.kubernetes.io/name: argocd-applicationset-controller
            topologyKey: kubernetes.io/hostname
          weight: 100
    automountServiceAccountToken: true
    containers:
    - args:
      - /usr/local/bin/argocd-applicationset-controller
      - --metrics-addr=:8080
      - --probe-addr=:8081
      - --webhook-addr=:7000
      env:
      - name: NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: ARGOCD_APPLICATIONSET_CONTROLLER_GLOBAL_PRESERVED_ANNOTATIONS
        valueFrom:
          configMapKeyRef:
            key: applicationsetcontroller.global.preserved.annotations
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATIONSET_CONTROLLER_GLOBAL_PRESERVED_LABELS
        valueFrom:
          configMapKeyRef:
            key: applicationsetcontroller.global.preserved.labels
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_LEADER_ELECTION
        valueFrom:
          configMapKeyRef:
            key: applicationsetcontroller.enable.leader.election
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER
        valueFrom:
          configMapKeyRef:
            key: repo.server
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATIONSET_CONTROLLER_POLICY
        valueFrom:
          configMapKeyRef:
            key: applicationsetcontroller.policy
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_POLICY_OVERRIDE
        valueFrom:
          configMapKeyRef:
            key: applicationsetcontroller.enable.policy.override
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATIONSET_CONTROLLER_DEBUG
        valueFrom:
          configMapKeyRef:
            key: applicationsetcontroller.debug
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATIONSET_CONTROLLER_LOGFORMAT
        valueFrom:
          configMapKeyRef:
            key: applicationsetcontroller.log.format
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATIONSET_CONTROLLER_LOGLEVEL
        valueFrom:
          configMapKeyRef:
            key: applicationsetcontroller.log.level
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATIONSET_CONTROLLER_DRY_RUN
        valueFrom:
          configMapKeyRef:
            key: applicationsetcontroller.dryrun
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_GIT_MODULES_ENABLED
        valueFrom:
          configMapKeyRef:
            key: applicationsetcontroller.enable.git.submodule
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_PROGRESSIVE_SYNCS
        valueFrom:
          configMapKeyRef:
            key: applicationsetcontroller.enable.progressive.syncs
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_NEW_GIT_FILE_GLOBBING
        valueFrom:
          configMapKeyRef:
            key: applicationsetcontroller.enable.new.git.file.globbing
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_PLAINTEXT
        valueFrom:
          configMapKeyRef:
            key: applicationsetcontroller.repo.server.plaintext
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_STRICT_TLS
        valueFrom:
          configMapKeyRef:
            key: applicationsetcontroller.repo.server.strict.tls
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_TIMEOUT_SECONDS
        valueFrom:
          configMapKeyRef:
            key: applicationsetcontroller.repo.server.timeout.seconds
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATIONSET_CONTROLLER_CONCURRENT_RECONCILIATIONS
        valueFrom:
          configMapKeyRef:
            key: applicationsetcontroller.concurrent.reconciliations.max
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATIONSET_CONTROLLER_NAMESPACES
        valueFrom:
          configMapKeyRef:
            key: applicationsetcontroller.namespaces
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATIONSET_CONTROLLER_SCM_ROOT_CA_PATH
        valueFrom:
          configMapKeyRef:
            key: applicationsetcontroller.scm.root.ca.path
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATIONSET_CONTROLLER_ALLOWED_SCM_PROVIDERS
        valueFrom:
          configMapKeyRef:
            key: applicationsetcontroller.allowed.scm.providers
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_SCM_PROVIDERS
        valueFrom:
          configMapKeyRef:
            key: applicationsetcontroller.enable.scm.providers
            name: argocd-cmd-params-cm
            optional: true
      image: quay.io/argoproj/argocd:v2.11.5
      imagePullPolicy: IfNotPresent
      name: applicationset-controller
      ports:
      - containerPort: 8080
        name: metrics
        protocol: TCP
      - containerPort: 8081
        name: probe
        protocol: TCP
      - containerPort: 7000
        name: webhook
        protocol: TCP
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /app/config/ssh
        name: ssh-known-hosts
      - mountPath: /app/config/tls
        name: tls-certs
      - mountPath: /app/config/gpg/source
        name: gpg-keys
      - mountPath: /app/config/gpg/keys
        name: gpg-keyring
      - mountPath: /app/config/reposerver/tls
        name: argocd-repo-server-tls
      - mountPath: /tmp
        name: tmp
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-hs7jl
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: argocd-applicationset-controller
    serviceAccountName: argocd-applicationset-controller
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: argocd-ssh-known-hosts-cm
      name: ssh-known-hosts
    - configMap:
        defaultMode: 420
        name: argocd-tls-certs-cm
      name: tls-certs
    - configMap:
        defaultMode: 420
        name: argocd-gpg-keys-cm
      name: gpg-keys
    - emptyDir: {}
      name: gpg-keyring
    - emptyDir: {}
      name: tmp
    - name: argocd-repo-server-tls
      secret:
        defaultMode: 420
        items:
        - key: tls.crt
          path: tls.crt
        - key: tls.key
          path: tls.key
        - key: ca.crt
          path: ca.crt
        optional: true
        secretName: argocd-repo-server-tls
    - name: kube-api-access-hs7jl
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:17Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-07-19T17:25:51Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:17Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:17Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-07-19T17:25:51Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://6e8e6753e681383c1fff694535061e549f67c1f150e5546deec4c0fb45e72889
      image: quay.io/argoproj/argocd:v2.11.5
      imageID: docker-pullable://quay.io/argoproj/argocd@sha256:a39a3dd97da2ff325a06bb4a6ed3e84ccacc297740ec38afa50fb15bda2bf7f0
      lastState: {}
      name: applicationset-controller
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2024-12-23T13:36:10Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 10.244.1.126
    podIPs:
    - ip: 10.244.1.126
    qosClass: BestEffort
    startTime: "2024-07-19T17:25:51Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      checksum/cmd-params: bcbb2496303699a508a41b49a033d6f92d273aba139ec132105f461a1d84fa46
    creationTimestamp: "2024-07-19T17:25:51Z"
    generateName: argocd-dex-server-7db6876989-
    labels:
      app.kubernetes.io/component: dex-server
      app.kubernetes.io/instance: argocd
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: argocd-dex-server
      app.kubernetes.io/part-of: argocd
      app.kubernetes.io/version: v2.11.5
      helm.sh/chart: argo-cd-7.3.9
      pod-template-hash: 7db6876989
    name: argocd-dex-server-7db6876989-4ppln
    namespace: argocd
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: argocd-dex-server-7db6876989
      uid: bba8b4d4-7c02-454a-b3ea-2f7b4e350ea6
    resourceVersion: "17862389"
    uid: f1d2a245-53a6-486b-af08-9726a1982219
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app.kubernetes.io/name: argocd-dex-server
            topologyKey: kubernetes.io/hostname
          weight: 100
    automountServiceAccountToken: true
    containers:
    - args:
      - rundex
      command:
      - /shared/argocd-dex
      - --logformat=text
      - --loglevel=info
      env:
      - name: ARGOCD_DEX_SERVER_DISABLE_TLS
        valueFrom:
          configMapKeyRef:
            key: dexserver.disable.tls
            name: argocd-cmd-params-cm
            optional: true
      image: ghcr.io/dexidp/dex:v2.38.0
      imagePullPolicy: IfNotPresent
      name: dex-server
      ports:
      - containerPort: 5556
        name: http
        protocol: TCP
      - containerPort: 5557
        name: grpc
        protocol: TCP
      - containerPort: 5558
        name: metrics
        protocol: TCP
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /shared
        name: static-files
      - mountPath: /tmp
        name: dexconfig
      - mountPath: /tls
        name: argocd-dex-server-tls
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-z2pqz
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    initContainers:
    - command:
      - /bin/cp
      - -n
      - /usr/local/bin/argocd
      - /shared/argocd-dex
      image: quay.io/argoproj/argocd:v2.11.5
      imagePullPolicy: IfNotPresent
      name: copyutil
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /shared
        name: static-files
      - mountPath: /tmp
        name: dexconfig
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-z2pqz
        readOnly: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: argocd-dex-server
    serviceAccountName: argocd-dex-server
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir: {}
      name: static-files
    - emptyDir: {}
      name: dexconfig
    - name: argocd-dex-server-tls
      secret:
        defaultMode: 420
        items:
        - key: tls.crt
          path: tls.crt
        - key: tls.key
          path: tls.key
        - key: ca.crt
          path: ca.crt
        optional: true
        secretName: argocd-dex-server-tls
    - name: kube-api-access-z2pqz
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:22Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-07-19T17:25:54Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:27Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:27Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-07-19T17:25:51Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://6df331739f2cd0b74284b4fa0e0634e3792e71608f352d4c62c28d3deb7e97d5
      image: ghcr.io/dexidp/dex:v2.38.0
      imageID: docker-pullable://ghcr.io/dexidp/dex@sha256:b1d793440a98d7ecde7fa5dbc8cee1204ef0e8918d9e51ef6201f50d12d55925
      lastState: {}
      name: dex-server
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2024-12-23T13:36:23Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    initContainerStatuses:
    - containerID: docker://78c0a45d8c747f33fec3d1ed4fbc0df5134822921216370d82b84c53e2ba2f68
      image: quay.io/argoproj/argocd:v2.11.5
      imageID: docker-pullable://quay.io/argoproj/argocd@sha256:a39a3dd97da2ff325a06bb4a6ed3e84ccacc297740ec38afa50fb15bda2bf7f0
      lastState: {}
      name: copyutil
      ready: true
      restartCount: 1
      started: false
      state:
        terminated:
          containerID: docker://78c0a45d8c747f33fec3d1ed4fbc0df5134822921216370d82b84c53e2ba2f68
          exitCode: 0
          finishedAt: "2024-12-23T13:36:16Z"
          reason: Completed
          startedAt: "2024-12-23T13:36:16Z"
    phase: Running
    podIP: 10.244.1.146
    podIPs:
    - ip: 10.244.1.146
    qosClass: BestEffort
    startTime: "2024-07-19T17:25:51Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-07-19T17:25:51Z"
    generateName: argocd-notifications-controller-5c8658678f-
    labels:
      app.kubernetes.io/component: notifications-controller
      app.kubernetes.io/instance: argocd
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: argocd-notifications-controller
      app.kubernetes.io/part-of: argocd
      app.kubernetes.io/version: v2.11.5
      helm.sh/chart: argo-cd-7.3.9
      pod-template-hash: 5c8658678f
    name: argocd-notifications-controller-5c8658678f-zjkzs
    namespace: argocd
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: argocd-notifications-controller-5c8658678f
      uid: 8b9f5444-40e4-42fd-9188-9e1246a5b76d
    resourceVersion: "17862368"
    uid: f836e8f2-f3ef-460b-96ec-3d5f0e9e2333
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app.kubernetes.io/name: argocd-notifications-controller
            topologyKey: kubernetes.io/hostname
          weight: 100
    automountServiceAccountToken: true
    containers:
    - args:
      - /usr/local/bin/argocd-notifications
      - --metrics-port=9001
      - --loglevel=info
      - --logformat=text
      - --namespace=argocd
      - --argocd-repo-server=argocd-repo-server:8081
      - --secret-name=argocd-notifications-secret
      env:
      - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGLEVEL
        valueFrom:
          configMapKeyRef:
            key: notificationscontroller.log.level
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
        valueFrom:
          configMapKeyRef:
            key: notificationscontroller.log.format
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATION_NAMESPACES
        valueFrom:
          configMapKeyRef:
            key: application.namespaces
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_NOTIFICATION_CONTROLLER_SELF_SERVICE_NOTIFICATION_ENABLED
        valueFrom:
          configMapKeyRef:
            key: notificationscontroller.selfservice.enabled
            name: argocd-cmd-params-cm
            optional: true
      image: quay.io/argoproj/argocd:v2.11.5
      imagePullPolicy: IfNotPresent
      name: notifications-controller
      ports:
      - containerPort: 9001
        name: metrics
        protocol: TCP
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /app/config/tls
        name: tls-certs
      - mountPath: /app/config/reposerver/tls
        name: argocd-repo-server-tls
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-kmxgb
        readOnly: true
      workingDir: /app
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: argocd-notifications-controller
    serviceAccountName: argocd-notifications-controller
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: argocd-tls-certs-cm
      name: tls-certs
    - name: argocd-repo-server-tls
      secret:
        defaultMode: 420
        items:
        - key: tls.crt
          path: tls.crt
        - key: tls.key
          path: tls.key
        - key: ca.crt
          path: ca.crt
        optional: true
        secretName: argocd-repo-server-tls
    - name: kube-api-access-kmxgb
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:17Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-07-19T17:25:51Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:17Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:17Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-07-19T17:25:51Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://a285da009bbfa0a2b07fbf8210d870cfe1ce4e3aa3c27571b3f350b0248008aa
      image: quay.io/argoproj/argocd:v2.11.5
      imageID: docker-pullable://quay.io/argoproj/argocd@sha256:a39a3dd97da2ff325a06bb4a6ed3e84ccacc297740ec38afa50fb15bda2bf7f0
      lastState: {}
      name: notifications-controller
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2024-12-23T13:36:13Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 10.244.1.139
    podIPs:
    - ip: 10.244.1.139
    qosClass: BestEffort
    startTime: "2024-07-19T17:25:51Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-07-19T17:25:51Z"
    generateName: argocd-redis-6d9f6dc894-
    labels:
      app.kubernetes.io/component: redis
      app.kubernetes.io/instance: argocd
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: argocd-redis
      app.kubernetes.io/part-of: argocd
      app.kubernetes.io/version: v2.11.5
      helm.sh/chart: argo-cd-7.3.9
      pod-template-hash: 6d9f6dc894
    name: argocd-redis-6d9f6dc894-n6dld
    namespace: argocd
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: argocd-redis-6d9f6dc894
      uid: 811c81f3-5f29-4fb9-b308-a603f40593d3
    resourceVersion: "17862386"
    uid: 73f5d5b0-ffaf-48af-b676-af81e4705442
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app.kubernetes.io/name: argocd-redis
            topologyKey: kubernetes.io/hostname
          weight: 100
    automountServiceAccountToken: true
    containers:
    - args:
      - --save
      - ""
      - --appendonly
      - "no"
      - --requirepass $(REDIS_PASSWORD)
      env:
      - name: REDIS_PASSWORD
        valueFrom:
          secretKeyRef:
            key: auth
            name: argocd-redis
      image: public.ecr.aws/docker/library/redis:7.2.4-alpine
      imagePullPolicy: IfNotPresent
      name: redis
      ports:
      - containerPort: 6379
        name: redis
        protocol: TCP
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /health
        name: health
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-ndh6g
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
      runAsUser: 999
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 493
        name: argocd-redis-health-configmap
      name: health
    - name: kube-api-access-ndh6g
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:17Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-07-19T17:25:51Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:17Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:17Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-07-19T17:25:51Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://5ba3925a1edf0f0d22fa4d64eb58795ef02c6de4a0d0a3830f898bba8fabbeeb
      image: public.ecr.aws/docker/library/redis:7.2.4-alpine
      imageID: docker-pullable://public.ecr.aws/docker/library/redis@sha256:c8bb255c3559b3e458766db810aa7b3c7af1235b204cfdb304e79ff388fe1a5a
      lastState: {}
      name: redis
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2024-12-23T13:36:13Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 10.244.1.133
    podIPs:
    - ip: 10.244.1.133
    qosClass: BestEffort
    startTime: "2024-07-19T17:25:51Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-07-19T17:25:47Z"
    generateName: argocd-redis-secret-init-
    labels:
      app.kubernetes.io/component: redis-secret-init
      app.kubernetes.io/instance: argocd
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: argocd-redis-secret-init
      app.kubernetes.io/part-of: argocd
      app.kubernetes.io/version: v2.11.5
      batch.kubernetes.io/controller-uid: b9e5519c-6ef0-4988-9fd9-517301a7d897
      batch.kubernetes.io/job-name: argocd-redis-secret-init
      controller-uid: b9e5519c-6ef0-4988-9fd9-517301a7d897
      helm.sh/chart: argo-cd-7.3.9
      job-name: argocd-redis-secret-init
    name: argocd-redis-secret-init-ld7rw
    namespace: argocd
    ownerReferences:
    - apiVersion: batch/v1
      blockOwnerDeletion: true
      controller: true
      kind: Job
      name: argocd-redis-secret-init
      uid: b9e5519c-6ef0-4988-9fd9-517301a7d897
    resourceVersion: "766817"
    uid: a6a61e05-3539-4043-84ef-36c11e5e209c
  spec:
    containers:
    - command:
      - argocd
      - admin
      - redis-initial-password
      image: quay.io/argoproj/argocd:v2.11.5
      imagePullPolicy: IfNotPresent
      name: secret-init
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-dfwdw
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: OnFailure
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: argocd-redis-secret-init
    serviceAccountName: argocd-redis-secret-init
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-dfwdw
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-07-19T17:25:50Z"
      status: "False"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-07-19T17:25:47Z"
      reason: PodCompleted
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-07-19T17:25:49Z"
      reason: PodCompleted
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-07-19T17:25:49Z"
      reason: PodCompleted
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-07-19T17:25:47Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://fa75654495cdca4e0f4a0c173e0709c51a7108ee21c175f2656b9df33d28cc84
      image: quay.io/argoproj/argocd:v2.11.5
      imageID: docker-pullable://quay.io/argoproj/argocd@sha256:a39a3dd97da2ff325a06bb4a6ed3e84ccacc297740ec38afa50fb15bda2bf7f0
      lastState: {}
      name: secret-init
      ready: false
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: docker://fa75654495cdca4e0f4a0c173e0709c51a7108ee21c175f2656b9df33d28cc84
          exitCode: 0
          finishedAt: "2024-07-19T17:25:48Z"
          reason: Completed
          startedAt: "2024-07-19T17:25:48Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Succeeded
    qosClass: BestEffort
    startTime: "2024-07-19T17:25:47Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      checksum/cm: 9156c689cecc9c1147df3672959659693b08b4c335adc717836ea9bc0cc75160
      checksum/cmd-params: bcbb2496303699a508a41b49a033d6f92d273aba139ec132105f461a1d84fa46
    creationTimestamp: "2024-07-19T17:25:51Z"
    generateName: argocd-repo-server-6b5cdc488b-
    labels:
      app.kubernetes.io/component: repo-server
      app.kubernetes.io/instance: argocd
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: argocd-repo-server
      app.kubernetes.io/part-of: argocd
      app.kubernetes.io/version: v2.11.5
      helm.sh/chart: argo-cd-7.3.9
      pod-template-hash: 6b5cdc488b
    name: argocd-repo-server-6b5cdc488b-xmxcv
    namespace: argocd
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: argocd-repo-server-6b5cdc488b
      uid: 354e4fe0-2efa-4b08-b890-debb92b9e056
    resourceVersion: "22846810"
    uid: db9479a9-c093-450f-a149-e484e20e4f4d
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app.kubernetes.io/name: argocd-repo-server
            topologyKey: kubernetes.io/hostname
          weight: 100
    automountServiceAccountToken: true
    containers:
    - args:
      - /usr/local/bin/argocd-repo-server
      - --port=8081
      - --metrics-port=8084
      env:
      - name: ARGOCD_REPO_SERVER_NAME
        value: argocd-repo-server
      - name: ARGOCD_RECONCILIATION_TIMEOUT
        valueFrom:
          configMapKeyRef:
            key: timeout.reconciliation
            name: argocd-cm
            optional: true
      - name: ARGOCD_REPO_SERVER_LOGFORMAT
        valueFrom:
          configMapKeyRef:
            key: reposerver.log.format
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_REPO_SERVER_LOGLEVEL
        valueFrom:
          configMapKeyRef:
            key: reposerver.log.level
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_REPO_SERVER_PARALLELISM_LIMIT
        valueFrom:
          configMapKeyRef:
            key: reposerver.parallelism.limit
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_REPO_SERVER_LISTEN_ADDRESS
        valueFrom:
          configMapKeyRef:
            key: reposerver.listen.address
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_REPO_SERVER_LISTEN_METRICS_ADDRESS
        valueFrom:
          configMapKeyRef:
            key: reposerver.metrics.listen.address
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_REPO_SERVER_DISABLE_TLS
        valueFrom:
          configMapKeyRef:
            key: reposerver.disable.tls
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_TLS_MIN_VERSION
        valueFrom:
          configMapKeyRef:
            key: reposerver.tls.minversion
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_TLS_MAX_VERSION
        valueFrom:
          configMapKeyRef:
            key: reposerver.tls.maxversion
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_TLS_CIPHERS
        valueFrom:
          configMapKeyRef:
            key: reposerver.tls.ciphers
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_REPO_CACHE_EXPIRATION
        valueFrom:
          configMapKeyRef:
            key: reposerver.repo.cache.expiration
            name: argocd-cmd-params-cm
            optional: true
      - name: REDIS_SERVER
        valueFrom:
          configMapKeyRef:
            key: redis.server
            name: argocd-cmd-params-cm
            optional: true
      - name: REDIS_COMPRESSION
        valueFrom:
          configMapKeyRef:
            key: redis.compression
            name: argocd-cmd-params-cm
            optional: true
      - name: REDISDB
        valueFrom:
          configMapKeyRef:
            key: redis.db
            name: argocd-cmd-params-cm
            optional: true
      - name: REDIS_USERNAME
        valueFrom:
          secretKeyRef:
            key: redis-username
            name: argocd-redis
            optional: true
      - name: REDIS_PASSWORD
        valueFrom:
          secretKeyRef:
            key: auth
            name: argocd-redis
            optional: true
      - name: REDIS_SENTINEL_USERNAME
        valueFrom:
          secretKeyRef:
            key: redis-sentinel-username
            name: argocd-redis
            optional: true
      - name: REDIS_SENTINEL_PASSWORD
        valueFrom:
          secretKeyRef:
            key: redis-sentinel-password
            name: argocd-redis
            optional: true
      - name: ARGOCD_DEFAULT_CACHE_EXPIRATION
        valueFrom:
          configMapKeyRef:
            key: reposerver.default.cache.expiration
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_REPO_SERVER_OTLP_ADDRESS
        valueFrom:
          configMapKeyRef:
            key: otlp.address
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_REPO_SERVER_OTLP_INSECURE
        valueFrom:
          configMapKeyRef:
            key: otlp.insecure
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_REPO_SERVER_OTLP_HEADERS
        valueFrom:
          configMapKeyRef:
            key: otlp.headers
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_REPO_SERVER_MAX_COMBINED_DIRECTORY_MANIFESTS_SIZE
        valueFrom:
          configMapKeyRef:
            key: reposerver.max.combined.directory.manifests.size
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_REPO_SERVER_PLUGIN_TAR_EXCLUSIONS
        valueFrom:
          configMapKeyRef:
            key: reposerver.plugin.tar.exclusions
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_REPO_SERVER_ALLOW_OUT_OF_BOUNDS_SYMLINKS
        valueFrom:
          configMapKeyRef:
            key: reposerver.allow.oob.symlinks
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_TAR_SIZE
        valueFrom:
          configMapKeyRef:
            key: reposerver.streamed.manifest.max.tar.size
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_EXTRACTED_SIZE
        valueFrom:
          configMapKeyRef:
            key: reposerver.streamed.manifest.max.extracted.size
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_REPO_SERVER_HELM_MANIFEST_MAX_EXTRACTED_SIZE
        valueFrom:
          configMapKeyRef:
            key: reposerver.helm.manifest.max.extracted.size
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_REPO_SERVER_DISABLE_HELM_MANIFEST_MAX_EXTRACTED_SIZE
        valueFrom:
          configMapKeyRef:
            key: reposerver.disable.helm.manifest.max.extracted.size
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_GIT_MODULES_ENABLED
        valueFrom:
          configMapKeyRef:
            key: reposerver.enable.git.submodule
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_GIT_LS_REMOTE_PARALLELISM_LIMIT
        valueFrom:
          configMapKeyRef:
            key: reposerver.git.lsremote.parallelism.limit
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_GIT_REQUEST_TIMEOUT
        valueFrom:
          configMapKeyRef:
            key: reposerver.git.request.timeout
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_REVISION_CACHE_LOCK_TIMEOUT
        valueFrom:
          configMapKeyRef:
            key: reposerver.revision.cache.lock.timeout
            name: argocd-cmd-params-cm
            optional: true
      - name: HELM_CACHE_HOME
        value: /helm-working-dir
      - name: HELM_CONFIG_HOME
        value: /helm-working-dir
      - name: HELM_DATA_HOME
        value: /helm-working-dir
      image: quay.io/argoproj/argocd:v2.11.5
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz?full=true
          port: metrics
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: repo-server
      ports:
      - containerPort: 8081
        name: repo-server
        protocol: TCP
      - containerPort: 8084
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: metrics
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /app/config/ssh
        name: ssh-known-hosts
      - mountPath: /app/config/tls
        name: tls-certs
      - mountPath: /app/config/gpg/source
        name: gpg-keys
      - mountPath: /app/config/gpg/keys
        name: gpg-keyring
      - mountPath: /app/config/reposerver/tls
        name: argocd-repo-server-tls
      - mountPath: /helm-working-dir
        name: helm-working-dir
      - mountPath: /home/argocd/cmp-server/plugins
        name: plugins
      - mountPath: /tmp
        name: tmp
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-lw7n9
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    initContainers:
    - command:
      - /bin/cp
      - -n
      - /usr/local/bin/argocd
      - /var/run/argocd/argocd-cmp-server
      image: quay.io/argoproj/argocd:v2.11.5
      imagePullPolicy: IfNotPresent
      name: copyutil
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/argocd
        name: var-files
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-lw7n9
        readOnly: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: argocd-repo-server
    serviceAccountName: argocd-repo-server
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir: {}
      name: helm-working-dir
    - emptyDir: {}
      name: plugins
    - emptyDir: {}
      name: var-files
    - emptyDir: {}
      name: tmp
    - configMap:
        defaultMode: 420
        name: argocd-ssh-known-hosts-cm
      name: ssh-known-hosts
    - configMap:
        defaultMode: 420
        name: argocd-tls-certs-cm
      name: tls-certs
    - configMap:
        defaultMode: 420
        name: argocd-gpg-keys-cm
      name: gpg-keys
    - emptyDir: {}
      name: gpg-keyring
    - name: argocd-repo-server-tls
      secret:
        defaultMode: 420
        items:
        - key: tls.crt
          path: tls.crt
        - key: tls.key
          path: tls.key
        - key: ca.crt
          path: ca.crt
        optional: true
        secretName: argocd-repo-server-tls
    - name: kube-api-access-lw7n9
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:21Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-07-19T17:25:54Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-02-07T06:56:06Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-02-07T06:56:06Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-07-19T17:25:51Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://84023862938ed3183a62a64eb0485200ba0fd4cf142e05a2e4a4f7b4788ea627
      image: quay.io/argoproj/argocd:v2.11.5
      imageID: docker-pullable://quay.io/argoproj/argocd@sha256:a39a3dd97da2ff325a06bb4a6ed3e84ccacc297740ec38afa50fb15bda2bf7f0
      lastState:
        terminated:
          containerID: docker://b23c5daf90474a5c97456c13aaa8be99af9fe2e7964ea1d41715c1a2e491a4f2
          exitCode: 143
          finishedAt: "2025-02-07T06:55:54Z"
          reason: Error
          startedAt: "2024-12-23T13:36:22Z"
      name: repo-server
      ready: true
      restartCount: 2
      started: true
      state:
        running:
          startedAt: "2025-02-07T06:55:56Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    initContainerStatuses:
    - containerID: docker://6ca6ef4c8583e107873d0672b37e8290dee0ff74f447becd5e46e50eab2416ee
      image: quay.io/argoproj/argocd:v2.11.5
      imageID: docker-pullable://quay.io/argoproj/argocd@sha256:a39a3dd97da2ff325a06bb4a6ed3e84ccacc297740ec38afa50fb15bda2bf7f0
      lastState: {}
      name: copyutil
      ready: true
      restartCount: 1
      started: false
      state:
        terminated:
          containerID: docker://6ca6ef4c8583e107873d0672b37e8290dee0ff74f447becd5e46e50eab2416ee
          exitCode: 0
          finishedAt: "2024-12-23T13:36:16Z"
          reason: Completed
          startedAt: "2024-12-23T13:36:16Z"
    phase: Running
    podIP: 10.244.1.145
    podIPs:
    - ip: 10.244.1.145
    qosClass: BestEffort
    startTime: "2024-07-19T17:25:51Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      checksum/cm: 9156c689cecc9c1147df3672959659693b08b4c335adc717836ea9bc0cc75160
      checksum/cmd-params: bcbb2496303699a508a41b49a033d6f92d273aba139ec132105f461a1d84fa46
    creationTimestamp: "2024-07-19T17:25:51Z"
    generateName: argocd-server-85f4f7b9f7-
    labels:
      app.kubernetes.io/component: server
      app.kubernetes.io/instance: argocd
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: argocd-server
      app.kubernetes.io/part-of: argocd
      app.kubernetes.io/version: v2.11.5
      helm.sh/chart: argo-cd-7.3.9
      pod-template-hash: 85f4f7b9f7
    name: argocd-server-85f4f7b9f7-s5bms
    namespace: argocd
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: argocd-server-85f4f7b9f7
      uid: 5a8a7973-a730-40b8-a50c-5210f6f350b8
    resourceVersion: "17862444"
    uid: b5c61df1-e3ef-404b-84c0-4b69d2ec6939
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchLabels:
                app.kubernetes.io/name: argocd-server
            topologyKey: kubernetes.io/hostname
          weight: 100
    automountServiceAccountToken: true
    containers:
    - args:
      - /usr/local/bin/argocd-server
      - --port=8080
      - --metrics-port=8083
      - --rootpath
      - /argocd
      env:
      - name: ARGOCD_SERVER_NAME
        value: argocd-server
      - name: ARGOCD_SERVER_INSECURE
        valueFrom:
          configMapKeyRef:
            key: server.insecure
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_SERVER_BASEHREF
        valueFrom:
          configMapKeyRef:
            key: server.basehref
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_SERVER_ROOTPATH
        valueFrom:
          configMapKeyRef:
            key: server.rootpath
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_SERVER_LOGFORMAT
        valueFrom:
          configMapKeyRef:
            key: server.log.format
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_SERVER_LOG_LEVEL
        valueFrom:
          configMapKeyRef:
            key: server.log.level
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_SERVER_REPO_SERVER
        valueFrom:
          configMapKeyRef:
            key: repo.server
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_SERVER_DEX_SERVER
        valueFrom:
          configMapKeyRef:
            key: server.dex.server
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_SERVER_DISABLE_AUTH
        valueFrom:
          configMapKeyRef:
            key: server.disable.auth
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_SERVER_ENABLE_GZIP
        valueFrom:
          configMapKeyRef:
            key: server.enable.gzip
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_SERVER_REPO_SERVER_TIMEOUT_SECONDS
        valueFrom:
          configMapKeyRef:
            key: server.repo.server.timeout.seconds
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_SERVER_X_FRAME_OPTIONS
        valueFrom:
          configMapKeyRef:
            key: server.x.frame.options
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_SERVER_CONTENT_SECURITY_POLICY
        valueFrom:
          configMapKeyRef:
            key: server.content.security.policy
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_SERVER_REPO_SERVER_PLAINTEXT
        valueFrom:
          configMapKeyRef:
            key: server.repo.server.plaintext
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_SERVER_REPO_SERVER_STRICT_TLS
        valueFrom:
          configMapKeyRef:
            key: server.repo.server.strict.tls
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_SERVER_DEX_SERVER_PLAINTEXT
        valueFrom:
          configMapKeyRef:
            key: server.dex.server.plaintext
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_SERVER_DEX_SERVER_STRICT_TLS
        valueFrom:
          configMapKeyRef:
            key: server.dex.server.strict.tls
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_TLS_MIN_VERSION
        valueFrom:
          configMapKeyRef:
            key: server.tls.minversion
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_TLS_MAX_VERSION
        valueFrom:
          configMapKeyRef:
            key: server.tls.maxversion
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_TLS_CIPHERS
        valueFrom:
          configMapKeyRef:
            key: server.tls.ciphers
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_SERVER_CONNECTION_STATUS_CACHE_EXPIRATION
        valueFrom:
          configMapKeyRef:
            key: server.connection.status.cache.expiration
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_SERVER_OIDC_CACHE_EXPIRATION
        valueFrom:
          configMapKeyRef:
            key: server.oidc.cache.expiration
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_SERVER_LOGIN_ATTEMPTS_EXPIRATION
        valueFrom:
          configMapKeyRef:
            key: server.login.attempts.expiration
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_SERVER_STATIC_ASSETS
        valueFrom:
          configMapKeyRef:
            key: server.staticassets
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APP_STATE_CACHE_EXPIRATION
        valueFrom:
          configMapKeyRef:
            key: server.app.state.cache.expiration
            name: argocd-cmd-params-cm
            optional: true
      - name: REDIS_SERVER
        valueFrom:
          configMapKeyRef:
            key: redis.server
            name: argocd-cmd-params-cm
            optional: true
      - name: REDIS_COMPRESSION
        valueFrom:
          configMapKeyRef:
            key: redis.compression
            name: argocd-cmd-params-cm
            optional: true
      - name: REDISDB
        valueFrom:
          configMapKeyRef:
            key: redis.db
            name: argocd-cmd-params-cm
            optional: true
      - name: REDIS_USERNAME
        valueFrom:
          secretKeyRef:
            key: redis-username
            name: argocd-redis
            optional: true
      - name: REDIS_PASSWORD
        valueFrom:
          secretKeyRef:
            key: auth
            name: argocd-redis
            optional: true
      - name: REDIS_SENTINEL_USERNAME
        valueFrom:
          secretKeyRef:
            key: redis-sentinel-username
            name: argocd-redis
            optional: true
      - name: REDIS_SENTINEL_PASSWORD
        valueFrom:
          secretKeyRef:
            key: redis-sentinel-password
            name: argocd-redis
            optional: true
      - name: ARGOCD_DEFAULT_CACHE_EXPIRATION
        valueFrom:
          configMapKeyRef:
            key: server.default.cache.expiration
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_MAX_COOKIE_NUMBER
        valueFrom:
          configMapKeyRef:
            key: server.http.cookie.maxnumber
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_SERVER_LISTEN_ADDRESS
        valueFrom:
          configMapKeyRef:
            key: server.listen.address
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_SERVER_METRICS_LISTEN_ADDRESS
        valueFrom:
          configMapKeyRef:
            key: server.metrics.listen.address
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_SERVER_OTLP_ADDRESS
        valueFrom:
          configMapKeyRef:
            key: otlp.address
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_SERVER_OTLP_INSECURE
        valueFrom:
          configMapKeyRef:
            key: otlp.insecure
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_SERVER_OTLP_HEADERS
        valueFrom:
          configMapKeyRef:
            key: otlp.headers
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_APPLICATION_NAMESPACES
        valueFrom:
          configMapKeyRef:
            key: application.namespaces
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_SERVER_ENABLE_PROXY_EXTENSION
        valueFrom:
          configMapKeyRef:
            key: server.enable.proxy.extension
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_K8SCLIENT_RETRY_MAX
        valueFrom:
          configMapKeyRef:
            key: server.k8sclient.retry.max
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_K8SCLIENT_RETRY_BASE_BACKOFF
        valueFrom:
          configMapKeyRef:
            key: server.k8sclient.retry.base.backoff
            name: argocd-cmd-params-cm
            optional: true
      - name: ARGOCD_API_CONTENT_TYPES
        valueFrom:
          configMapKeyRef:
            key: server.api.content.types
            name: argocd-cmd-params-cm
            optional: true
      image: quay.io/argoproj/argocd:v2.11.5
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz?full=true
          port: server
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: server
      ports:
      - containerPort: 8080
        name: server
        protocol: TCP
      - containerPort: 8083
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: server
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /app/config/ssh
        name: ssh-known-hosts
      - mountPath: /app/config/tls
        name: tls-certs
      - mountPath: /app/config/server/tls
        name: argocd-repo-server-tls
      - mountPath: /app/config/dex/tls
        name: argocd-dex-server-tls
      - mountPath: /home/argocd
        name: plugins-home
      - mountPath: /shared/app/custom
        name: styles
      - mountPath: /tmp
        name: tmp
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-q8d9f
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: argocd-server
    serviceAccountName: argocd-server
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir: {}
      name: plugins-home
    - emptyDir: {}
      name: tmp
    - configMap:
        defaultMode: 420
        name: argocd-ssh-known-hosts-cm
      name: ssh-known-hosts
    - configMap:
        defaultMode: 420
        name: argocd-tls-certs-cm
      name: tls-certs
    - configMap:
        defaultMode: 420
        name: argocd-styles-cm
        optional: true
      name: styles
    - name: argocd-repo-server-tls
      secret:
        defaultMode: 420
        items:
        - key: tls.crt
          path: tls.crt
        - key: tls.key
          path: tls.key
        - key: ca.crt
          path: ca.crt
        optional: true
        secretName: argocd-repo-server-tls
    - name: argocd-dex-server-tls
      secret:
        defaultMode: 420
        items:
        - key: tls.crt
          path: tls.crt
        - key: ca.crt
          path: ca.crt
        optional: true
        secretName: argocd-dex-server-tls
    - name: kube-api-access-q8d9f
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:13Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-07-19T17:25:51Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:22Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:22Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-07-19T17:25:51Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://845976c914a0ecad51794484b506f194b92dc10ca91daf27c2594e23e3194a5f
      image: quay.io/argoproj/argocd:v2.11.5
      imageID: docker-pullable://quay.io/argoproj/argocd@sha256:a39a3dd97da2ff325a06bb4a6ed3e84ccacc297740ec38afa50fb15bda2bf7f0
      lastState: {}
      name: server
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2024-12-23T13:36:11Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 10.244.1.131
    podIPs:
    - ip: 10.244.1.131
    qosClass: BestEffort
    startTime: "2024-07-19T17:25:51Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2025-01-06T14:43:15+09:00"
    creationTimestamp: "2025-01-06T05:43:38Z"
    generateName: backend-5f6bfbb599-
    labels:
      app: backend
      pod-template-hash: 5f6bfbb599
    name: backend-5f6bfbb599-dxjlg
    namespace: backend
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: backend-5f6bfbb599
      uid: d00d5309-28fb-41c6-a86d-0b74a1158708
    resourceVersion: "19414817"
    uid: c8d91145-b175-4462-a21e-e34c74c65262
  spec:
    containers:
    - env:
      - name: SPRING_CONFIG_LOCATION
        value: /app/config/application.yaml
      image: zicdding0904/zicdding-class-back:latest
      imagePullPolicy: Always
      name: backend
      ports:
      - containerPort: 3000
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /app/config/application.yaml
        name: config-volume
        subPath: application.yaml
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-mvfx4
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: backend-config
      name: config-volume
    - name: kube-api-access-mvfx4
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-01-06T05:43:50Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-01-06T05:43:38Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-01-06T05:43:50Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-01-06T05:43:50Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-01-06T05:43:38Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://b8a5f0220bec1293f88ab7ebcdafbb950700ffe61dcf8524c541d54edd8e2bd5
      image: zicdding0904/zicdding-class-back:latest
      imageID: docker-pullable://zicdding0904/zicdding-class-back@sha256:7f205f1036192398c03aa5c1f10f6878a976d8ad3de13b0839f61bcc0dddc69d
      lastState: {}
      name: backend
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-01-06T05:43:49Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 10.244.1.181
    podIPs:
    - ip: 10.244.1.181
    qosClass: BestEffort
    startTime: "2025-01-06T05:43:38Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2025-01-06T14:43:15+09:00"
    creationTimestamp: "2025-01-06T05:43:15Z"
    generateName: backend-5f6bfbb599-
    labels:
      app: backend
      pod-template-hash: 5f6bfbb599
    name: backend-5f6bfbb599-mhs7f
    namespace: backend
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: backend-5f6bfbb599
      uid: d00d5309-28fb-41c6-a86d-0b74a1158708
    resourceVersion: "19414771"
    uid: 0ce70606-9b77-49e5-a87d-7e828b443149
  spec:
    containers:
    - env:
      - name: SPRING_CONFIG_LOCATION
        value: /app/config/application.yaml
      image: zicdding0904/zicdding-class-back:latest
      imagePullPolicy: Always
      name: backend
      ports:
      - containerPort: 3000
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /app/config/application.yaml
        name: config-volume
        subPath: application.yaml
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-d4gj2
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: backend-config
      name: config-volume
    - name: kube-api-access-d4gj2
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-01-06T05:43:38Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2025-01-06T05:43:15Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-01-06T05:43:38Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-01-06T05:43:38Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-01-06T05:43:15Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://463e128dcbd5457caeaab4b6fffae8a7517d4f58535e62748f96c794262926ae
      image: zicdding0904/zicdding-class-back:latest
      imageID: docker-pullable://zicdding0904/zicdding-class-back@sha256:7f205f1036192398c03aa5c1f10f6878a976d8ad3de13b0839f61bcc0dddc69d
      lastState: {}
      name: backend
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-01-06T05:43:37Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 10.244.1.180
    podIPs:
    - ip: 10.244.1.180
    qosClass: BestEffort
    startTime: "2025-01-06T05:43:15Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-08-03T05:16:32Z"
    generateName: ingress-nginx-admission-create-
    labels:
      app.kubernetes.io/component: admission-webhook
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/name: ingress-nginx
      batch.kubernetes.io/controller-uid: 348142fc-f5a7-42fb-a4e3-9ff3eb4c1647
      batch.kubernetes.io/job-name: ingress-nginx-admission-create
      controller-uid: 348142fc-f5a7-42fb-a4e3-9ff3eb4c1647
      job-name: ingress-nginx-admission-create
    name: ingress-nginx-admission-create-fw9fk
    namespace: ingress-nginx
    ownerReferences:
    - apiVersion: batch/v1
      blockOwnerDeletion: true
      controller: true
      kind: Job
      name: ingress-nginx-admission-create
      uid: 348142fc-f5a7-42fb-a4e3-9ff3eb4c1647
    resourceVersion: "13870282"
    uid: cbb70df7-70db-443f-9485-b1482e252016
  spec:
    containers:
    - args:
      - create
      - --host=ingress-nginx-controller-admission,ingress-nginx-controller-admission.$(POD_NAMESPACE).svc
      - --namespace=$(POD_NAMESPACE)
      - --secret-name=ingress-nginx-admission
      env:
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.4.1@sha256:36d05b4077fb8e3d13663702fa337f124675ba8667cbd949c03a8e8ea6fa4366
      imagePullPolicy: IfNotPresent
      name: create
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-6qngn
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: minikube
    nodeSelector:
      kubernetes.io/os: linux
      minikube.k8s.io/primary: "true"
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: OnFailure
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
      runAsUser: 2000
    serviceAccount: ingress-nginx-admission
    serviceAccountName: ingress-nginx-admission
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-6qngn
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-08-03T05:16:35Z"
      status: "False"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-08-03T05:16:32Z"
      reason: PodCompleted
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-03T05:16:32Z"
      reason: PodCompleted
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-03T05:16:32Z"
      reason: PodCompleted
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-08-03T05:16:32Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://72d9bb38ed703075377148c186f666d58caf3fe379097f8331dd160eef1a2fb3
      image: sha256:684c5ea3b61b299cd4e713c10bfd8989341da91f6175e2e6e502869c0781fb66
      imageID: docker-pullable://registry.k8s.io/ingress-nginx/kube-webhook-certgen@sha256:36d05b4077fb8e3d13663702fa337f124675ba8667cbd949c03a8e8ea6fa4366
      lastState: {}
      name: create
      ready: false
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: docker://72d9bb38ed703075377148c186f666d58caf3fe379097f8331dd160eef1a2fb3
          exitCode: 0
          finishedAt: "2024-08-03T05:16:33Z"
          reason: Completed
          startedAt: "2024-08-03T05:16:33Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Succeeded
    qosClass: BestEffort
    startTime: "2024-08-03T05:16:32Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-08-03T05:16:32Z"
    generateName: ingress-nginx-admission-patch-
    labels:
      app.kubernetes.io/component: admission-webhook
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/name: ingress-nginx
      batch.kubernetes.io/controller-uid: c1abac12-b362-44f2-ba9d-e12ff629ccc9
      batch.kubernetes.io/job-name: ingress-nginx-admission-patch
      controller-uid: c1abac12-b362-44f2-ba9d-e12ff629ccc9
      job-name: ingress-nginx-admission-patch
    name: ingress-nginx-admission-patch-qdn8m
    namespace: ingress-nginx
    ownerReferences:
    - apiVersion: batch/v1
      blockOwnerDeletion: true
      controller: true
      kind: Job
      name: ingress-nginx-admission-patch
      uid: c1abac12-b362-44f2-ba9d-e12ff629ccc9
    resourceVersion: "13870284"
    uid: b6d93f6a-571e-4353-92d8-e84b15d9aeea
  spec:
    containers:
    - args:
      - patch
      - --webhook-name=ingress-nginx-admission
      - --namespace=$(POD_NAMESPACE)
      - --patch-mutating=false
      - --secret-name=ingress-nginx-admission
      - --patch-failure-policy=Fail
      env:
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      image: registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.4.1@sha256:36d05b4077fb8e3d13663702fa337f124675ba8667cbd949c03a8e8ea6fa4366
      imagePullPolicy: IfNotPresent
      name: patch
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-bbpkl
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: minikube
    nodeSelector:
      kubernetes.io/os: linux
      minikube.k8s.io/primary: "true"
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: OnFailure
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
      runAsUser: 2000
    serviceAccount: ingress-nginx-admission
    serviceAccountName: ingress-nginx-admission
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-bbpkl
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-08-03T05:16:36Z"
      status: "False"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-08-03T05:16:32Z"
      reason: PodCompleted
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-08-03T05:16:32Z"
      reason: PodCompleted
      status: "False"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-08-03T05:16:32Z"
      reason: PodCompleted
      status: "False"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-08-03T05:16:32Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://c324fd587d6403a608a213e0e519e1fe44642d0e6da18ab29b2154db5e4b1d39
      image: sha256:684c5ea3b61b299cd4e713c10bfd8989341da91f6175e2e6e502869c0781fb66
      imageID: docker-pullable://registry.k8s.io/ingress-nginx/kube-webhook-certgen@sha256:36d05b4077fb8e3d13663702fa337f124675ba8667cbd949c03a8e8ea6fa4366
      lastState: {}
      name: patch
      ready: false
      restartCount: 1
      started: false
      state:
        terminated:
          containerID: docker://c324fd587d6403a608a213e0e519e1fe44642d0e6da18ab29b2154db5e4b1d39
          exitCode: 0
          finishedAt: "2024-08-03T05:16:34Z"
          reason: Completed
          startedAt: "2024-08-03T05:16:34Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Succeeded
    qosClass: BestEffort
    startTime: "2024-08-03T05:16:32Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2024-12-27T00:22:02+09:00"
    creationTimestamp: "2024-12-26T15:22:02Z"
    generateName: ingress-nginx-controller-79d9f6f4d6-
    labels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/name: ingress-nginx
      gcp-auth-skip-secret: "true"
      pod-template-hash: 79d9f6f4d6
    name: ingress-nginx-controller-79d9f6f4d6-fg9gj
    namespace: ingress-nginx
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: ingress-nginx-controller-79d9f6f4d6
      uid: e7fcb5ac-82e6-4102-9bbc-241dc5e3ecd7
    resourceVersion: "18212283"
    uid: a4a3d24b-1064-408b-a6f0-bd206c6df48a
  spec:
    containers:
    - args:
      - /nginx-ingress-controller
      - --election-id=ingress-nginx-leader
      - --controller-class=k8s.io/ingress-nginx
      - --watch-ingress-without-class=true
      - --configmap=$(POD_NAMESPACE)/ingress-nginx-controller
      - --tcp-services-configmap=$(POD_NAMESPACE)/tcp-services
      - --udp-services-configmap=$(POD_NAMESPACE)/udp-services
      - --validating-webhook=:8443
      - --validating-webhook-certificate=/usr/local/certificates/cert
      - --validating-webhook-key=/usr/local/certificates/key
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: LD_PRELOAD
        value: /usr/local/lib/libmimalloc.so
      image: registry.k8s.io/ingress-nginx/controller:v1.10.1@sha256:e24f39d3eed6bcc239a56f20098878845f62baa34b9f2be2fd2c38ce9fb0f29e
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - /wait-shutdown
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /healthz
          port: 10254
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: controller
      ports:
      - containerPort: 80
        hostPort: 80
        name: http
        protocol: TCP
      - containerPort: 443
        hostPort: 443
        name: https
        protocol: TCP
      - containerPort: 8443
        name: webhook
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: 10254
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 100m
          memory: 90Mi
      securityContext:
        allowPrivilegeEscalation: true
        capabilities:
          add:
          - NET_BIND_SERVICE
          drop:
          - ALL
        runAsUser: 101
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /usr/local/certificates/
        name: webhook-cert
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-pxp45
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: minikube
    nodeSelector:
      kubernetes.io/os: linux
      minikube.k8s.io/primary: "true"
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: ingress-nginx
    serviceAccountName: ingress-nginx
    terminationGracePeriodSeconds: 0
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Equal
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: webhook-cert
      secret:
        defaultMode: 420
        secretName: ingress-nginx-admission
    - name: kube-api-access-pxp45
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-12-26T15:22:07Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-12-26T15:22:04Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-12-26T15:22:24Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-12-26T15:22:24Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-12-26T15:22:04Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://1bdb3d453c181c686d7cd9c83d0d00fcbdfbf35a87d79f2ba56f7911bf8bfdbf
      image: sha256:ee54966f3891d75b255d160236368a4f9d3b588d32fb44bd04aea5101143e829
      imageID: docker-pullable://registry.k8s.io/ingress-nginx/controller@sha256:e24f39d3eed6bcc239a56f20098878845f62baa34b9f2be2fd2c38ce9fb0f29e
      lastState: {}
      name: controller
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-12-26T15:22:07Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 10.244.1.166
    podIPs:
    - ip: 10.244.1.166
    qosClass: Burstable
    startTime: "2024-12-26T15:22:04Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-07-20T01:14:48Z"
    generateName: nginx-ingress-ingress-nginx-controller-7855544b44-
    labels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: nginx-ingress
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: ingress-nginx
      app.kubernetes.io/part-of: ingress-nginx
      app.kubernetes.io/version: 1.11.1
      helm.sh/chart: ingress-nginx-4.11.1
      pod-template-hash: 7855544b44
    name: nginx-ingress-ingress-nginx-controller-7855544b44-lkv6d
    namespace: ingress-nginx
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: nginx-ingress-ingress-nginx-controller-7855544b44
      uid: ca98a617-f851-403a-b21d-00c8e3200a74
    resourceVersion: "17862429"
    uid: 25dfef74-4adf-47a5-8db4-7ac6c97f1203
  spec:
    containers:
    - args:
      - /nginx-ingress-controller
      - --publish-service=$(POD_NAMESPACE)/nginx-ingress-ingress-nginx-controller
      - --election-id=nginx-ingress-ingress-nginx-leader
      - --controller-class=k8s.io/ingress-nginx
      - --ingress-class=nginx
      - --configmap=$(POD_NAMESPACE)/nginx-ingress-ingress-nginx-controller
      - --validating-webhook=:8443
      - --validating-webhook-certificate=/usr/local/certificates/cert
      - --validating-webhook-key=/usr/local/certificates/key
      - --enable-metrics=false
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: metadata.namespace
      - name: LD_PRELOAD
        value: /usr/local/lib/libmimalloc.so
      image: registry.k8s.io/ingress-nginx/controller:v1.11.1@sha256:e6439a12b52076965928e83b7b56aae6731231677b01e81818bce7fa5c60161a
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - /wait-shutdown
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /healthz
          port: 10254
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: controller
      ports:
      - containerPort: 80
        name: http
        protocol: TCP
      - containerPort: 443
        name: https
        protocol: TCP
      - containerPort: 8443
        name: webhook
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: 10254
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 100m
          memory: 90Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          add:
          - NET_BIND_SERVICE
          drop:
          - ALL
        readOnlyRootFilesystem: false
        runAsNonRoot: true
        runAsUser: 101
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /usr/local/certificates/
        name: webhook-cert
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-8sgs4
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: minikube
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: nginx-ingress-ingress-nginx
    serviceAccountName: nginx-ingress-ingress-nginx
    terminationGracePeriodSeconds: 300
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: webhook-cert
      secret:
        defaultMode: 420
        secretName: nginx-ingress-ingress-nginx-admission
    - name: kube-api-access-8sgs4
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:17Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-07-20T01:14:48Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:36Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:36Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-07-20T01:14:48Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://74c033a58ad34e0af32c8d752b6da9e82f2248098de5d7547919e1f659873115
      image: sha256:5a3c471280784f5608f93a85c51b1d34b68689d20540689077010c90f137701a
      imageID: docker-pullable://registry.k8s.io/ingress-nginx/controller@sha256:e6439a12b52076965928e83b7b56aae6731231677b01e81818bce7fa5c60161a
      lastState: {}
      name: controller
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2024-12-23T13:36:14Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 10.244.1.137
    podIPs:
    - ip: 10.244.1.137
    qosClass: Burstable
    startTime: "2024-07-20T01:14:48Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-07-09T13:40:32Z"
    generateName: coredns-7db6d8ff4d-
    labels:
      k8s-app: kube-dns
      pod-template-hash: 7db6d8ff4d
    name: coredns-7db6d8ff4d-pcrm2
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: coredns-7db6d8ff4d
      uid: 14eea68f-ba1d-4906-b9de-a1cfa8a1d252
    resourceVersion: "17862491"
    uid: c637e5e3-23b6-4cc2-957b-f16aa162c3af
  spec:
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: k8s-app
                operator: In
                values:
                - kube-dns
            topologyKey: kubernetes.io/hostname
          weight: 100
    containers:
    - args:
      - -conf
      - /etc/coredns/Corefile
      image: registry.k8s.io/coredns/coredns:v1.11.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /health
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: coredns
      ports:
      - containerPort: 53
        name: dns
        protocol: UDP
      - containerPort: 53
        name: dns-tcp
        protocol: TCP
      - containerPort: 9153
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /ready
          port: 8181
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        limits:
          memory: 170Mi
        requests:
          cpu: 100m
          memory: 70Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          add:
          - NET_BIND_SERVICE
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/coredns
        name: config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-r2jl4
        readOnly: true
    dnsPolicy: Default
    enableServiceLinks: true
    nodeName: minikube
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: coredns
    serviceAccountName: coredns
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: CriticalAddonsOnly
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        items:
        - key: Corefile
          path: Corefile
        name: coredns
      name: config-volume
    - name: kube-api-access-r2jl4
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:17Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-07-09T13:40:32Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:17Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:17Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-07-09T13:40:32Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://6ff350d0e4078f3441ab525decbb44a831070e0e11118fd78fb16284c13733af
      image: registry.k8s.io/coredns/coredns:v1.11.1
      imageID: docker-pullable://registry.k8s.io/coredns/coredns@sha256:1eeb4c7316bacb1d4c8ead65571cd92dd21e27359f0d4917f1a5822a73b75db1
      lastState: {}
      name: coredns
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2024-12-23T13:36:10Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 10.244.1.128
    podIPs:
    - ip: 10.244.1.128
    qosClass: Burstable
    startTime: "2024-07-09T13:40:32Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubeadm.kubernetes.io/etcd.advertise-client-urls: https://192.168.49.2:2379
      kubernetes.io/config.hash: 063d6b9688927e601f52fd818d1305c5
      kubernetes.io/config.mirror: 063d6b9688927e601f52fd818d1305c5
      kubernetes.io/config.seen: "2024-07-09T13:40:18.289182353Z"
      kubernetes.io/config.source: file
    creationTimestamp: "2024-07-09T13:40:18Z"
    labels:
      component: etcd
      tier: control-plane
    name: etcd-minikube
    namespace: kube-system
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: minikube
      uid: 7e880626-2fba-4056-9d97-bf62046162bc
    resourceVersion: "17862398"
    uid: 9bf38af1-7a5e-4488-8842-969431844065
  spec:
    containers:
    - command:
      - etcd
      - --advertise-client-urls=https://192.168.49.2:2379
      - --cert-file=/var/lib/minikube/certs/etcd/server.crt
      - --client-cert-auth=true
      - --data-dir=/var/lib/minikube/etcd
      - --experimental-initial-corrupt-check=true
      - --experimental-watch-progress-notify-interval=5s
      - --initial-advertise-peer-urls=https://192.168.49.2:2380
      - --initial-cluster=minikube=https://192.168.49.2:2380
      - --key-file=/var/lib/minikube/certs/etcd/server.key
      - --listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379
      - --listen-metrics-urls=http://127.0.0.1:2381
      - --listen-peer-urls=https://192.168.49.2:2380
      - --name=minikube
      - --peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt
      - --peer-client-cert-auth=true
      - --peer-key-file=/var/lib/minikube/certs/etcd/peer.key
      - --peer-trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt
      - --proxy-refresh-interval=70000
      - --snapshot-count=10000
      - --trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt
      image: registry.k8s.io/etcd:3.5.12-0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 127.0.0.1
          path: /health?exclude=NOSPACE&serializable=true
          port: 2381
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: etcd
      resources:
        requests:
          cpu: 100m
          memory: 100Mi
      startupProbe:
        failureThreshold: 24
        httpGet:
          host: 127.0.0.1
          path: /health?serializable=false
          port: 2381
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/minikube/etcd
        name: etcd-data
      - mountPath: /var/lib/minikube/certs/etcd
        name: etcd-certs
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      seccompProfile:
        type: RuntimeDefault
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /var/lib/minikube/certs/etcd
        type: DirectoryOrCreate
      name: etcd-certs
    - hostPath:
        path: /var/lib/minikube/etcd
        type: DirectoryOrCreate
      name: etcd-data
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:35:54Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:35:51Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:06Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:06Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:35:51Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://0a3ab4780b820e88ef427ca781ac02462eb03af3684fae9115af182ee8d22d06
      image: registry.k8s.io/etcd:3.5.12-0
      imageID: docker-pullable://registry.k8s.io/etcd@sha256:44a8e24dcbba3470ee1fee21d5e88d128c936e9b55d4bc51fbef8086f8ed123b
      lastState: {}
      name: etcd
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2024-12-23T13:35:53Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 192.168.49.2
    podIPs:
    - ip: 192.168.49.2
    qosClass: Burstable
    startTime: "2024-12-23T13:35:51Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubeadm.kubernetes.io/kube-apiserver.advertise-address.endpoint: 192.168.49.2:8443
      kubernetes.io/config.hash: 3c555f828409b009ebee39fdbedfcac0
      kubernetes.io/config.mirror: 3c555f828409b009ebee39fdbedfcac0
      kubernetes.io/config.seen: "2024-07-09T13:40:18.289187153Z"
      kubernetes.io/config.source: file
    creationTimestamp: "2024-07-09T13:40:18Z"
    labels:
      component: kube-apiserver
      tier: control-plane
    name: kube-apiserver-minikube
    namespace: kube-system
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: minikube
      uid: 7e880626-2fba-4056-9d97-bf62046162bc
    resourceVersion: "22846733"
    uid: 6fdff87a-d709-46b1-890e-935ac3f8aa21
  spec:
    containers:
    - command:
      - kube-apiserver
      - --advertise-address=192.168.49.2
      - --allow-privileged=true
      - --authorization-mode=Node,RBAC
      - --client-ca-file=/var/lib/minikube/certs/ca.crt
      - --enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota
      - --enable-bootstrap-token-auth=true
      - --etcd-cafile=/var/lib/minikube/certs/etcd/ca.crt
      - --etcd-certfile=/var/lib/minikube/certs/apiserver-etcd-client.crt
      - --etcd-keyfile=/var/lib/minikube/certs/apiserver-etcd-client.key
      - --etcd-servers=https://127.0.0.1:2379
      - --kubelet-client-certificate=/var/lib/minikube/certs/apiserver-kubelet-client.crt
      - --kubelet-client-key=/var/lib/minikube/certs/apiserver-kubelet-client.key
      - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
      - --proxy-client-cert-file=/var/lib/minikube/certs/front-proxy-client.crt
      - --proxy-client-key-file=/var/lib/minikube/certs/front-proxy-client.key
      - --requestheader-allowed-names=front-proxy-client
      - --requestheader-client-ca-file=/var/lib/minikube/certs/front-proxy-ca.crt
      - --requestheader-extra-headers-prefix=X-Remote-Extra-
      - --requestheader-group-headers=X-Remote-Group
      - --requestheader-username-headers=X-Remote-User
      - --secure-port=8443
      - --service-account-issuer=https://kubernetes.default.svc.cluster.local
      - --service-account-key-file=/var/lib/minikube/certs/sa.pub
      - --service-account-signing-key-file=/var/lib/minikube/certs/sa.key
      - --service-cluster-ip-range=10.96.0.0/12
      - --tls-cert-file=/var/lib/minikube/certs/apiserver.crt
      - --tls-private-key-file=/var/lib/minikube/certs/apiserver.key
      image: registry.k8s.io/kube-apiserver:v1.30.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 192.168.49.2
          path: /livez
          port: 8443
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: kube-apiserver
      readinessProbe:
        failureThreshold: 3
        httpGet:
          host: 192.168.49.2
          path: /readyz
          port: 8443
          scheme: HTTPS
        periodSeconds: 1
        successThreshold: 1
        timeoutSeconds: 15
      resources:
        requests:
          cpu: 250m
      startupProbe:
        failureThreshold: 24
        httpGet:
          host: 192.168.49.2
          path: /livez
          port: 8443
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/ssl/certs
        name: ca-certs
        readOnly: true
      - mountPath: /etc/ca-certificates
        name: etc-ca-certificates
        readOnly: true
      - mountPath: /var/lib/minikube/certs
        name: k8s-certs
        readOnly: true
      - mountPath: /usr/local/share/ca-certificates
        name: usr-local-share-ca-certificates
        readOnly: true
      - mountPath: /usr/share/ca-certificates
        name: usr-share-ca-certificates
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      seccompProfile:
        type: RuntimeDefault
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/ssl/certs
        type: DirectoryOrCreate
      name: ca-certs
    - hostPath:
        path: /etc/ca-certificates
        type: DirectoryOrCreate
      name: etc-ca-certificates
    - hostPath:
        path: /var/lib/minikube/certs
        type: DirectoryOrCreate
      name: k8s-certs
    - hostPath:
        path: /usr/local/share/ca-certificates
        type: DirectoryOrCreate
      name: usr-local-share-ca-certificates
    - hostPath:
        path: /usr/share/ca-certificates
        type: DirectoryOrCreate
      name: usr-share-ca-certificates
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:35:54Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:35:51Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-02-07T06:55:50Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-02-07T06:55:50Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:35:51Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://d1fdfba6891ad247f3f940c9892cdc365d530effc5b5b3b7c37270ab40f5dfa7
      image: registry.k8s.io/kube-apiserver:v1.30.0
      imageID: docker-pullable://registry.k8s.io/kube-apiserver@sha256:6b8e197b2d39c321189a475ac755a77896e34b56729425590fbc99f3a96468a3
      lastState: {}
      name: kube-apiserver
      ready: true
      restartCount: 8
      started: true
      state:
        running:
          startedAt: "2024-12-23T13:35:53Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 192.168.49.2
    podIPs:
    - ip: 192.168.49.2
    qosClass: Burstable
    startTime: "2024-12-23T13:35:51Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: 7fd44e8d11c3e0ffe6b1825e2a1f2270
      kubernetes.io/config.mirror: 7fd44e8d11c3e0ffe6b1825e2a1f2270
      kubernetes.io/config.seen: "2024-07-09T13:40:18.289188953Z"
      kubernetes.io/config.source: file
    creationTimestamp: "2024-07-09T13:40:18Z"
    labels:
      component: kube-controller-manager
      tier: control-plane
    name: kube-controller-manager-minikube
    namespace: kube-system
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: minikube
      uid: 7e880626-2fba-4056-9d97-bf62046162bc
    resourceVersion: "17862520"
    uid: ed307a3d-bd6d-4147-aecb-fb3757efc3b6
  spec:
    containers:
    - command:
      - kube-controller-manager
      - --allocate-node-cidrs=true
      - --authentication-kubeconfig=/etc/kubernetes/controller-manager.conf
      - --authorization-kubeconfig=/etc/kubernetes/controller-manager.conf
      - --bind-address=127.0.0.1
      - --client-ca-file=/var/lib/minikube/certs/ca.crt
      - --cluster-cidr=10.244.0.0/16
      - --cluster-name=mk
      - --cluster-signing-cert-file=/var/lib/minikube/certs/ca.crt
      - --cluster-signing-key-file=/var/lib/minikube/certs/ca.key
      - --controllers=*,bootstrapsigner,tokencleaner
      - --kubeconfig=/etc/kubernetes/controller-manager.conf
      - --leader-elect=false
      - --requestheader-client-ca-file=/var/lib/minikube/certs/front-proxy-ca.crt
      - --root-ca-file=/var/lib/minikube/certs/ca.crt
      - --service-account-private-key-file=/var/lib/minikube/certs/sa.key
      - --service-cluster-ip-range=10.96.0.0/12
      - --use-service-account-credentials=true
      image: registry.k8s.io/kube-controller-manager:v1.30.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10257
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: kube-controller-manager
      resources:
        requests:
          cpu: 200m
      startupProbe:
        failureThreshold: 24
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10257
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/ssl/certs
        name: ca-certs
        readOnly: true
      - mountPath: /etc/ca-certificates
        name: etc-ca-certificates
        readOnly: true
      - mountPath: /usr/libexec/kubernetes/kubelet-plugins/volume/exec
        name: flexvolume-dir
      - mountPath: /var/lib/minikube/certs
        name: k8s-certs
        readOnly: true
      - mountPath: /etc/kubernetes/controller-manager.conf
        name: kubeconfig
        readOnly: true
      - mountPath: /usr/local/share/ca-certificates
        name: usr-local-share-ca-certificates
        readOnly: true
      - mountPath: /usr/share/ca-certificates
        name: usr-share-ca-certificates
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      seccompProfile:
        type: RuntimeDefault
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/ssl/certs
        type: DirectoryOrCreate
      name: ca-certs
    - hostPath:
        path: /etc/ca-certificates
        type: DirectoryOrCreate
      name: etc-ca-certificates
    - hostPath:
        path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec
        type: DirectoryOrCreate
      name: flexvolume-dir
    - hostPath:
        path: /var/lib/minikube/certs
        type: DirectoryOrCreate
      name: k8s-certs
    - hostPath:
        path: /etc/kubernetes/controller-manager.conf
        type: FileOrCreate
      name: kubeconfig
    - hostPath:
        path: /usr/local/share/ca-certificates
        type: DirectoryOrCreate
      name: usr-local-share-ca-certificates
    - hostPath:
        path: /usr/share/ca-certificates
        type: DirectoryOrCreate
      name: usr-share-ca-certificates
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:35:54Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:35:51Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:10Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:10Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:35:51Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://733fb3374b492c16fbcb167d80e370c61a1eff9e1c0b896de45901d3292a0763
      image: registry.k8s.io/kube-controller-manager:v1.30.0
      imageID: docker-pullable://registry.k8s.io/kube-controller-manager@sha256:5f52f00f17d5784b5ca004dffca59710fa1a9eec8d54cebdf9433a1d134150fe
      lastState: {}
      name: kube-controller-manager
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2024-12-23T13:35:53Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 192.168.49.2
    podIPs:
    - ip: 192.168.49.2
    qosClass: Burstable
    startTime: "2024-12-23T13:35:51Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2024-12-27T00:21:25+09:00"
    creationTimestamp: "2024-12-26T15:21:25Z"
    generateName: kube-proxy-
    labels:
      controller-revision-hash: 5bdbbccbb4
      k8s-app: kube-proxy
      pod-template-generation: "2"
    name: kube-proxy-gjl8f
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: kube-proxy
      uid: d756443e-6a19-4edf-b116-4adb6849d6ec
    resourceVersion: "18212153"
    uid: acb675f9-4d73-4baf-a684-437ff9561ed0
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - minikube
    containers:
    - command:
      - /usr/local/bin/kube-proxy
      - --config=/var/lib/kube-proxy/config.conf
      - --hostname-override=$(NODE_NAME)
      env:
      - name: NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: registry.k8s.io/kube-proxy:v1.30.0
      imagePullPolicy: IfNotPresent
      name: kube-proxy
      resources: {}
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/kube-proxy
        name: kube-proxy
      - mountPath: /run/xtables.lock
        name: xtables-lock
      - mountPath: /lib/modules
        name: lib-modules
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-wfbz4
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: minikube
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kube-proxy
    serviceAccountName: kube-proxy
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: kube-proxy
      name: kube-proxy
    - hostPath:
        path: /run/xtables.lock
        type: FileOrCreate
      name: xtables-lock
    - hostPath:
        path: /lib/modules
        type: ""
      name: lib-modules
    - name: kube-api-access-wfbz4
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-12-26T15:21:27Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-12-26T15:21:26Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-12-26T15:21:27Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-12-26T15:21:27Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-12-26T15:21:25Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://ee072d20a8e78691dfec40f42d435853b62dd7549bd4b74c23d7b78c20a79667
      image: registry.k8s.io/kube-proxy:v1.30.0
      imageID: docker-pullable://registry.k8s.io/kube-proxy@sha256:ec532ff47eaf39822387e51ec73f1f2502eb74658c6303319db88d2c380d0210
      lastState: {}
      name: kube-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-12-26T15:21:27Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 192.168.49.2
    podIPs:
    - ip: 192.168.49.2
    qosClass: BestEffort
    startTime: "2024-12-26T15:21:26Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubernetes.io/config.hash: f9c8e1d0d74b1727abdb4b4a31d3a7c1
      kubernetes.io/config.mirror: f9c8e1d0d74b1727abdb4b4a31d3a7c1
      kubernetes.io/config.seen: "2024-07-09T13:40:18.289190253Z"
      kubernetes.io/config.source: file
    creationTimestamp: "2024-07-09T13:40:18Z"
    labels:
      component: kube-scheduler
      tier: control-plane
    name: kube-scheduler-minikube
    namespace: kube-system
    ownerReferences:
    - apiVersion: v1
      controller: true
      kind: Node
      name: minikube
      uid: 7e880626-2fba-4056-9d97-bf62046162bc
    resourceVersion: "17862455"
    uid: ef628b86-077c-4960-ac21-2ded754a9da1
  spec:
    containers:
    - command:
      - kube-scheduler
      - --authentication-kubeconfig=/etc/kubernetes/scheduler.conf
      - --authorization-kubeconfig=/etc/kubernetes/scheduler.conf
      - --bind-address=127.0.0.1
      - --kubeconfig=/etc/kubernetes/scheduler.conf
      - --leader-elect=false
      image: registry.k8s.io/kube-scheduler:v1.30.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 8
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10259
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      name: kube-scheduler
      resources:
        requests:
          cpu: 100m
      startupProbe:
        failureThreshold: 24
        httpGet:
          host: 127.0.0.1
          path: /healthz
          port: 10259
          scheme: HTTPS
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 15
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/kubernetes/scheduler.conf
        name: kubeconfig
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      seccompProfile:
        type: RuntimeDefault
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      operator: Exists
    volumes:
    - hostPath:
        path: /etc/kubernetes/scheduler.conf
        type: FileOrCreate
      name: kubeconfig
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:35:54Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:35:51Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:11Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:11Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:35:51Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://a646c274231dcc4e75a7a0e4e3f0ae3d96194a1b28306969095d340853c82891
      image: registry.k8s.io/kube-scheduler:v1.30.0
      imageID: docker-pullable://registry.k8s.io/kube-scheduler@sha256:2353c3a1803229970fcb571cffc9b2f120372350e01c7381b4b650c4a02b9d67
      lastState: {}
      name: kube-scheduler
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2024-12-23T13:35:53Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 192.168.49.2
    podIPs:
    - ip: 192.168.49.2
    qosClass: Burstable
    startTime: "2024-12-23T13:35:51Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2024-12-23T22:43:40+09:00"
    creationTimestamp: "2024-12-23T13:43:41Z"
    generateName: metrics-server-fc9f6bcf6-
    labels:
      k8s-app: metrics-server
      pod-template-hash: fc9f6bcf6
    name: metrics-server-fc9f6bcf6-dxnww
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: metrics-server-fc9f6bcf6
      uid: cb6b57e2-b4d4-49ea-ba45-d064dd1c87b1
    resourceVersion: "22846834"
    uid: 69d9ee34-7e6c-47b4-9c11-69fe376eb66d
  spec:
    containers:
    - args:
      - --cert-dir=/tmp
      - --secure-port=10250
      - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
      - --kubelet-use-node-status-port
      - --metric-resolution=15s
      - --kubelet-insecure-tls
      - --kubelet-preferred-address-types=InternalIP
      image: registry.k8s.io/metrics-server/metrics-server:v0.7.2
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /livez
          port: https
          scheme: HTTPS
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: metrics-server
      ports:
      - containerPort: 10250
        name: https
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /readyz
          port: https
          scheme: HTTPS
        initialDelaySeconds: 20
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
        runAsNonRoot: true
        runAsUser: 1000
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp
        name: tmp-dir
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-42jnx
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: minikube
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: metrics-server
    serviceAccountName: metrics-server
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir: {}
      name: tmp-dir
    - name: kube-api-access-42jnx
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:43:43Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:43:41Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-02-07T06:56:21Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-02-07T06:56:21Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:43:41Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://a56cb4ab6a98efb79987887a5bf67a7357ef51835e825322d820ecf5df770e3a
      image: registry.k8s.io/metrics-server/metrics-server:v0.7.2
      imageID: docker-pullable://registry.k8s.io/metrics-server/metrics-server@sha256:ffcb2bf004d6aa0a17d90e0247cf94f2865c8901dcab4427034c341951c239f9
      lastState: {}
      name: metrics-server
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-12-23T13:43:42Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 10.244.1.149
    podIPs:
    - ip: 10.244.1.149
    qosClass: Burstable
    startTime: "2024-12-23T13:43:41Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Pod","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","integration-test":"storage-provisioner"},"name":"storage-provisioner","namespace":"kube-system"},"spec":{"containers":[{"command":["/storage-provisioner"],"image":"gcr.io/k8s-minikube/storage-provisioner:v5","imagePullPolicy":"IfNotPresent","name":"storage-provisioner","volumeMounts":[{"mountPath":"/tmp","name":"tmp"}]}],"hostNetwork":true,"serviceAccountName":"storage-provisioner","volumes":[{"hostPath":{"path":"/tmp","type":"Directory"},"name":"tmp"}]}}
    creationTimestamp: "2024-07-09T13:40:19Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      integration-test: storage-provisioner
    name: storage-provisioner
    namespace: kube-system
    resourceVersion: "22856106"
    uid: fba73234-9d59-4ecf-92ca-284e15ff1d1a
  spec:
    containers:
    - command:
      - /storage-provisioner
      image: gcr.io/k8s-minikube/storage-provisioner:v5
      imagePullPolicy: IfNotPresent
      name: storage-provisioner
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp
        name: tmp
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-2qnqx
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: storage-provisioner
    serviceAccountName: storage-provisioner
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - hostPath:
        path: /tmp
        type: Directory
      name: tmp
    - name: kube-api-access-2qnqx
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:17Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-07-09T13:40:31Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-02-07T09:00:47Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-02-07T09:00:47Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-07-09T13:40:31Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://2856f8220f8dacb99e9011ab22598f16582775badf8cfbe202f4c008281feca3
      image: gcr.io/k8s-minikube/storage-provisioner:v5
      imageID: docker-pullable://gcr.io/k8s-minikube/storage-provisioner@sha256:18eb69d1418e854ad5a19e399310e52808a8321e4c441c1dddad8977a0d7a944
      lastState:
        terminated:
          containerID: docker://bc97325fcc1a0021984d910c619e2e9dae4500aa47da1102c26c293c3815c4cf
          exitCode: 255
          finishedAt: "2025-02-07T09:00:46Z"
          reason: Error
          startedAt: "2025-02-07T06:55:56Z"
      name: storage-provisioner
      ready: true
      restartCount: 16
      started: true
      state:
        running:
          startedAt: "2025-02-07T09:00:47Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 192.168.49.2
    podIPs:
    - ip: 192.168.49.2
    qosClass: BestEffort
    startTime: "2024-07-09T13:40:31Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      seccomp.security.alpha.kubernetes.io/pod: runtime/default
    creationTimestamp: "2024-08-01T14:13:41Z"
    generateName: dashboard-metrics-scraper-b5fc48f67-
    labels:
      k8s-app: dashboard-metrics-scraper
      pod-template-hash: b5fc48f67
    name: dashboard-metrics-scraper-b5fc48f67-clj9t
    namespace: kubernetes-dashboard
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: dashboard-metrics-scraper-b5fc48f67
      uid: 7a05aea7-c992-44c2-b06c-56a5f52e87f5
    resourceVersion: "17862488"
    uid: 8a3d832d-5ec1-4593-9a52-76e076e55d64
  spec:
    containers:
    - image: docker.io/kubernetesui/metrics-scraper:v1.0.8@sha256:76049887f07a0476dc93efc2d3569b9529bf982b22d29f356092ce206e98765c
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /
          port: 8000
          scheme: HTTP
        initialDelaySeconds: 30
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 30
      name: dashboard-metrics-scraper
      ports:
      - containerPort: 8000
        protocol: TCP
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        readOnlyRootFilesystem: true
        runAsGroup: 2001
        runAsUser: 1001
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp
        name: tmp-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-k76jw
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: minikube
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kubernetes-dashboard
    serviceAccountName: kubernetes-dashboard
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir: {}
      name: tmp-volume
    - name: kube-api-access-k76jw
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:17Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-08-01T14:13:41Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:17Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:17Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-08-01T14:13:41Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://8b1064e7d99bf2a055babbf05eca297a63733aa706a76b4fcd16c60011085f64
      image: sha256:115053965e86b2df4d78af78d7951b8644839d20a03820c6df59a261103315f7
      imageID: docker-pullable://kubernetesui/metrics-scraper@sha256:76049887f07a0476dc93efc2d3569b9529bf982b22d29f356092ce206e98765c
      lastState: {}
      name: dashboard-metrics-scraper
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2024-12-23T13:36:13Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 10.244.1.136
    podIPs:
    - ip: 10.244.1.136
    qosClass: BestEffort
    startTime: "2024-08-01T14:13:41Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-08-01T14:13:41Z"
    generateName: kubernetes-dashboard-779776cb65-
    labels:
      gcp-auth-skip-secret: "true"
      k8s-app: kubernetes-dashboard
      pod-template-hash: 779776cb65
    name: kubernetes-dashboard-779776cb65-pbgfk
    namespace: kubernetes-dashboard
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: kubernetes-dashboard-779776cb65
      uid: 4bce2e0f-e72e-4252-8ed3-bbfaa052e36d
    resourceVersion: "17862438"
    uid: 2030eb13-bb7a-434b-810b-33cc4d92523d
  spec:
    containers:
    - args:
      - --namespace=kubernetes-dashboard
      - --enable-skip-login
      - --disable-settings-authorizer
      image: docker.io/kubernetesui/dashboard:v2.7.0@sha256:2e500d29e9d5f4a086b908eb8dfe7ecac57d2ab09d65b24f588b1d449841ef93
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /
          port: 9090
          scheme: HTTP
        initialDelaySeconds: 30
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 30
      name: kubernetes-dashboard
      ports:
      - containerPort: 9090
        protocol: TCP
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        readOnlyRootFilesystem: true
        runAsGroup: 2001
        runAsUser: 1001
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp
        name: tmp-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-c2gl5
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: minikube
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: kubernetes-dashboard
    serviceAccountName: kubernetes-dashboard
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir: {}
      name: tmp-volume
    - name: kube-api-access-c2gl5
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:17Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-08-01T14:13:41Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:17Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:17Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-08-01T14:13:41Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://5649d80dcb016ea99bb695b3ce809ae8c2f8dfdf29c64a18c3f02d9d863ab321
      image: sha256:07655ddf2eebe5d250f7a72c25f638b27126805d61779741b4e62e69ba080558
      imageID: docker-pullable://kubernetesui/dashboard@sha256:2e500d29e9d5f4a086b908eb8dfe7ecac57d2ab09d65b24f588b1d449841ef93
      lastState: {}
      name: kubernetes-dashboard
      ready: true
      restartCount: 273
      started: true
      state:
        running:
          startedAt: "2024-12-23T13:36:09Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 10.244.1.124
    podIPs:
    - ip: 10.244.1.124
    qosClass: BestEffort
    startTime: "2024-08-01T14:13:41Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2024-07-20T09:59:49+09:00"
      prometheus.io/port: "7472"
      prometheus.io/scrape: "true"
    creationTimestamp: "2024-11-19T12:23:17Z"
    generateName: controller-776c4595bf-
    labels:
      app: metallb
      component: controller
      pod-template-hash: 776c4595bf
    name: controller-776c4595bf-pt8rd
    namespace: metallb-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: controller-776c4595bf
      uid: a4111e10-5941-485c-b675-4519b5b77da8
    resourceVersion: "17862478"
    uid: 369fbcce-b15b-4949-a63a-2e86762a1635
  spec:
    containers:
    - args:
      - --port=7472
      - --config=config
      image: quay.io/metallb/controller:v0.9.6@sha256:6932cf255dd7f06f550c7f106b9a206be95f847ab8cb77aafac7acd27def0b00
      imagePullPolicy: IfNotPresent
      name: controller
      ports:
      - containerPort: 7472
        name: monitoring
        protocol: TCP
      resources:
        limits:
          cpu: 100m
          memory: 100Mi
        requests:
          cpu: 100m
          memory: 100Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - all
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-dwqrn
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: minikube
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
      runAsUser: 65534
    serviceAccount: controller
    serviceAccountName: controller
    terminationGracePeriodSeconds: 0
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-dwqrn
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:18Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-11-19T12:23:17Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:18Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:18Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-19T12:23:17Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://84dabc0192a69a0a89d4951dbf531d503b8775ee53850e252593d427d82990d8
      image: sha256:154603634d2cc729c04cb5d63a70be3b4fc6b0a92ce93b4edd600c1b4cb5b9fd
      imageID: docker-pullable://quay.io/metallb/controller@sha256:6932cf255dd7f06f550c7f106b9a206be95f847ab8cb77aafac7acd27def0b00
      lastState: {}
      name: controller
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2024-12-23T13:36:16Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 10.244.1.143
    podIPs:
    - ip: 10.244.1.143
    qosClass: Guaranteed
    startTime: "2024-11-19T12:23:17Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      kubectl.kubernetes.io/restartedAt: "2024-07-20T09:59:49+09:00"
      prometheus.io/port: "7472"
      prometheus.io/scrape: "true"
    creationTimestamp: "2024-11-19T12:24:29Z"
    generateName: speaker-
    labels:
      app: metallb
      component: speaker
      controller-revision-hash: 5d59bc76d5
      pod-template-generation: "4"
    name: speaker-8kj8s
    namespace: metallb-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: speaker
      uid: 14c5133c-835f-4e54-a54c-7953ae91174a
    resourceVersion: "17862379"
    uid: 5f6d5d5f-e678-4104-b38a-bd4c1d235386
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - minikube
    containers:
    - args:
      - --port=7472
      - --config=config
      env:
      - name: METALLB_NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: METALLB_HOST
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.hostIP
      image: quay.io/metallb/speaker:v0.9.6@sha256:7a400205b4986acd3d2ff32c29929682b8ff8d830837aff74f787c757176fa9f
      imagePullPolicy: IfNotPresent
      name: speaker
      ports:
      - containerPort: 7472
        hostPort: 7472
        name: monitoring
        protocol: TCP
      resources:
        limits:
          cpu: 100m
          memory: 100Mi
        requests:
          cpu: 100m
          memory: 100Mi
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          add:
          - NET_ADMIN
          - NET_RAW
          - SYS_ADMIN
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-lkpxs
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: minikube
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: speaker
    serviceAccountName: speaker
    terminationGracePeriodSeconds: 0
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - name: kube-api-access-lkpxs
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:17Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-11-19T12:24:29Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:17Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:17Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-19T12:24:29Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://fccad1be9d546f225f8e366ddff682298b5ec2d136526b8840d82afedd582f3a
      image: sha256:ed8aa6340f153dd5c33eb3fae692a71f87bd462c9f63c584953f553ff5d128fe
      imageID: docker-pullable://quay.io/metallb/speaker@sha256:7a400205b4986acd3d2ff32c29929682b8ff8d830837aff74f787c757176fa9f
      lastState: {}
      name: speaker
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2024-12-23T13:36:08Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 192.168.49.2
    podIPs:
    - ip: 192.168.49.2
    qosClass: Guaranteed
    startTime: "2024-11-19T12:24:29Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      checksum/config: 8543d68a9795066423a4ce0ff28f2c56950acfa1bac20e850c016a4fd91a9300
      kubectl.kubernetes.io/restartedAt: "2024-11-04T12:52:04+09:00"
      prometheus.io/port: http-metrics
      prometheus.io/scrape: "true"
    creationTimestamp: "2024-11-04T03:52:07Z"
    generateName: loki-
    labels:
      app: loki
      apps.kubernetes.io/pod-index: "0"
      controller-revision-hash: loki-55dbb5b75c
      name: loki
      release: loki
      statefulset.kubernetes.io/pod-name: loki-0
    name: loki-0
    namespace: monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: loki
      uid: 4001f9e0-3e7a-4c2d-8314-9330e444634a
    resourceVersion: "17862382"
    uid: c2eff723-e855-47b5-bc87-de0db1b191a2
  spec:
    affinity: {}
    containers:
    - args:
      - -config.file=/etc/loki/loki.yaml
      image: grafana/loki:2.9.3
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /ready
          port: http-metrics
          scheme: HTTP
        initialDelaySeconds: 45
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: loki
      ports:
      - containerPort: 3100
        name: http-metrics
        protocol: TCP
      - containerPort: 9095
        name: grpc
        protocol: TCP
      - containerPort: 7946
        name: memberlist-port
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /ready
          port: http-metrics
          scheme: HTTP
        initialDelaySeconds: 45
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      securityContext:
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp
        name: tmp
      - mountPath: /etc/loki
        name: config
      - mountPath: /data
        name: storage
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-dl5s5
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: loki-0
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 10001
      runAsGroup: 10001
      runAsNonRoot: true
      runAsUser: 10001
    serviceAccount: loki
    serviceAccountName: loki
    subdomain: loki-headless
    terminationGracePeriodSeconds: 4800
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir: {}
      name: tmp
    - name: config
      secret:
        defaultMode: 420
        secretName: loki
    - emptyDir: {}
      name: storage
    - name: kube-api-access-dl5s5
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:18Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-11-04T03:52:07Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:38:34Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:38:34Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-04T03:52:07Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://2dc1d83bc97bb3133b118a12224868a86d2f0c223f5254241ea682d4205d1f25
      image: grafana/loki:2.9.3
      imageID: docker-pullable://grafana/loki@sha256:eb92f1a439171542fd718f929fad38c917b3cad15ec830ba4742e2ba5ab03313
      lastState: {}
      name: loki
      ready: true
      restartCount: 2
      started: true
      state:
        running:
          startedAt: "2024-12-23T13:37:32Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 10.244.1.141
    podIPs:
    - ip: 10.244.1.141
    qosClass: BestEffort
    startTime: "2024-11-04T03:52:07Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      checksum/config: 0f49fcd7a8fab642f9644e0a4d67b9f2bf9ce3e2cbf1f2ebfa7a301dbd59a7e0
      kubectl.kubernetes.io/restartedAt: "2024-11-04T12:51:42+09:00"
    creationTimestamp: "2024-11-04T03:51:43Z"
    generateName: loki-promtail-
    labels:
      app.kubernetes.io/instance: loki
      app.kubernetes.io/name: promtail
      controller-revision-hash: 7df4f96869
      pod-template-generation: "2"
    name: loki-promtail-vnp95
    namespace: monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: loki-promtail
      uid: 3eb7cea9-9f93-438a-8e52-03a5ac4ba7ae
    resourceVersion: "17862472"
    uid: 18755bf8-0fe3-487f-b7ab-a075d1213b25
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - minikube
    containers:
    - args:
      - -config.file=/etc/promtail/promtail.yaml
      env:
      - name: HOSTNAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: docker.io/grafana/promtail:2.9.3
      imagePullPolicy: IfNotPresent
      name: promtail
      ports:
      - containerPort: 3101
        name: http-metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 5
        httpGet:
          path: /ready
          port: http-metrics
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/promtail
        name: config
      - mountPath: /run/promtail
        name: run
      - mountPath: /var/lib/docker/containers
        name: containers
        readOnly: true
      - mountPath: /var/log/pods
        name: pods
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-t78wn
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      runAsGroup: 0
      runAsUser: 0
    serviceAccount: loki-promtail
    serviceAccountName: loki-promtail
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoSchedule
      key: node-role.kubernetes.io/control-plane
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - name: config
      secret:
        defaultMode: 420
        secretName: loki-promtail
    - hostPath:
        path: /run/promtail
        type: ""
      name: run
    - hostPath:
        path: /var/lib/docker/containers
        type: ""
      name: containers
    - hostPath:
        path: /var/log/pods
        type: ""
      name: pods
    - name: kube-api-access-t78wn
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:17Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-11-04T03:51:43Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:40:07Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:40:07Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-11-04T03:51:43Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://0ad4ac9e5dea1de09853103179d62e275f123f737b0d7bc7c9a2967339fa0eb3
      image: grafana/promtail:2.9.3
      imageID: docker-pullable://grafana/promtail@sha256:b338a29de45ef8ffa96f882f3a36306b1e61262b2a560ff523e0e2633cccbbc4
      lastState: {}
      name: promtail
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2024-12-23T13:36:13Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 10.244.1.138
    podIPs:
    - ip: 10.244.1.138
    qosClass: BestEffort
    startTime: "2024-11-04T03:51:43Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      checksum/config: 0e9cbd0ea8e24e32f7dfca5bab17a2ba05652642f0a09a4882833ae88e4cc4a3
      checksum/sc-dashboard-provider-config: e70bf6a851099d385178a76de9757bb0bef8299da6d8443602590e44f05fdf24
      checksum/secret: 42bbcab3a67ca3daa20142f240a2eba96ec843b11984a0cdd14677477a16e751
      kubectl.kubernetes.io/default-container: grafana
      kubectl.kubernetes.io/restartedAt: "2024-12-31T15:48:25+09:00"
    creationTimestamp: "2024-12-31T06:48:26Z"
    generateName: monitoring-grafana-7cbb8f4465-
    labels:
      app.kubernetes.io/instance: monitoring
      app.kubernetes.io/name: grafana
      pod-template-hash: 7cbb8f4465
    name: monitoring-grafana-7cbb8f4465-bdg95
    namespace: monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: monitoring-grafana-7cbb8f4465
      uid: f52249c5-80f4-42d5-a4e8-f15e9cbb01a7
    resourceVersion: "18746434"
    uid: 4956e42b-cc43-4e5a-9887-0bfaed619a7b
  spec:
    automountServiceAccountToken: true
    containers:
    - env:
      - name: METHOD
        value: WATCH
      - name: LABEL
        value: grafana_dashboard
      - name: FOLDER
        value: /tmp/dashboards
      - name: RESOURCE
        value: both
      - name: REQ_USERNAME
        valueFrom:
          secretKeyRef:
            key: admin-user
            name: monitoring-grafana
      - name: REQ_PASSWORD
        valueFrom:
          secretKeyRef:
            key: admin-password
            name: monitoring-grafana
      - name: REQ_URL
        value: http://localhost:3000/api/admin/provisioning/dashboards/reload
      - name: REQ_METHOD
        value: POST
      image: quay.io/kiwigrid/k8s-sidecar:1.28.0
      imagePullPolicy: IfNotPresent
      name: grafana-sc-dashboard
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /tmp/dashboards
        name: sc-dashboard-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-2pfl4
        readOnly: true
    - env:
      - name: METHOD
        value: WATCH
      - name: LABEL
        value: grafana_datasource
      - name: FOLDER
        value: /etc/grafana/provisioning/datasources
      - name: RESOURCE
        value: both
      - name: REQ_USERNAME
        valueFrom:
          secretKeyRef:
            key: admin-user
            name: monitoring-grafana
      - name: REQ_PASSWORD
        valueFrom:
          secretKeyRef:
            key: admin-password
            name: monitoring-grafana
      - name: REQ_URL
        value: http://localhost:3000/api/admin/provisioning/datasources/reload
      - name: REQ_METHOD
        value: POST
      image: quay.io/kiwigrid/k8s-sidecar:1.28.0
      imagePullPolicy: IfNotPresent
      name: grafana-sc-datasources
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/grafana/provisioning/datasources
        name: sc-datasources-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-2pfl4
        readOnly: true
    - env:
      - name: POD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      - name: GF_SECURITY_ADMIN_USER
        valueFrom:
          secretKeyRef:
            key: admin-user
            name: monitoring-grafana
      - name: GF_SECURITY_ADMIN_PASSWORD
        valueFrom:
          secretKeyRef:
            key: admin-password
            name: monitoring-grafana
      - name: GF_PATHS_DATA
        value: /var/lib/grafana/
      - name: GF_PATHS_LOGS
        value: /var/log/grafana
      - name: GF_PATHS_PLUGINS
        value: /var/lib/grafana/plugins
      - name: GF_PATHS_PROVISIONING
        value: /etc/grafana/provisioning
      image: docker.io/grafana/grafana:11.2.2-security-01
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 10
        httpGet:
          path: /api/health
          port: 3000
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 30
      name: grafana
      ports:
      - containerPort: 3000
        name: grafana
        protocol: TCP
      - containerPort: 9094
        name: gossip-tcp
        protocol: TCP
      - containerPort: 9094
        name: gossip-udp
        protocol: UDP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /api/health
          port: 3000
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/grafana/grafana.ini
        name: config
        subPath: grafana.ini
      - mountPath: /var/lib/grafana
        name: storage
      - mountPath: /tmp/dashboards
        name: sc-dashboard-volume
      - mountPath: /etc/grafana/provisioning/dashboards/sc-dashboardproviders.yaml
        name: sc-dashboard-provider
        subPath: provider.yaml
      - mountPath: /etc/grafana/provisioning/datasources
        name: sc-datasources-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-2pfl4
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    initContainers:
    - command:
      - chown
      - -R
      - 472:472
      - /var/lib/grafana
      image: docker.io/library/busybox:1.31.1
      imagePullPolicy: IfNotPresent
      name: init-chown-data
      resources: {}
      securityContext:
        capabilities:
          add:
          - CHOWN
        runAsNonRoot: false
        runAsUser: 0
        seccompProfile:
          type: RuntimeDefault
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/lib/grafana
        name: storage
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-2pfl4
        readOnly: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 472
      runAsGroup: 472
      runAsNonRoot: true
      runAsUser: 472
    serviceAccount: monitoring-grafana
    serviceAccountName: monitoring-grafana
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: monitoring-grafana
      name: config
    - name: storage
      persistentVolumeClaim:
        claimName: monitoring-grafana
    - emptyDir: {}
      name: sc-dashboard-volume
    - configMap:
        defaultMode: 420
        name: monitoring-grafana-config-dashboards
      name: sc-dashboard-provider
    - emptyDir: {}
      name: sc-datasources-volume
    - name: kube-api-access-2pfl4
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-12-31T06:48:34Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-12-31T06:48:34Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-12-31T06:48:47Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-12-31T06:48:47Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-12-31T06:48:26Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://a06295ccdfeabb6ac60793d2d09710e5301b15329cd8854cae2d57461fb279a8
      image: grafana/grafana:11.2.2-security-01
      imageID: docker-pullable://grafana/grafana@sha256:464eac539793a183381ae198cb3bfcee137f17888ee192b8ac1ae2e867f72a9d
      lastState: {}
      name: grafana
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-12-31T06:48:35Z"
    - containerID: docker://0a41336a74bad71555343f339d65758093d0d9083377416530d4b1d9dd9655e3
      image: quay.io/kiwigrid/k8s-sidecar:1.28.0
      imageID: docker-pullable://quay.io/kiwigrid/k8s-sidecar@sha256:4166a019eeafd1f0fef4d867dc5f224f18d84ec8681dbb31f3ca258ecf07bcf2
      lastState: {}
      name: grafana-sc-dashboard
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-12-31T06:48:34Z"
    - containerID: docker://4da518e6d68fb10f73e3bb56fd35ec7dfa05710316805624fd6cfb24e66ff8f1
      image: quay.io/kiwigrid/k8s-sidecar:1.28.0
      imageID: docker-pullable://quay.io/kiwigrid/k8s-sidecar@sha256:4166a019eeafd1f0fef4d867dc5f224f18d84ec8681dbb31f3ca258ecf07bcf2
      lastState: {}
      name: grafana-sc-datasources
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-12-31T06:48:34Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    initContainerStatuses:
    - containerID: docker://0b4f0e0b59a5f1ef65dd6745a984ef219d1aa1770fd43a28c57304baa34d44c2
      image: busybox:1.31.1
      imageID: docker-pullable://busybox@sha256:95cf004f559831017cdf4628aaf1bb30133677be8702a8c5f2994629f637a209
      lastState: {}
      name: init-chown-data
      ready: true
      restartCount: 0
      started: false
      state:
        terminated:
          containerID: docker://0b4f0e0b59a5f1ef65dd6745a984ef219d1aa1770fd43a28c57304baa34d44c2
          exitCode: 0
          finishedAt: "2024-12-31T06:48:33Z"
          reason: Completed
          startedAt: "2024-12-31T06:48:33Z"
    phase: Running
    podIP: 10.244.1.177
    podIPs:
    - ip: 10.244.1.177
    qosClass: BestEffort
    startTime: "2024-12-31T06:48:26Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      checksum/config: 195883ecd2ee641260040a4479e9ef202bcac4f1146b5f55dcae7155de43bcc8
    creationTimestamp: "2024-10-21T12:53:19Z"
    generateName: prometheus-alertmanager-
    labels:
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/name: alertmanager
      apps.kubernetes.io/pod-index: "0"
      controller-revision-hash: prometheus-alertmanager-fcbc844b6
      statefulset.kubernetes.io/pod-name: prometheus-alertmanager-0
    name: prometheus-alertmanager-0
    namespace: monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: StatefulSet
      name: prometheus-alertmanager
      uid: 07a73890-ac41-4b44-9865-d76da15082c4
    resourceVersion: "17862487"
    uid: cf6fee6e-b5ff-42c9-bc24-5929825d0ce9
  spec:
    automountServiceAccountToken: true
    containers:
    - args:
      - --storage.path=/alertmanager
      - --config.file=/etc/alertmanager/alertmanager.yml
      env:
      - name: POD_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.podIP
      image: quay.io/prometheus/alertmanager:v0.27.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /
          port: http
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: alertmanager
      ports:
      - containerPort: 9093
        name: http
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /
          port: http
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      securityContext:
        runAsGroup: 65534
        runAsNonRoot: true
        runAsUser: 65534
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/alertmanager
        name: config
      - mountPath: /alertmanager
        name: storage
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-mdfh5
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostname: prometheus-alertmanager-0
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 65534
      runAsGroup: 65534
      runAsNonRoot: true
      runAsUser: 65534
    serviceAccount: prometheus-alertmanager
    serviceAccountName: prometheus-alertmanager
    subdomain: prometheus-alertmanager-headless
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: storage
      persistentVolumeClaim:
        claimName: storage-prometheus-alertmanager-0
    - configMap:
        defaultMode: 420
        name: prometheus-alertmanager
      name: config
    - name: kube-api-access-mdfh5
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:19Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-10-21T12:53:22Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:20Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:20Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-10-21T12:53:22Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://1d705a8558066503fec8291bff8362a772f68c7a93fbdb8042fdd81e318bbdb5
      image: quay.io/prometheus/alertmanager:v0.27.0
      imageID: docker-pullable://quay.io/prometheus/alertmanager@sha256:e13b6ed5cb929eeaee733479dce55e10eb3bc2e9c4586c705a4e8da41e5eacf5
      lastState: {}
      name: alertmanager
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2024-12-23T13:36:12Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 10.244.1.134
    podIPs:
    - ip: 10.244.1.134
    qosClass: BestEffort
    startTime: "2024-10-21T12:53:22Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-10-21T12:53:19Z"
    generateName: prometheus-kube-state-metrics-74cdb59bff-
    labels:
      app.kubernetes.io/component: metrics
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kube-state-metrics
      app.kubernetes.io/part-of: kube-state-metrics
      app.kubernetes.io/version: 2.13.0
      helm.sh/chart: kube-state-metrics-5.25.1
      pod-template-hash: 74cdb59bff
    name: prometheus-kube-state-metrics-74cdb59bff-z79gv
    namespace: monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: prometheus-kube-state-metrics-74cdb59bff
      uid: e4212076-aa08-43c4-9515-f7f9fde6f6b0
    resourceVersion: "22856124"
    uid: c042d250-d63d-4d9a-a545-127e89801230
  spec:
    automountServiceAccountToken: true
    containers:
    - args:
      - --port=8080
      - --resources=certificatesigningrequests,configmaps,cronjobs,daemonsets,deployments,endpoints,horizontalpodautoscalers,ingresses,jobs,leases,limitranges,mutatingwebhookconfigurations,namespaces,networkpolicies,nodes,persistentvolumeclaims,persistentvolumes,poddisruptionbudgets,pods,replicasets,replicationcontrollers,resourcequotas,secrets,services,statefulsets,storageclasses,validatingwebhookconfigurations,volumeattachments
      image: registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.13.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /livez
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 5
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: kube-state-metrics
      ports:
      - containerPort: 8080
        name: http
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /readyz
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 5
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        capabilities:
          drop:
          - ALL
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-29qnw
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 65534
      runAsGroup: 65534
      runAsNonRoot: true
      runAsUser: 65534
      seccompProfile:
        type: RuntimeDefault
    serviceAccount: prometheus-kube-state-metrics
    serviceAccountName: prometheus-kube-state-metrics
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-29qnw
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:17Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-10-21T12:53:20Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-02-07T09:00:57Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-02-07T09:00:57Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-10-21T12:53:20Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://8f3f6178b2d31eeb34e0f41fbb095835c3af9486d3743fff285eefe507005926
      image: registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.13.0
      imageID: docker-pullable://registry.k8s.io/kube-state-metrics/kube-state-metrics@sha256:639a1e2da549210adddc0391ff91e270e83f7873014aec53258462812f741e6f
      lastState:
        terminated:
          containerID: docker://6185d4196a12be3a6e53426d5fa8d62cbd6a9bd17a6b503d4164d3d7926e9098
          exitCode: 2
          finishedAt: "2025-02-07T09:00:46Z"
          reason: Error
          startedAt: "2025-02-07T06:55:56Z"
      name: kube-state-metrics
      ready: true
      restartCount: 13
      started: true
      state:
        running:
          startedAt: "2025-02-07T09:00:47Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 10.244.1.132
    podIPs:
    - ip: 10.244.1.132
    qosClass: BestEffort
    startTime: "2024-10-21T12:53:20Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
    creationTimestamp: "2024-10-21T12:53:19Z"
    generateName: prometheus-prometheus-node-exporter-
    labels:
      app.kubernetes.io/component: metrics
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: prometheus-node-exporter
      app.kubernetes.io/part-of: prometheus-node-exporter
      app.kubernetes.io/version: 1.8.2
      controller-revision-hash: 85b596c95
      helm.sh/chart: prometheus-node-exporter-4.39.0
      pod-template-generation: "1"
    name: prometheus-prometheus-node-exporter-h6ztp
    namespace: monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: prometheus-prometheus-node-exporter
      uid: c236ce51-afda-4d3d-a351-ef469759cfeb
    resourceVersion: "17862447"
    uid: de06be95-4955-4da5-acab-651e314c9146
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - minikube
    automountServiceAccountToken: false
    containers:
    - args:
      - --path.procfs=/host/proc
      - --path.sysfs=/host/sys
      - --path.rootfs=/host/root
      - --path.udev.data=/host/root/run/udev/data
      - --web.listen-address=[$(HOST_IP)]:9100
      env:
      - name: HOST_IP
        value: 0.0.0.0
      image: quay.io/prometheus/node-exporter:v1.8.2
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /
          port: 9100
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: node-exporter
      ports:
      - containerPort: 9100
        hostPort: 9100
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /
          port: 9100
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      securityContext:
        allowPrivilegeEscalation: false
        readOnlyRootFilesystem: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host/proc
        name: proc
        readOnly: true
      - mountPath: /host/sys
        name: sys
        readOnly: true
      - mountPath: /host/root
        mountPropagation: HostToContainer
        name: root
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    nodeName: minikube
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 65534
      runAsGroup: 65534
      runAsNonRoot: true
      runAsUser: 65534
    serviceAccount: prometheus-prometheus-node-exporter
    serviceAccountName: prometheus-prometheus-node-exporter
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - hostPath:
        path: /proc
        type: ""
      name: proc
    - hostPath:
        path: /sys
        type: ""
      name: sys
    - hostPath:
        path: /
        type: ""
      name: root
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:17Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-10-21T12:53:20Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:17Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:17Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-10-21T12:53:19Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://c1d805df59d8a67984a3b49a7243882fd49943e09740ff48cff261cd2cfc3d91
      image: quay.io/prometheus/node-exporter:v1.8.2
      imageID: docker-pullable://quay.io/prometheus/node-exporter@sha256:4032c6d5bfd752342c3e631c2f1de93ba6b86c41db6b167b9a35372c139e7706
      lastState: {}
      name: node-exporter
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2024-12-23T13:36:08Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 192.168.49.2
    podIPs:
    - ip: 192.168.49.2
    qosClass: BestEffort
    startTime: "2024-10-21T12:53:20Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-10-21T12:53:19Z"
    generateName: prometheus-prometheus-pushgateway-66fc55f8d-
    labels:
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: prometheus-pushgateway
      app.kubernetes.io/version: v1.9.0
      helm.sh/chart: prometheus-pushgateway-2.14.0
      pod-template-hash: 66fc55f8d
    name: prometheus-prometheus-pushgateway-66fc55f8d-js769
    namespace: monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: prometheus-prometheus-pushgateway-66fc55f8d
      uid: 430663db-2554-483d-810c-1f65e1908fd0
    resourceVersion: "17862448"
    uid: 5efc4e00-f2bd-4cc3-b5ab-ef470d6691e9
  spec:
    automountServiceAccountToken: true
    containers:
    - image: quay.io/prometheus/pushgateway:v1.9.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /-/healthy
          port: 9091
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 10
      name: pushgateway
      ports:
      - containerPort: 9091
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /-/ready
          port: 9091
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 10
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /data
        name: storage-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-mpnrn
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 65534
      runAsNonRoot: true
      runAsUser: 65534
    serviceAccount: prometheus-prometheus-pushgateway
    serviceAccountName: prometheus-prometheus-pushgateway
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - emptyDir: {}
      name: storage-volume
    - name: kube-api-access-mpnrn
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:22Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-10-21T12:53:20Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:26Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:26Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-10-21T12:53:20Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://707aebd59f47f21dd1b04ebd29daaa8523827647643c5e327f6f2037dfd60662
      image: quay.io/prometheus/pushgateway:v1.9.0
      imageID: docker-pullable://quay.io/prometheus/pushgateway@sha256:98a458415f8f5afcfd45622d289a0aa67063563bec0f90d598ebc76783571936
      lastState: {}
      name: pushgateway
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2024-12-23T13:36:16Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 10.244.1.142
    podIPs:
    - ip: 10.244.1.142
    qosClass: BestEffort
    startTime: "2024-10-21T12:53:20Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-10-21T12:53:19Z"
    generateName: prometheus-server-dd484f8d9-
    labels:
      app.kubernetes.io/component: server
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: prometheus
      app.kubernetes.io/part-of: prometheus
      app.kubernetes.io/version: v2.54.1
      helm.sh/chart: prometheus-25.27.0
      pod-template-hash: dd484f8d9
    name: prometheus-server-dd484f8d9-hlmxx
    namespace: monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: prometheus-server-dd484f8d9
      uid: f910c7f0-e328-4e55-bc71-0898c1cf528a
    resourceVersion: "17862477"
    uid: 54a95c6a-4158-4dc5-a62e-223f9f53a8c2
  spec:
    containers:
    - args:
      - --watched-dir=/etc/config
      - --listen-address=0.0.0.0:8080
      - --reload-url=http://127.0.0.1:9090/-/reload
      image: quay.io/prometheus-operator/prometheus-config-reloader:v0.76.0
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: metrics
          scheme: HTTP
        initialDelaySeconds: 2
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      name: prometheus-server-configmap-reload
      ports:
      - containerPort: 8080
        name: metrics
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /healthz
          port: metrics
          scheme: HTTP
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 1
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/config
        name: config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-c5d7l
        readOnly: true
    - args:
      - --storage.tsdb.retention.time=15d
      - --config.file=/etc/config/prometheus.yml
      - --storage.tsdb.path=/data
      - --web.console.libraries=/etc/prometheus/console_libraries
      - --web.console.templates=/etc/prometheus/consoles
      - --web.enable-lifecycle
      image: quay.io/prometheus/prometheus:v2.54.1
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 3
        httpGet:
          path: /-/healthy
          port: 9090
          scheme: HTTP
        initialDelaySeconds: 30
        periodSeconds: 15
        successThreshold: 1
        timeoutSeconds: 10
      name: prometheus-server
      ports:
      - containerPort: 9090
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /-/ready
          port: 9090
          scheme: HTTP
        initialDelaySeconds: 30
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 4
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/config
        name: config-volume
      - mountPath: /data
        name: storage-volume
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-c5d7l
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      fsGroup: 65534
      runAsGroup: 65534
      runAsNonRoot: true
      runAsUser: 65534
    serviceAccount: prometheus-server
    serviceAccountName: prometheus-server
    terminationGracePeriodSeconds: 300
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - configMap:
        defaultMode: 420
        name: prometheus-server
      name: config-volume
    - name: storage-volume
      persistentVolumeClaim:
        claimName: prometheus-server
    - name: kube-api-access-c5d7l
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:26Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-10-21T12:53:20Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:37:32Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:37:32Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-10-21T12:53:20Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://daa6cde33fbef3c353f7782c77424d0b2ac109d4975f1d2f60db7a166c253dc7
      image: quay.io/prometheus/prometheus:v2.54.1
      imageID: docker-pullable://quay.io/prometheus/prometheus@sha256:f6639335d34a77d9d9db382b92eeb7fc00934be8eae81dbc03b31cfe90411a94
      lastState: {}
      name: prometheus-server
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2024-12-23T13:36:21Z"
    - containerID: docker://54520a7df408b990c807aa4f8a96e34e296c887232f8efa05f246fcd9c02b5f8
      image: quay.io/prometheus-operator/prometheus-config-reloader:v0.76.0
      imageID: docker-pullable://quay.io/prometheus-operator/prometheus-config-reloader@sha256:3ee47d8f6eae9e3997bd928525946c4eb06d5bb82bf1da69ca743169c331c6a0
      lastState: {}
      name: prometheus-server-configmap-reload
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2024-12-23T13:36:16Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 10.244.1.144
    podIPs:
    - ip: 10.244.1.144
    qosClass: BestEffort
    startTime: "2024-10-21T12:53:20Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-08-16T13:06:18Z"
    generateName: zicdding-front-app-569d9cf59b-
    labels:
      app: front-app
      pod-template-hash: 569d9cf59b
    name: zicdding-front-app-569d9cf59b-s9dgb
    namespace: zicdding
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: zicdding-front-app-569d9cf59b
      uid: cf8b56b4-290d-4ed3-9387-49ad74b9ecce
    resourceVersion: "17862466"
    uid: bcc70d7d-11d2-49fb-9f26-a37cc59f9cd6
  spec:
    containers:
    - image: zicdding0904/zicdding-front:0.0.1
      imagePullPolicy: IfNotPresent
      name: zicdding-front-app
      ports:
      - containerPort: 3000
        protocol: TCP
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-vdqxp
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: minikube
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-vdqxp
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:17Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-08-16T13:06:18Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:17Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-12-23T13:36:17Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-08-16T13:06:18Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: docker://cb9fd5822d9b421f70bd5d845c82cec276cbaf70637dbd78fdd872d7e0426329
      image: zicdding0904/zicdding-front:0.0.1
      imageID: docker-pullable://zicdding0904/zicdding-front@sha256:2a47bc78f37efc9cd916a956b04779ca92a59261dbbdf3b76e024f7f9b7d0ac3
      lastState: {}
      name: zicdding-front-app
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2024-12-23T13:36:13Z"
    hostIP: 192.168.49.2
    hostIPs:
    - ip: 192.168.49.2
    phase: Running
    podIP: 10.244.1.135
    podIPs:
    - ip: 10.244.1.135
    qosClass: BestEffort
    startTime: "2024-08-16T13:06:18Z"
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: argocd
      meta.helm.sh/release-namespace: argocd
    creationTimestamp: "2024-07-19T17:25:51Z"
    labels:
      app.kubernetes.io/component: applicationset-controller
      app.kubernetes.io/instance: argocd
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: argocd-applicationset-controller
      app.kubernetes.io/part-of: argocd
      app.kubernetes.io/version: v2.11.5
      helm.sh/chart: argo-cd-7.3.9
    name: argocd-applicationset-controller
    namespace: argocd
    resourceVersion: "721819"
    uid: d7c36b04-0954-4aca-bf23-fb46c92e8f11
  spec:
    clusterIP: 10.111.105.180
    clusterIPs:
    - 10.111.105.180
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http-webhook
      port: 7000
      protocol: TCP
      targetPort: webhook
    selector:
      app.kubernetes.io/instance: argocd
      app.kubernetes.io/name: argocd-applicationset-controller
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: argocd
      meta.helm.sh/release-namespace: argocd
    creationTimestamp: "2024-07-19T17:25:51Z"
    labels:
      app.kubernetes.io/component: dex-server
      app.kubernetes.io/instance: argocd
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: argocd-dex-server
      app.kubernetes.io/part-of: argocd
      app.kubernetes.io/version: v2.11.5
      helm.sh/chart: argo-cd-7.3.9
    name: argocd-dex-server
    namespace: argocd
    resourceVersion: "721831"
    uid: e1dc61b9-b5bf-49b0-a0e2-8460152efc60
  spec:
    clusterIP: 10.103.69.14
    clusterIPs:
    - 10.103.69.14
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http
      port: 5556
      protocol: TCP
      targetPort: http
    - name: grpc
      port: 5557
      protocol: TCP
      targetPort: grpc
    selector:
      app.kubernetes.io/instance: argocd
      app.kubernetes.io/name: argocd-dex-server
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: argocd
      meta.helm.sh/release-namespace: argocd
    creationTimestamp: "2024-07-19T17:25:51Z"
    labels:
      app.kubernetes.io/component: redis
      app.kubernetes.io/instance: argocd
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: argocd-redis
      app.kubernetes.io/part-of: argocd
      app.kubernetes.io/version: v2.11.5
      helm.sh/chart: argo-cd-7.3.9
    name: argocd-redis
    namespace: argocd
    resourceVersion: "721835"
    uid: 1e9797cb-c017-47f9-8a8d-f8c1098b40e5
  spec:
    clusterIP: 10.96.217.26
    clusterIPs:
    - 10.96.217.26
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: redis
      port: 6379
      protocol: TCP
      targetPort: redis
    selector:
      app.kubernetes.io/instance: argocd
      app.kubernetes.io/name: argocd-redis
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: argocd
      meta.helm.sh/release-namespace: argocd
    creationTimestamp: "2024-07-19T17:25:51Z"
    labels:
      app.kubernetes.io/component: repo-server
      app.kubernetes.io/instance: argocd
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: argocd-repo-server
      app.kubernetes.io/part-of: argocd
      app.kubernetes.io/version: v2.11.5
      helm.sh/chart: argo-cd-7.3.9
    name: argocd-repo-server
    namespace: argocd
    resourceVersion: "721823"
    uid: 82f2975a-4efd-462a-894d-66a3e05bf0f0
  spec:
    clusterIP: 10.106.78.173
    clusterIPs:
    - 10.106.78.173
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: tcp-repo-server
      port: 8081
      protocol: TCP
      targetPort: repo-server
    selector:
      app.kubernetes.io/instance: argocd
      app.kubernetes.io/name: argocd-repo-server
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: argocd
      meta.helm.sh/release-namespace: argocd
    creationTimestamp: "2024-07-19T17:25:51Z"
    labels:
      app.kubernetes.io/component: server
      app.kubernetes.io/instance: argocd
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: argocd-server
      app.kubernetes.io/part-of: argocd
      app.kubernetes.io/version: v2.11.5
      helm.sh/chart: argo-cd-7.3.9
    name: argocd-server
    namespace: argocd
    resourceVersion: "721827"
    uid: d1a10d49-dd42-49e6-b939-b3a4e930e9a3
  spec:
    clusterIP: 10.96.127.54
    clusterIPs:
    - 10.96.127.54
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http
      port: 80
      protocol: TCP
      targetPort: 8080
    - name: https
      port: 443
      protocol: TCP
      targetPort: 8080
    selector:
      app.kubernetes.io/instance: argocd
      app.kubernetes.io/name: argocd-server
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"labels":{"argocd.argoproj.io/instance":"backend"},"name":"backend-service","namespace":"backend"},"spec":{"ports":[{"nodePort":30000,"port":8080,"protocol":"TCP","targetPort":8080}],"selector":{"app":"backend"},"type":"LoadBalancer"}}
    creationTimestamp: "2024-12-26T14:41:51Z"
    labels:
      argocd.argoproj.io/instance: backend
    name: backend-service
    namespace: backend
    resourceVersion: "19414156"
    uid: 37d26829-a005-487b-b6a9-3e93836cd841
  spec:
    allocateLoadBalancerNodePorts: true
    clusterIP: 10.104.68.112
    clusterIPs:
    - 10.104.68.112
    externalTrafficPolicy: Cluster
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - nodePort: 30000
      port: 8080
      protocol: TCP
      targetPort: 8080
    selector:
      app: backend
    sessionAffinity: None
    type: LoadBalancer
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    creationTimestamp: "2024-07-09T13:40:17Z"
    labels:
      component: apiserver
      provider: kubernetes
    name: kubernetes
    namespace: default
    resourceVersion: "237"
    uid: 2d8eb4f1-94d4-4ad4-b308-628b3ecc0057
  spec:
    clusterIP: 10.96.0.1
    clusterIPs:
    - 10.96.0.1
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: https
      port: 443
      protocol: TCP
      targetPort: 8443
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"labels":{"app.kubernetes.io/component":"controller","app.kubernetes.io/instance":"ingress-nginx","app.kubernetes.io/name":"ingress-nginx"},"name":"ingress-nginx-controller","namespace":"ingress-nginx"},"spec":{"ipFamilies":["IPv4"],"ipFamilyPolicy":"SingleStack","ports":[{"appProtocol":"http","name":"http","port":80,"protocol":"TCP","targetPort":"http"},{"appProtocol":"https","name":"https","port":443,"protocol":"TCP","targetPort":"https"}],"selector":{"app.kubernetes.io/component":"controller","app.kubernetes.io/instance":"ingress-nginx","app.kubernetes.io/name":"ingress-nginx"},"type":"NodePort"}}
    creationTimestamp: "2024-08-03T05:16:32Z"
    labels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/name: ingress-nginx
    name: ingress-nginx-controller
    namespace: ingress-nginx
    resourceVersion: "1865341"
    uid: da1931aa-c841-4add-b637-0d968aa264d9
  spec:
    clusterIP: 10.106.90.192
    clusterIPs:
    - 10.106.90.192
    externalTrafficPolicy: Cluster
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - appProtocol: http
      name: http
      nodePort: 31473
      port: 80
      protocol: TCP
      targetPort: http
    - appProtocol: https
      name: https
      nodePort: 30915
      port: 443
      protocol: TCP
      targetPort: https
    selector:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/name: ingress-nginx
    sessionAffinity: None
    type: NodePort
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"labels":{"app.kubernetes.io/component":"controller","app.kubernetes.io/instance":"ingress-nginx","app.kubernetes.io/name":"ingress-nginx"},"name":"ingress-nginx-controller-admission","namespace":"ingress-nginx"},"spec":{"ports":[{"appProtocol":"https","name":"https-webhook","port":443,"targetPort":"webhook"}],"selector":{"app.kubernetes.io/component":"controller","app.kubernetes.io/instance":"ingress-nginx","app.kubernetes.io/name":"ingress-nginx"},"type":"ClusterIP"}}
    creationTimestamp: "2024-08-03T05:16:32Z"
    labels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/name: ingress-nginx
    name: ingress-nginx-controller-admission
    namespace: ingress-nginx
    resourceVersion: "1865345"
    uid: af73160f-f219-46e3-b1b7-af1446b198a2
  spec:
    clusterIP: 10.98.130.159
    clusterIPs:
    - 10.98.130.159
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - appProtocol: https
      name: https-webhook
      port: 443
      protocol: TCP
      targetPort: webhook
    selector:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/name: ingress-nginx
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: nginx-ingress
      meta.helm.sh/release-namespace: ingress-nginx
    creationTimestamp: "2024-07-20T01:14:48Z"
    labels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: nginx-ingress
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: ingress-nginx
      app.kubernetes.io/part-of: ingress-nginx
      app.kubernetes.io/version: 1.11.1
      helm.sh/chart: ingress-nginx-4.11.1
    name: nginx-ingress-ingress-nginx-controller
    namespace: ingress-nginx
    resourceVersion: "18788207"
    uid: 0db0d997-50ad-469c-89e4-708eee029ad2
  spec:
    allocateLoadBalancerNodePorts: true
    clusterIP: 10.99.135.168
    clusterIPs:
    - 10.99.135.168
    externalTrafficPolicy: Local
    healthCheckNodePort: 31352
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - appProtocol: http
      name: http
      nodePort: 30307
      port: 80
      protocol: TCP
      targetPort: http
    - appProtocol: https
      name: https
      nodePort: 31827
      port: 443
      protocol: TCP
      targetPort: https
    selector:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: nginx-ingress
      app.kubernetes.io/name: ingress-nginx
    sessionAffinity: None
    type: LoadBalancer
  status:
    loadBalancer:
      ingress:
      - ip: 192.168.0.9
        ipMode: VIP
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: nginx-ingress
      meta.helm.sh/release-namespace: ingress-nginx
    creationTimestamp: "2024-07-20T01:14:48Z"
    labels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: nginx-ingress
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: ingress-nginx
      app.kubernetes.io/part-of: ingress-nginx
      app.kubernetes.io/version: 1.11.1
      helm.sh/chart: ingress-nginx-4.11.1
    name: nginx-ingress-ingress-nginx-controller-admission
    namespace: ingress-nginx
    resourceVersion: "764482"
    uid: 58fedf18-6c29-4e5d-b384-04dd4fa126f8
  spec:
    clusterIP: 10.99.143.211
    clusterIPs:
    - 10.99.143.211
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - appProtocol: https
      name: https-webhook
      port: 443
      protocol: TCP
      targetPort: webhook
    selector:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: nginx-ingress
      app.kubernetes.io/name: ingress-nginx
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      prometheus.io/port: "9153"
      prometheus.io/scrape: "true"
    creationTimestamp: "2024-07-09T13:40:18Z"
    labels:
      k8s-app: kube-dns
      kubernetes.io/cluster-service: "true"
      kubernetes.io/name: CoreDNS
    name: kube-dns
    namespace: kube-system
    resourceVersion: "280"
    uid: e73c418f-f67e-4886-b9f9-b0293d539549
  spec:
    clusterIP: 10.96.0.10
    clusterIPs:
    - 10.96.0.10
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: dns
      port: 53
      protocol: UDP
      targetPort: 53
    - name: dns-tcp
      port: 53
      protocol: TCP
      targetPort: 53
    - name: metrics
      port: 9153
      protocol: TCP
      targetPort: 9153
    selector:
      k8s-app: kube-dns
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"labels":{"k8s-app":"metrics-server"},"name":"metrics-server","namespace":"kube-system"},"spec":{"ports":[{"name":"https","port":443,"protocol":"TCP","targetPort":"https"}],"selector":{"k8s-app":"metrics-server"}}}
    creationTimestamp: "2024-12-23T13:40:58Z"
    labels:
      k8s-app: metrics-server
    name: metrics-server
    namespace: kube-system
    resourceVersion: "17859731"
    uid: 892a26d6-c3de-4633-8530-ad6a44796335
  spec:
    clusterIP: 10.105.141.137
    clusterIPs:
    - 10.105.141.137
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: https
      port: 443
      protocol: TCP
      targetPort: https
    selector:
      k8s-app: metrics-server
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","k8s-app":"dashboard-metrics-scraper","kubernetes.io/minikube-addons":"dashboard"},"name":"dashboard-metrics-scraper","namespace":"kubernetes-dashboard"},"spec":{"ports":[{"port":8000,"targetPort":8000}],"selector":{"k8s-app":"dashboard-metrics-scraper"}}}
    creationTimestamp: "2024-08-01T14:13:28Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      k8s-app: dashboard-metrics-scraper
      kubernetes.io/minikube-addons: dashboard
    name: dashboard-metrics-scraper
    namespace: kubernetes-dashboard
    resourceVersion: "1729596"
    uid: aa816ef8-efc8-4186-b8a9-e7871da4a2d4
  spec:
    clusterIP: 10.101.162.186
    clusterIPs:
    - 10.101.162.186
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - port: 8000
      protocol: TCP
      targetPort: 8000
    selector:
      k8s-app: dashboard-metrics-scraper
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","k8s-app":"kubernetes-dashboard","kubernetes.io/minikube-addons":"dashboard"},"name":"kubernetes-dashboard","namespace":"kubernetes-dashboard"},"spec":{"ports":[{"port":80,"targetPort":9090}],"selector":{"k8s-app":"kubernetes-dashboard"}}}
    creationTimestamp: "2024-08-01T14:13:28Z"
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      k8s-app: kubernetes-dashboard
      kubernetes.io/minikube-addons: dashboard
    name: kubernetes-dashboard
    namespace: kubernetes-dashboard
    resourceVersion: "1729594"
    uid: e009490b-0a0c-4ca1-b753-03ac8f56be3f
  spec:
    clusterIP: 10.110.247.140
    clusterIPs:
    - 10.110.247.140
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - port: 80
      protocol: TCP
      targetPort: 9090
    selector:
      k8s-app: kubernetes-dashboard
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"name":"webhook-service","namespace":"metallb-system"},"spec":{"ports":[{"port":443,"targetPort":9443}],"selector":{"component":"controller"}}}
    creationTimestamp: "2024-07-19T17:40:40Z"
    name: webhook-service
    namespace: metallb-system
    resourceVersion: "722932"
    uid: 423c0b56-27c2-4f9b-b103-f72b7894defd
  spec:
    clusterIP: 10.98.188.164
    clusterIPs:
    - 10.98.188.164
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - port: 443
      protocol: TCP
      targetPort: 9443
    selector:
      component: controller
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: loki
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-10-21T12:56:07Z"
    labels:
      app: loki
      app.kubernetes.io/managed-by: Helm
      chart: loki-2.16.0
      heritage: Helm
      release: loki
    name: loki
    namespace: monitoring
    resourceVersion: "10863322"
    uid: 1cbf4d20-3b48-4cec-b55f-f474137a9a89
  spec:
    clusterIP: 10.101.98.186
    clusterIPs:
    - 10.101.98.186
    externalTrafficPolicy: Cluster
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http-metrics
      nodePort: 31683
      port: 3100
      protocol: TCP
      targetPort: http-metrics
    selector:
      app: loki
      release: loki
    sessionAffinity: None
    type: NodePort
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: loki
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-10-21T12:56:07Z"
    labels:
      app: loki
      app.kubernetes.io/managed-by: Helm
      chart: loki-2.16.0
      heritage: Helm
      release: loki
      variant: headless
    name: loki-headless
    namespace: monitoring
    resourceVersion: "10746828"
    uid: 851b73d2-3aad-4f51-b6ba-d1684773f2b3
  spec:
    clusterIP: None
    clusterIPs:
    - None
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http-metrics
      port: 3100
      protocol: TCP
      targetPort: http-metrics
    selector:
      app: loki
      release: loki
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: loki
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-10-21T12:56:07Z"
    labels:
      app: loki
      app.kubernetes.io/managed-by: Helm
      chart: loki-2.16.0
      heritage: Helm
      release: loki
    name: loki-memberlist
    namespace: monitoring
    resourceVersion: "10746827"
    uid: c91d76b1-2984-4464-9875-201a7c01fb08
  spec:
    clusterIP: None
    clusterIPs:
    - None
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http
      port: 7946
      protocol: TCP
      targetPort: memberlist-port
    publishNotReadyAddresses: true
    selector:
      app: loki
      release: loki
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"labels":{"app.kubernetes.io/instance":"monitoring","app.kubernetes.io/managed-by":"Helm","app.kubernetes.io/name":"grafana","app.kubernetes.io/version":"11.2.2-security-01","argocd.argoproj.io/instance":"monitoring","helm.sh/chart":"grafana-8.5.8"},"name":"monitoring-grafana","namespace":"monitoring"},"spec":{"ports":[{"name":"service","nodePort":32180,"port":80,"protocol":"TCP","targetPort":3000}],"selector":{"app.kubernetes.io/instance":"monitoring","app.kubernetes.io/name":"grafana"},"type":"NodePort"}}
    creationTimestamp: "2024-12-29T14:19:33Z"
    labels:
      app.kubernetes.io/instance: monitoring
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: grafana
      app.kubernetes.io/version: 11.2.2-security-01
      argocd.argoproj.io/instance: monitoring
      helm.sh/chart: grafana-8.5.8
    name: monitoring-grafana
    namespace: monitoring
    resourceVersion: "18553875"
    uid: b8c2f65e-3a58-48c8-9294-9bf59aad9556
  spec:
    clusterIP: 10.102.115.8
    clusterIPs:
    - 10.102.115.8
    externalTrafficPolicy: Cluster
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: service
      nodePort: 32180
      port: 80
      protocol: TCP
      targetPort: 3000
    selector:
      app.kubernetes.io/instance: monitoring
      app.kubernetes.io/name: grafana
    sessionAffinity: None
    type: NodePort
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-10-21T12:53:18Z"
    labels:
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: alertmanager
      app.kubernetes.io/version: v0.27.0
      helm.sh/chart: alertmanager-1.12.0
    name: prometheus-alertmanager
    namespace: monitoring
    resourceVersion: "10746369"
    uid: fc886762-3ac2-4231-b14c-008ff7bfa8ba
  spec:
    clusterIP: 10.102.71.104
    clusterIPs:
    - 10.102.71.104
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http
      port: 9093
      protocol: TCP
      targetPort: http
    selector:
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/name: alertmanager
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-10-21T12:53:18Z"
    labels:
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: alertmanager
      app.kubernetes.io/version: v0.27.0
      helm.sh/chart: alertmanager-1.12.0
    name: prometheus-alertmanager-headless
    namespace: monitoring
    resourceVersion: "10746351"
    uid: df275d6f-4b90-4f1b-a741-a4095885ac2f
  spec:
    clusterIP: None
    clusterIPs:
    - None
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http
      port: 9093
      protocol: TCP
      targetPort: http
    selector:
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/name: alertmanager
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
      prometheus.io/scrape: "true"
    creationTimestamp: "2024-10-21T12:53:18Z"
    labels:
      app.kubernetes.io/component: metrics
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kube-state-metrics
      app.kubernetes.io/part-of: kube-state-metrics
      app.kubernetes.io/version: 2.13.0
      helm.sh/chart: kube-state-metrics-5.25.1
    name: prometheus-kube-state-metrics
    namespace: monitoring
    resourceVersion: "10746377"
    uid: c94dafe4-682e-4324-9f01-210982a58e6f
  spec:
    clusterIP: 10.108.78.173
    clusterIPs:
    - 10.108.78.173
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http
      port: 8080
      protocol: TCP
      targetPort: 8080
    selector:
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/name: kube-state-metrics
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
      prometheus.io/scrape: "true"
    creationTimestamp: "2024-10-21T12:53:18Z"
    labels:
      app.kubernetes.io/component: metrics
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: prometheus-node-exporter
      app.kubernetes.io/part-of: prometheus-node-exporter
      app.kubernetes.io/version: 1.8.2
      helm.sh/chart: prometheus-node-exporter-4.39.0
    name: prometheus-prometheus-node-exporter
    namespace: monitoring
    resourceVersion: "10746363"
    uid: 8c36c781-be08-4a58-9cde-aaca23d6d503
  spec:
    clusterIP: 10.104.241.213
    clusterIPs:
    - 10.104.241.213
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: metrics
      port: 9100
      protocol: TCP
      targetPort: 9100
    selector:
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/name: prometheus-node-exporter
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
      prometheus.io/probe: pushgateway
    creationTimestamp: "2024-10-21T12:53:18Z"
    labels:
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: prometheus-pushgateway
      app.kubernetes.io/version: v1.9.0
      helm.sh/chart: prometheus-pushgateway-2.14.0
    name: prometheus-prometheus-pushgateway
    namespace: monitoring
    resourceVersion: "10746378"
    uid: 28681c47-263d-410a-b5d1-bfcfd8fb8156
  spec:
    clusterIP: 10.107.51.42
    clusterIPs:
    - 10.107.51.42
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http
      port: 9091
      protocol: TCP
      targetPort: 9091
    selector:
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/name: prometheus-pushgateway
    sessionAffinity: None
    type: ClusterIP
  status:
    loadBalancer: {}
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-10-21T12:53:18Z"
    labels:
      app.kubernetes.io/component: server
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: prometheus
      app.kubernetes.io/part-of: prometheus
      app.kubernetes.io/version: v2.54.1
      helm.sh/chart: prometheus-25.27.0
    name: prometheus-server
    namespace: monitoring
    resourceVersion: "18788212"
    uid: 39b800df-e83c-442d-9ae7-4807fcd66513
  spec:
    allocateLoadBalancerNodePorts: true
    clusterIP: 10.111.230.8
    clusterIPs:
    - 10.111.230.8
    externalTrafficPolicy: Cluster
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - name: http
      nodePort: 30238
      port: 80
      protocol: TCP
      targetPort: 9090
    selector:
      app.kubernetes.io/component: server
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/name: prometheus
    sessionAffinity: None
    type: LoadBalancer
  status:
    loadBalancer:
      ingress:
      - ip: 192.168.0.10
        ipMode: VIP
- apiVersion: v1
  kind: Service
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"labels":{"argocd.argoproj.io/instance":"zicdding-front-app"},"name":"front-app","namespace":"zicdding"},"spec":{"ports":[{"nodePort":31000,"port":3000,"protocol":"TCP","targetPort":3000}],"selector":{"app":"front-app"},"type":"LoadBalancer"}}
    creationTimestamp: "2024-08-16T13:06:18Z"
    labels:
      argocd.argoproj.io/instance: zicdding-front-app
    name: front-app
    namespace: zicdding
    resourceVersion: "18788213"
    uid: 4ba42b4e-e169-4e2f-b511-ddebd546a293
  spec:
    allocateLoadBalancerNodePorts: true
    clusterIP: 10.99.80.136
    clusterIPs:
    - 10.99.80.136
    externalTrafficPolicy: Cluster
    internalTrafficPolicy: Cluster
    ipFamilies:
    - IPv4
    ipFamilyPolicy: SingleStack
    ports:
    - nodePort: 31000
      port: 3000
      protocol: TCP
      targetPort: 3000
    selector:
      app: front-app
    sessionAffinity: None
    type: LoadBalancer
  status:
    loadBalancer: {}
- apiVersion: apps/v1
  kind: DaemonSet
  metadata:
    annotations:
      deprecated.daemonset.template.generation: "2"
    creationTimestamp: "2024-07-09T13:40:18Z"
    generation: 2
    labels:
      k8s-app: kube-proxy
    name: kube-proxy
    namespace: kube-system
    resourceVersion: "18212154"
    uid: d756443e-6a19-4edf-b116-4adb6849d6ec
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: kube-proxy
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2024-12-27T00:21:25+09:00"
        creationTimestamp: null
        labels:
          k8s-app: kube-proxy
      spec:
        containers:
        - command:
          - /usr/local/bin/kube-proxy
          - --config=/var/lib/kube-proxy/config.conf
          - --hostname-override=$(NODE_NAME)
          env:
          - name: NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          image: registry.k8s.io/kube-proxy:v1.30.0
          imagePullPolicy: IfNotPresent
          name: kube-proxy
          resources: {}
          securityContext:
            privileged: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/lib/kube-proxy
            name: kube-proxy
          - mountPath: /run/xtables.lock
            name: xtables-lock
          - mountPath: /lib/modules
            name: lib-modules
            readOnly: true
        dnsPolicy: ClusterFirst
        hostNetwork: true
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-node-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: kube-proxy
        serviceAccountName: kube-proxy
        terminationGracePeriodSeconds: 30
        tolerations:
        - operator: Exists
        volumes:
        - configMap:
            defaultMode: 420
            name: kube-proxy
          name: kube-proxy
        - hostPath:
            path: /run/xtables.lock
            type: FileOrCreate
          name: xtables-lock
        - hostPath:
            path: /lib/modules
            type: ""
          name: lib-modules
    updateStrategy:
      rollingUpdate:
        maxSurge: 0
        maxUnavailable: 1
      type: RollingUpdate
  status:
    currentNumberScheduled: 1
    desiredNumberScheduled: 1
    numberAvailable: 1
    numberMisscheduled: 0
    numberReady: 1
    observedGeneration: 2
    updatedNumberScheduled: 1
- apiVersion: apps/v1
  kind: DaemonSet
  metadata:
    annotations:
      deprecated.daemonset.template.generation: "4"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"DaemonSet","metadata":{"annotations":{},"labels":{"app":"metallb","component":"speaker"},"name":"speaker","namespace":"metallb-system"},"spec":{"selector":{"matchLabels":{"app":"metallb","component":"speaker"}},"template":{"metadata":{"annotations":{"prometheus.io/port":"7472","prometheus.io/scrape":"true"},"labels":{"app":"metallb","component":"speaker"}},"spec":{"containers":[{"args":["--port=7472","--config=config"],"env":[{"name":"METALLB_NODE_NAME","valueFrom":{"fieldRef":{"fieldPath":"spec.nodeName"}}},{"name":"METALLB_HOST","valueFrom":{"fieldRef":{"fieldPath":"status.hostIP"}}}],"image":"quay.io/metallb/speaker:v0.9.6@sha256:7a400205b4986acd3d2ff32c29929682b8ff8d830837aff74f787c757176fa9f","imagePullPolicy":"IfNotPresent","name":"speaker","ports":[{"containerPort":7472,"name":"monitoring"}],"resources":{"limits":{"cpu":"100m","memory":"100Mi"}},"securityContext":{"allowPrivilegeEscalation":false,"capabilities":{"add":["NET_ADMIN","NET_RAW","SYS_ADMIN"],"drop":["ALL"]},"readOnlyRootFilesystem":true}}],"hostNetwork":true,"nodeSelector":{"kubernetes.io/os":"linux"},"serviceAccountName":"speaker","terminationGracePeriodSeconds":0,"tolerations":[{"effect":"NoSchedule","key":"node-role.kubernetes.io/master"}]}}}}
    creationTimestamp: "2024-07-19T17:40:40Z"
    generation: 4
    labels:
      app: metallb
      component: speaker
    name: speaker
    namespace: metallb-system
    resourceVersion: "15278097"
    uid: 14c5133c-835f-4e54-a54c-7953ae91174a
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: metallb
        component: speaker
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2024-07-20T09:59:49+09:00"
          prometheus.io/port: "7472"
          prometheus.io/scrape: "true"
        creationTimestamp: null
        labels:
          app: metallb
          component: speaker
      spec:
        containers:
        - args:
          - --port=7472
          - --config=config
          env:
          - name: METALLB_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: METALLB_HOST
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.hostIP
          image: quay.io/metallb/speaker:v0.9.6@sha256:7a400205b4986acd3d2ff32c29929682b8ff8d830837aff74f787c757176fa9f
          imagePullPolicy: IfNotPresent
          name: speaker
          ports:
          - containerPort: 7472
            name: monitoring
            protocol: TCP
          resources:
            limits:
              cpu: 100m
              memory: 100Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              add:
              - NET_ADMIN
              - NET_RAW
              - SYS_ADMIN
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        hostNetwork: true
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: speaker
        serviceAccountName: speaker
        terminationGracePeriodSeconds: 0
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
    updateStrategy:
      rollingUpdate:
        maxSurge: 0
        maxUnavailable: 1
      type: RollingUpdate
  status:
    currentNumberScheduled: 1
    desiredNumberScheduled: 1
    numberAvailable: 1
    numberMisscheduled: 0
    numberReady: 1
    observedGeneration: 4
    updatedNumberScheduled: 1
- apiVersion: apps/v1
  kind: DaemonSet
  metadata:
    annotations:
      deprecated.daemonset.template.generation: "2"
      meta.helm.sh/release-name: loki
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-10-21T12:56:07Z"
    generation: 2
    labels:
      app.kubernetes.io/instance: loki
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: promtail
      app.kubernetes.io/version: 2.9.3
      helm.sh/chart: promtail-6.15.5
    name: loki-promtail
    namespace: monitoring
    resourceVersion: "17859635"
    uid: 3eb7cea9-9f93-438a-8e52-03a5ac4ba7ae
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/instance: loki
        app.kubernetes.io/name: promtail
    template:
      metadata:
        annotations:
          checksum/config: 0f49fcd7a8fab642f9644e0a4d67b9f2bf9ce3e2cbf1f2ebfa7a301dbd59a7e0
          kubectl.kubernetes.io/restartedAt: "2024-11-04T12:51:42+09:00"
        creationTimestamp: null
        labels:
          app.kubernetes.io/instance: loki
          app.kubernetes.io/name: promtail
      spec:
        containers:
        - args:
          - -config.file=/etc/promtail/promtail.yaml
          env:
          - name: HOSTNAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          image: docker.io/grafana/promtail:2.9.3
          imagePullPolicy: IfNotPresent
          name: promtail
          ports:
          - containerPort: 3101
            name: http-metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 5
            httpGet:
              path: /ready
              port: http-metrics
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/promtail
            name: config
          - mountPath: /run/promtail
            name: run
          - mountPath: /var/lib/docker/containers
            name: containers
            readOnly: true
          - mountPath: /var/log/pods
            name: pods
            readOnly: true
        dnsPolicy: ClusterFirst
        enableServiceLinks: true
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          runAsGroup: 0
          runAsUser: 0
        serviceAccount: loki-promtail
        serviceAccountName: loki-promtail
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Exists
        volumes:
        - name: config
          secret:
            defaultMode: 420
            secretName: loki-promtail
        - hostPath:
            path: /run/promtail
            type: ""
          name: run
        - hostPath:
            path: /var/lib/docker/containers
            type: ""
          name: containers
        - hostPath:
            path: /var/log/pods
            type: ""
          name: pods
    updateStrategy:
      rollingUpdate:
        maxSurge: 0
        maxUnavailable: 1
      type: RollingUpdate
  status:
    currentNumberScheduled: 1
    desiredNumberScheduled: 1
    numberAvailable: 1
    numberMisscheduled: 0
    numberReady: 1
    observedGeneration: 2
    updatedNumberScheduled: 1
- apiVersion: apps/v1
  kind: DaemonSet
  metadata:
    annotations:
      deprecated.daemonset.template.generation: "1"
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-10-21T12:53:19Z"
    generation: 1
    labels:
      app.kubernetes.io/component: metrics
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: prometheus-node-exporter
      app.kubernetes.io/part-of: prometheus-node-exporter
      app.kubernetes.io/version: 1.8.2
      helm.sh/chart: prometheus-node-exporter-4.39.0
    name: prometheus-prometheus-node-exporter
    namespace: monitoring
    resourceVersion: "17859170"
    uid: c236ce51-afda-4d3d-a351-ef469759cfeb
  spec:
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/instance: prometheus
        app.kubernetes.io/name: prometheus-node-exporter
    template:
      metadata:
        annotations:
          cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: metrics
          app.kubernetes.io/instance: prometheus
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: prometheus-node-exporter
          app.kubernetes.io/part-of: prometheus-node-exporter
          app.kubernetes.io/version: 1.8.2
          helm.sh/chart: prometheus-node-exporter-4.39.0
      spec:
        automountServiceAccountToken: false
        containers:
        - args:
          - --path.procfs=/host/proc
          - --path.sysfs=/host/sys
          - --path.rootfs=/host/root
          - --path.udev.data=/host/root/run/udev/data
          - --web.listen-address=[$(HOST_IP)]:9100
          env:
          - name: HOST_IP
            value: 0.0.0.0
          image: quay.io/prometheus/node-exporter:v1.8.2
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: 9100
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: node-exporter
          ports:
          - containerPort: 9100
            name: metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: 9100
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /host/proc
            name: proc
            readOnly: true
          - mountPath: /host/sys
            name: sys
            readOnly: true
          - mountPath: /host/root
            mountPropagation: HostToContainer
            name: root
            readOnly: true
        dnsPolicy: ClusterFirst
        hostNetwork: true
        hostPID: true
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          runAsGroup: 65534
          runAsNonRoot: true
          runAsUser: 65534
        serviceAccount: prometheus-prometheus-node-exporter
        serviceAccountName: prometheus-prometheus-node-exporter
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          operator: Exists
        volumes:
        - hostPath:
            path: /proc
            type: ""
          name: proc
        - hostPath:
            path: /sys
            type: ""
          name: sys
        - hostPath:
            path: /
            type: ""
          name: root
    updateStrategy:
      rollingUpdate:
        maxSurge: 0
        maxUnavailable: 1
      type: RollingUpdate
  status:
    currentNumberScheduled: 1
    desiredNumberScheduled: 1
    numberAvailable: 1
    numberMisscheduled: 0
    numberReady: 1
    observedGeneration: 1
    updatedNumberScheduled: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: argocd
      meta.helm.sh/release-namespace: argocd
    creationTimestamp: "2024-07-19T17:25:51Z"
    generation: 1
    labels:
      app.kubernetes.io/component: applicationset-controller
      app.kubernetes.io/instance: argocd
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: argocd-applicationset-controller
      app.kubernetes.io/part-of: argocd
      app.kubernetes.io/version: v2.11.5
      helm.sh/chart: argo-cd-7.3.9
    name: argocd-applicationset-controller
    namespace: argocd
    resourceVersion: "17859154"
    uid: b9249080-f1c3-49d2-9e3f-823c701b3fc5
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 3
    selector:
      matchLabels:
        app.kubernetes.io/instance: argocd
        app.kubernetes.io/name: argocd-applicationset-controller
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        annotations:
          checksum/cmd-params: bcbb2496303699a508a41b49a033d6f92d273aba139ec132105f461a1d84fa46
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: applicationset-controller
          app.kubernetes.io/instance: argocd
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: argocd-applicationset-controller
          app.kubernetes.io/part-of: argocd
          app.kubernetes.io/version: v2.11.5
          helm.sh/chart: argo-cd-7.3.9
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: argocd-applicationset-controller
                topologyKey: kubernetes.io/hostname
              weight: 100
        automountServiceAccountToken: true
        containers:
        - args:
          - /usr/local/bin/argocd-applicationset-controller
          - --metrics-addr=:8080
          - --probe-addr=:8081
          - --webhook-addr=:7000
          env:
          - name: NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_GLOBAL_PRESERVED_ANNOTATIONS
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.global.preserved.annotations
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_GLOBAL_PRESERVED_LABELS
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.global.preserved.labels
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_LEADER_ELECTION
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.enable.leader.election
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER
            valueFrom:
              configMapKeyRef:
                key: repo.server
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_POLICY
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.policy
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_POLICY_OVERRIDE
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.enable.policy.override
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_DEBUG
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.debug
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_LOGFORMAT
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.log.format
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_LOGLEVEL
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.log.level
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_DRY_RUN
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.dryrun
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_GIT_MODULES_ENABLED
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.enable.git.submodule
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_PROGRESSIVE_SYNCS
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.enable.progressive.syncs
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_NEW_GIT_FILE_GLOBBING
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.enable.new.git.file.globbing
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_PLAINTEXT
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.repo.server.plaintext
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_STRICT_TLS
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.repo.server.strict.tls
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_TIMEOUT_SECONDS
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.repo.server.timeout.seconds
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_CONCURRENT_RECONCILIATIONS
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.concurrent.reconciliations.max
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_NAMESPACES
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.namespaces
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_SCM_ROOT_CA_PATH
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.scm.root.ca.path
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_ALLOWED_SCM_PROVIDERS
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.allowed.scm.providers
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_SCM_PROVIDERS
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.enable.scm.providers
                name: argocd-cmd-params-cm
                optional: true
          image: quay.io/argoproj/argocd:v2.11.5
          imagePullPolicy: IfNotPresent
          name: applicationset-controller
          ports:
          - containerPort: 8080
            name: metrics
            protocol: TCP
          - containerPort: 8081
            name: probe
            protocol: TCP
          - containerPort: 7000
            name: webhook
            protocol: TCP
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /app/config/ssh
            name: ssh-known-hosts
          - mountPath: /app/config/tls
            name: tls-certs
          - mountPath: /app/config/gpg/source
            name: gpg-keys
          - mountPath: /app/config/gpg/keys
            name: gpg-keyring
          - mountPath: /app/config/reposerver/tls
            name: argocd-repo-server-tls
          - mountPath: /tmp
            name: tmp
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: argocd-applicationset-controller
        serviceAccountName: argocd-applicationset-controller
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: argocd-ssh-known-hosts-cm
          name: ssh-known-hosts
        - configMap:
            defaultMode: 420
            name: argocd-tls-certs-cm
          name: tls-certs
        - configMap:
            defaultMode: 420
            name: argocd-gpg-keys-cm
          name: gpg-keys
        - emptyDir: {}
          name: gpg-keyring
        - emptyDir: {}
          name: tmp
        - name: argocd-repo-server-tls
          secret:
            defaultMode: 420
            items:
            - key: tls.crt
              path: tls.crt
            - key: tls.key
              path: tls.key
            - key: ca.crt
              path: ca.crt
            optional: true
            secretName: argocd-repo-server-tls
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-07-19T17:25:51Z"
      lastUpdateTime: "2024-07-19T17:25:52Z"
      message: ReplicaSet "argocd-applicationset-controller-56d4d6458b" has successfully
        progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2024-12-23T13:36:20Z"
      lastUpdateTime: "2024-12-23T13:36:20Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: argocd
      meta.helm.sh/release-namespace: argocd
    creationTimestamp: "2024-07-19T17:25:51Z"
    generation: 1
    labels:
      app.kubernetes.io/component: dex-server
      app.kubernetes.io/instance: argocd
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: argocd-dex-server
      app.kubernetes.io/part-of: argocd
      app.kubernetes.io/version: v2.11.5
      helm.sh/chart: argo-cd-7.3.9
    name: argocd-dex-server
    namespace: argocd
    resourceVersion: "17859286"
    uid: 898e47f3-4a6d-49dc-837e-c37edb298f9f
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 3
    selector:
      matchLabels:
        app.kubernetes.io/instance: argocd
        app.kubernetes.io/name: argocd-dex-server
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        annotations:
          checksum/cmd-params: bcbb2496303699a508a41b49a033d6f92d273aba139ec132105f461a1d84fa46
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: dex-server
          app.kubernetes.io/instance: argocd
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: argocd-dex-server
          app.kubernetes.io/part-of: argocd
          app.kubernetes.io/version: v2.11.5
          helm.sh/chart: argo-cd-7.3.9
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: argocd-dex-server
                topologyKey: kubernetes.io/hostname
              weight: 100
        automountServiceAccountToken: true
        containers:
        - args:
          - rundex
          command:
          - /shared/argocd-dex
          - --logformat=text
          - --loglevel=info
          env:
          - name: ARGOCD_DEX_SERVER_DISABLE_TLS
            valueFrom:
              configMapKeyRef:
                key: dexserver.disable.tls
                name: argocd-cmd-params-cm
                optional: true
          image: ghcr.io/dexidp/dex:v2.38.0
          imagePullPolicy: IfNotPresent
          name: dex-server
          ports:
          - containerPort: 5556
            name: http
            protocol: TCP
          - containerPort: 5557
            name: grpc
            protocol: TCP
          - containerPort: 5558
            name: metrics
            protocol: TCP
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /shared
            name: static-files
          - mountPath: /tmp
            name: dexconfig
          - mountPath: /tls
            name: argocd-dex-server-tls
        dnsPolicy: ClusterFirst
        initContainers:
        - command:
          - /bin/cp
          - -n
          - /usr/local/bin/argocd
          - /shared/argocd-dex
          image: quay.io/argoproj/argocd:v2.11.5
          imagePullPolicy: IfNotPresent
          name: copyutil
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /shared
            name: static-files
          - mountPath: /tmp
            name: dexconfig
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: argocd-dex-server
        serviceAccountName: argocd-dex-server
        terminationGracePeriodSeconds: 30
        volumes:
        - emptyDir: {}
          name: static-files
        - emptyDir: {}
          name: dexconfig
        - name: argocd-dex-server-tls
          secret:
            defaultMode: 420
            items:
            - key: tls.crt
              path: tls.crt
            - key: tls.key
              path: tls.key
            - key: ca.crt
              path: ca.crt
            optional: true
            secretName: argocd-dex-server-tls
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-07-19T17:25:51Z"
      lastUpdateTime: "2024-07-19T17:25:55Z"
      message: ReplicaSet "argocd-dex-server-7db6876989" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2024-12-23T13:36:28Z"
      lastUpdateTime: "2024-12-23T13:36:28Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: argocd
      meta.helm.sh/release-namespace: argocd
    creationTimestamp: "2024-07-19T17:25:51Z"
    generation: 1
    labels:
      app.kubernetes.io/component: notifications-controller
      app.kubernetes.io/instance: argocd
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: argocd-notifications-controller
      app.kubernetes.io/part-of: argocd
      app.kubernetes.io/version: v2.11.5
      helm.sh/chart: argo-cd-7.3.9
    name: argocd-notifications-controller
    namespace: argocd
    resourceVersion: "15278045"
    uid: a7e0541c-ef85-484a-9493-ec6d0cd5266b
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 3
    selector:
      matchLabels:
        app.kubernetes.io/instance: argocd
        app.kubernetes.io/name: argocd-notifications-controller
    strategy:
      type: Recreate
    template:
      metadata:
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: notifications-controller
          app.kubernetes.io/instance: argocd
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: argocd-notifications-controller
          app.kubernetes.io/part-of: argocd
          app.kubernetes.io/version: v2.11.5
          helm.sh/chart: argo-cd-7.3.9
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: argocd-notifications-controller
                topologyKey: kubernetes.io/hostname
              weight: 100
        automountServiceAccountToken: true
        containers:
        - args:
          - /usr/local/bin/argocd-notifications
          - --metrics-port=9001
          - --loglevel=info
          - --logformat=text
          - --namespace=argocd
          - --argocd-repo-server=argocd-repo-server:8081
          - --secret-name=argocd-notifications-secret
          env:
          - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGLEVEL
            valueFrom:
              configMapKeyRef:
                key: notificationscontroller.log.level
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
            valueFrom:
              configMapKeyRef:
                key: notificationscontroller.log.format
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATION_NAMESPACES
            valueFrom:
              configMapKeyRef:
                key: application.namespaces
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_NOTIFICATION_CONTROLLER_SELF_SERVICE_NOTIFICATION_ENABLED
            valueFrom:
              configMapKeyRef:
                key: notificationscontroller.selfservice.enabled
                name: argocd-cmd-params-cm
                optional: true
          image: quay.io/argoproj/argocd:v2.11.5
          imagePullPolicy: IfNotPresent
          name: notifications-controller
          ports:
          - containerPort: 9001
            name: metrics
            protocol: TCP
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /app/config/tls
            name: tls-certs
          - mountPath: /app/config/reposerver/tls
            name: argocd-repo-server-tls
          workingDir: /app
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: argocd-notifications-controller
        serviceAccountName: argocd-notifications-controller
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: argocd-tls-certs-cm
          name: tls-certs
        - name: argocd-repo-server-tls
          secret:
            defaultMode: 420
            items:
            - key: tls.crt
              path: tls.crt
            - key: tls.key
              path: tls.key
            - key: ca.crt
              path: ca.crt
            optional: true
            secretName: argocd-repo-server-tls
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-07-19T17:25:51Z"
      lastUpdateTime: "2024-07-19T17:25:53Z"
      message: ReplicaSet "argocd-notifications-controller-5c8658678f" has successfully
        progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2024-12-01T15:00:50Z"
      lastUpdateTime: "2024-12-01T15:00:50Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: argocd
      meta.helm.sh/release-namespace: argocd
    creationTimestamp: "2024-07-19T17:25:51Z"
    generation: 1
    labels:
      app.kubernetes.io/component: redis
      app.kubernetes.io/instance: argocd
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: argocd-redis
      app.kubernetes.io/part-of: argocd
      app.kubernetes.io/version: v2.11.5
      helm.sh/chart: argo-cd-7.3.9
    name: argocd-redis
    namespace: argocd
    resourceVersion: "15278149"
    uid: 45324268-5269-4eed-9708-a4af5b18ebb7
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 3
    selector:
      matchLabels:
        app.kubernetes.io/name: argocd-redis
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: redis
          app.kubernetes.io/instance: argocd
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: argocd-redis
          app.kubernetes.io/part-of: argocd
          app.kubernetes.io/version: v2.11.5
          helm.sh/chart: argo-cd-7.3.9
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: argocd-redis
                topologyKey: kubernetes.io/hostname
              weight: 100
        automountServiceAccountToken: true
        containers:
        - args:
          - --save
          - ""
          - --appendonly
          - "no"
          - --requirepass $(REDIS_PASSWORD)
          env:
          - name: REDIS_PASSWORD
            valueFrom:
              secretKeyRef:
                key: auth
                name: argocd-redis
          image: public.ecr.aws/docker/library/redis:7.2.4-alpine
          imagePullPolicy: IfNotPresent
          name: redis
          ports:
          - containerPort: 6379
            name: redis
            protocol: TCP
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /health
            name: health
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          runAsNonRoot: true
          runAsUser: 999
          seccompProfile:
            type: RuntimeDefault
        serviceAccount: default
        serviceAccountName: default
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 493
            name: argocd-redis-health-configmap
          name: health
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-07-19T17:25:51Z"
      lastUpdateTime: "2024-07-19T17:25:54Z"
      message: ReplicaSet "argocd-redis-6d9f6dc894" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2024-12-01T15:01:09Z"
      lastUpdateTime: "2024-12-01T15:01:09Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: argocd
      meta.helm.sh/release-namespace: argocd
    creationTimestamp: "2024-07-19T17:25:51Z"
    generation: 1
    labels:
      app.kubernetes.io/component: repo-server
      app.kubernetes.io/instance: argocd
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: argocd-repo-server
      app.kubernetes.io/part-of: argocd
      app.kubernetes.io/version: v2.11.5
      helm.sh/chart: argo-cd-7.3.9
    name: argocd-repo-server
    namespace: argocd
    resourceVersion: "22846819"
    uid: fcf6fcc7-f3d1-4ceb-90b4-9514b00c396b
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 3
    selector:
      matchLabels:
        app.kubernetes.io/instance: argocd
        app.kubernetes.io/name: argocd-repo-server
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        annotations:
          checksum/cm: 9156c689cecc9c1147df3672959659693b08b4c335adc717836ea9bc0cc75160
          checksum/cmd-params: bcbb2496303699a508a41b49a033d6f92d273aba139ec132105f461a1d84fa46
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: repo-server
          app.kubernetes.io/instance: argocd
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: argocd-repo-server
          app.kubernetes.io/part-of: argocd
          app.kubernetes.io/version: v2.11.5
          helm.sh/chart: argo-cd-7.3.9
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: argocd-repo-server
                topologyKey: kubernetes.io/hostname
              weight: 100
        automountServiceAccountToken: true
        containers:
        - args:
          - /usr/local/bin/argocd-repo-server
          - --port=8081
          - --metrics-port=8084
          env:
          - name: ARGOCD_REPO_SERVER_NAME
            value: argocd-repo-server
          - name: ARGOCD_RECONCILIATION_TIMEOUT
            valueFrom:
              configMapKeyRef:
                key: timeout.reconciliation
                name: argocd-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_LOGFORMAT
            valueFrom:
              configMapKeyRef:
                key: reposerver.log.format
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_LOGLEVEL
            valueFrom:
              configMapKeyRef:
                key: reposerver.log.level
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_PARALLELISM_LIMIT
            valueFrom:
              configMapKeyRef:
                key: reposerver.parallelism.limit
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_LISTEN_ADDRESS
            valueFrom:
              configMapKeyRef:
                key: reposerver.listen.address
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_LISTEN_METRICS_ADDRESS
            valueFrom:
              configMapKeyRef:
                key: reposerver.metrics.listen.address
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_DISABLE_TLS
            valueFrom:
              configMapKeyRef:
                key: reposerver.disable.tls
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_TLS_MIN_VERSION
            valueFrom:
              configMapKeyRef:
                key: reposerver.tls.minversion
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_TLS_MAX_VERSION
            valueFrom:
              configMapKeyRef:
                key: reposerver.tls.maxversion
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_TLS_CIPHERS
            valueFrom:
              configMapKeyRef:
                key: reposerver.tls.ciphers
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_CACHE_EXPIRATION
            valueFrom:
              configMapKeyRef:
                key: reposerver.repo.cache.expiration
                name: argocd-cmd-params-cm
                optional: true
          - name: REDIS_SERVER
            valueFrom:
              configMapKeyRef:
                key: redis.server
                name: argocd-cmd-params-cm
                optional: true
          - name: REDIS_COMPRESSION
            valueFrom:
              configMapKeyRef:
                key: redis.compression
                name: argocd-cmd-params-cm
                optional: true
          - name: REDISDB
            valueFrom:
              configMapKeyRef:
                key: redis.db
                name: argocd-cmd-params-cm
                optional: true
          - name: REDIS_USERNAME
            valueFrom:
              secretKeyRef:
                key: redis-username
                name: argocd-redis
                optional: true
          - name: REDIS_PASSWORD
            valueFrom:
              secretKeyRef:
                key: auth
                name: argocd-redis
                optional: true
          - name: REDIS_SENTINEL_USERNAME
            valueFrom:
              secretKeyRef:
                key: redis-sentinel-username
                name: argocd-redis
                optional: true
          - name: REDIS_SENTINEL_PASSWORD
            valueFrom:
              secretKeyRef:
                key: redis-sentinel-password
                name: argocd-redis
                optional: true
          - name: ARGOCD_DEFAULT_CACHE_EXPIRATION
            valueFrom:
              configMapKeyRef:
                key: reposerver.default.cache.expiration
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_OTLP_ADDRESS
            valueFrom:
              configMapKeyRef:
                key: otlp.address
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_OTLP_INSECURE
            valueFrom:
              configMapKeyRef:
                key: otlp.insecure
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_OTLP_HEADERS
            valueFrom:
              configMapKeyRef:
                key: otlp.headers
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_MAX_COMBINED_DIRECTORY_MANIFESTS_SIZE
            valueFrom:
              configMapKeyRef:
                key: reposerver.max.combined.directory.manifests.size
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_PLUGIN_TAR_EXCLUSIONS
            valueFrom:
              configMapKeyRef:
                key: reposerver.plugin.tar.exclusions
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_ALLOW_OUT_OF_BOUNDS_SYMLINKS
            valueFrom:
              configMapKeyRef:
                key: reposerver.allow.oob.symlinks
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_TAR_SIZE
            valueFrom:
              configMapKeyRef:
                key: reposerver.streamed.manifest.max.tar.size
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_EXTRACTED_SIZE
            valueFrom:
              configMapKeyRef:
                key: reposerver.streamed.manifest.max.extracted.size
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_HELM_MANIFEST_MAX_EXTRACTED_SIZE
            valueFrom:
              configMapKeyRef:
                key: reposerver.helm.manifest.max.extracted.size
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_DISABLE_HELM_MANIFEST_MAX_EXTRACTED_SIZE
            valueFrom:
              configMapKeyRef:
                key: reposerver.disable.helm.manifest.max.extracted.size
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_GIT_MODULES_ENABLED
            valueFrom:
              configMapKeyRef:
                key: reposerver.enable.git.submodule
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_GIT_LS_REMOTE_PARALLELISM_LIMIT
            valueFrom:
              configMapKeyRef:
                key: reposerver.git.lsremote.parallelism.limit
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_GIT_REQUEST_TIMEOUT
            valueFrom:
              configMapKeyRef:
                key: reposerver.git.request.timeout
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REVISION_CACHE_LOCK_TIMEOUT
            valueFrom:
              configMapKeyRef:
                key: reposerver.revision.cache.lock.timeout
                name: argocd-cmd-params-cm
                optional: true
          - name: HELM_CACHE_HOME
            value: /helm-working-dir
          - name: HELM_CONFIG_HOME
            value: /helm-working-dir
          - name: HELM_DATA_HOME
            value: /helm-working-dir
          image: quay.io/argoproj/argocd:v2.11.5
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz?full=true
              port: metrics
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: repo-server
          ports:
          - containerPort: 8081
            name: repo-server
            protocol: TCP
          - containerPort: 8084
            name: metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: metrics
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /app/config/ssh
            name: ssh-known-hosts
          - mountPath: /app/config/tls
            name: tls-certs
          - mountPath: /app/config/gpg/source
            name: gpg-keys
          - mountPath: /app/config/gpg/keys
            name: gpg-keyring
          - mountPath: /app/config/reposerver/tls
            name: argocd-repo-server-tls
          - mountPath: /helm-working-dir
            name: helm-working-dir
          - mountPath: /home/argocd/cmp-server/plugins
            name: plugins
          - mountPath: /tmp
            name: tmp
        dnsPolicy: ClusterFirst
        initContainers:
        - command:
          - /bin/cp
          - -n
          - /usr/local/bin/argocd
          - /var/run/argocd/argocd-cmp-server
          image: quay.io/argoproj/argocd:v2.11.5
          imagePullPolicy: IfNotPresent
          name: copyutil
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/run/argocd
            name: var-files
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: argocd-repo-server
        serviceAccountName: argocd-repo-server
        terminationGracePeriodSeconds: 30
        volumes:
        - emptyDir: {}
          name: helm-working-dir
        - emptyDir: {}
          name: plugins
        - emptyDir: {}
          name: var-files
        - emptyDir: {}
          name: tmp
        - configMap:
            defaultMode: 420
            name: argocd-ssh-known-hosts-cm
          name: ssh-known-hosts
        - configMap:
            defaultMode: 420
            name: argocd-tls-certs-cm
          name: tls-certs
        - configMap:
            defaultMode: 420
            name: argocd-gpg-keys-cm
          name: gpg-keys
        - emptyDir: {}
          name: gpg-keyring
        - name: argocd-repo-server-tls
          secret:
            defaultMode: 420
            items:
            - key: tls.crt
              path: tls.crt
            - key: tls.key
              path: tls.key
            - key: ca.crt
              path: ca.crt
            optional: true
            secretName: argocd-repo-server-tls
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-07-19T17:25:51Z"
      lastUpdateTime: "2024-07-19T17:26:11Z"
      message: ReplicaSet "argocd-repo-server-6b5cdc488b" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-02-07T06:56:07Z"
      lastUpdateTime: "2025-02-07T06:56:07Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: argocd
      meta.helm.sh/release-namespace: argocd
    creationTimestamp: "2024-07-19T17:25:51Z"
    generation: 1
    labels:
      app.kubernetes.io/component: server
      app.kubernetes.io/instance: argocd
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: argocd-server
      app.kubernetes.io/part-of: argocd
      app.kubernetes.io/version: v2.11.5
      helm.sh/chart: argo-cd-7.3.9
    name: argocd-server
    namespace: argocd
    resourceVersion: "17859227"
    uid: e5c14ca8-810a-4d27-9307-998878397073
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 3
    selector:
      matchLabels:
        app.kubernetes.io/instance: argocd
        app.kubernetes.io/name: argocd-server
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        annotations:
          checksum/cm: 9156c689cecc9c1147df3672959659693b08b4c335adc717836ea9bc0cc75160
          checksum/cmd-params: bcbb2496303699a508a41b49a033d6f92d273aba139ec132105f461a1d84fa46
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: server
          app.kubernetes.io/instance: argocd
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: argocd-server
          app.kubernetes.io/part-of: argocd
          app.kubernetes.io/version: v2.11.5
          helm.sh/chart: argo-cd-7.3.9
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: argocd-server
                topologyKey: kubernetes.io/hostname
              weight: 100
        automountServiceAccountToken: true
        containers:
        - args:
          - /usr/local/bin/argocd-server
          - --port=8080
          - --metrics-port=8083
          - --rootpath
          - /argocd
          env:
          - name: ARGOCD_SERVER_NAME
            value: argocd-server
          - name: ARGOCD_SERVER_INSECURE
            valueFrom:
              configMapKeyRef:
                key: server.insecure
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_BASEHREF
            valueFrom:
              configMapKeyRef:
                key: server.basehref
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_ROOTPATH
            valueFrom:
              configMapKeyRef:
                key: server.rootpath
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_LOGFORMAT
            valueFrom:
              configMapKeyRef:
                key: server.log.format
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_LOG_LEVEL
            valueFrom:
              configMapKeyRef:
                key: server.log.level
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_REPO_SERVER
            valueFrom:
              configMapKeyRef:
                key: repo.server
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_DEX_SERVER
            valueFrom:
              configMapKeyRef:
                key: server.dex.server
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_DISABLE_AUTH
            valueFrom:
              configMapKeyRef:
                key: server.disable.auth
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_ENABLE_GZIP
            valueFrom:
              configMapKeyRef:
                key: server.enable.gzip
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_REPO_SERVER_TIMEOUT_SECONDS
            valueFrom:
              configMapKeyRef:
                key: server.repo.server.timeout.seconds
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_X_FRAME_OPTIONS
            valueFrom:
              configMapKeyRef:
                key: server.x.frame.options
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_CONTENT_SECURITY_POLICY
            valueFrom:
              configMapKeyRef:
                key: server.content.security.policy
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_REPO_SERVER_PLAINTEXT
            valueFrom:
              configMapKeyRef:
                key: server.repo.server.plaintext
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_REPO_SERVER_STRICT_TLS
            valueFrom:
              configMapKeyRef:
                key: server.repo.server.strict.tls
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_DEX_SERVER_PLAINTEXT
            valueFrom:
              configMapKeyRef:
                key: server.dex.server.plaintext
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_DEX_SERVER_STRICT_TLS
            valueFrom:
              configMapKeyRef:
                key: server.dex.server.strict.tls
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_TLS_MIN_VERSION
            valueFrom:
              configMapKeyRef:
                key: server.tls.minversion
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_TLS_MAX_VERSION
            valueFrom:
              configMapKeyRef:
                key: server.tls.maxversion
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_TLS_CIPHERS
            valueFrom:
              configMapKeyRef:
                key: server.tls.ciphers
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_CONNECTION_STATUS_CACHE_EXPIRATION
            valueFrom:
              configMapKeyRef:
                key: server.connection.status.cache.expiration
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_OIDC_CACHE_EXPIRATION
            valueFrom:
              configMapKeyRef:
                key: server.oidc.cache.expiration
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_LOGIN_ATTEMPTS_EXPIRATION
            valueFrom:
              configMapKeyRef:
                key: server.login.attempts.expiration
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_STATIC_ASSETS
            valueFrom:
              configMapKeyRef:
                key: server.staticassets
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APP_STATE_CACHE_EXPIRATION
            valueFrom:
              configMapKeyRef:
                key: server.app.state.cache.expiration
                name: argocd-cmd-params-cm
                optional: true
          - name: REDIS_SERVER
            valueFrom:
              configMapKeyRef:
                key: redis.server
                name: argocd-cmd-params-cm
                optional: true
          - name: REDIS_COMPRESSION
            valueFrom:
              configMapKeyRef:
                key: redis.compression
                name: argocd-cmd-params-cm
                optional: true
          - name: REDISDB
            valueFrom:
              configMapKeyRef:
                key: redis.db
                name: argocd-cmd-params-cm
                optional: true
          - name: REDIS_USERNAME
            valueFrom:
              secretKeyRef:
                key: redis-username
                name: argocd-redis
                optional: true
          - name: REDIS_PASSWORD
            valueFrom:
              secretKeyRef:
                key: auth
                name: argocd-redis
                optional: true
          - name: REDIS_SENTINEL_USERNAME
            valueFrom:
              secretKeyRef:
                key: redis-sentinel-username
                name: argocd-redis
                optional: true
          - name: REDIS_SENTINEL_PASSWORD
            valueFrom:
              secretKeyRef:
                key: redis-sentinel-password
                name: argocd-redis
                optional: true
          - name: ARGOCD_DEFAULT_CACHE_EXPIRATION
            valueFrom:
              configMapKeyRef:
                key: server.default.cache.expiration
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_MAX_COOKIE_NUMBER
            valueFrom:
              configMapKeyRef:
                key: server.http.cookie.maxnumber
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_LISTEN_ADDRESS
            valueFrom:
              configMapKeyRef:
                key: server.listen.address
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_METRICS_LISTEN_ADDRESS
            valueFrom:
              configMapKeyRef:
                key: server.metrics.listen.address
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_OTLP_ADDRESS
            valueFrom:
              configMapKeyRef:
                key: otlp.address
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_OTLP_INSECURE
            valueFrom:
              configMapKeyRef:
                key: otlp.insecure
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_OTLP_HEADERS
            valueFrom:
              configMapKeyRef:
                key: otlp.headers
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATION_NAMESPACES
            valueFrom:
              configMapKeyRef:
                key: application.namespaces
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_ENABLE_PROXY_EXTENSION
            valueFrom:
              configMapKeyRef:
                key: server.enable.proxy.extension
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_K8SCLIENT_RETRY_MAX
            valueFrom:
              configMapKeyRef:
                key: server.k8sclient.retry.max
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_K8SCLIENT_RETRY_BASE_BACKOFF
            valueFrom:
              configMapKeyRef:
                key: server.k8sclient.retry.base.backoff
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_API_CONTENT_TYPES
            valueFrom:
              configMapKeyRef:
                key: server.api.content.types
                name: argocd-cmd-params-cm
                optional: true
          image: quay.io/argoproj/argocd:v2.11.5
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz?full=true
              port: server
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: server
          ports:
          - containerPort: 8080
            name: server
            protocol: TCP
          - containerPort: 8083
            name: metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: server
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /app/config/ssh
            name: ssh-known-hosts
          - mountPath: /app/config/tls
            name: tls-certs
          - mountPath: /app/config/server/tls
            name: argocd-repo-server-tls
          - mountPath: /app/config/dex/tls
            name: argocd-dex-server-tls
          - mountPath: /home/argocd
            name: plugins-home
          - mountPath: /shared/app/custom
            name: styles
          - mountPath: /tmp
            name: tmp
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: argocd-server
        serviceAccountName: argocd-server
        terminationGracePeriodSeconds: 30
        volumes:
        - emptyDir: {}
          name: plugins-home
        - emptyDir: {}
          name: tmp
        - configMap:
            defaultMode: 420
            name: argocd-ssh-known-hosts-cm
          name: ssh-known-hosts
        - configMap:
            defaultMode: 420
            name: argocd-tls-certs-cm
          name: tls-certs
        - configMap:
            defaultMode: 420
            name: argocd-styles-cm
            optional: true
          name: styles
        - name: argocd-repo-server-tls
          secret:
            defaultMode: 420
            items:
            - key: tls.crt
              path: tls.crt
            - key: tls.key
              path: tls.key
            - key: ca.crt
              path: ca.crt
            optional: true
            secretName: argocd-repo-server-tls
        - name: argocd-dex-server-tls
          secret:
            defaultMode: 420
            items:
            - key: tls.crt
              path: tls.crt
            - key: ca.crt
              path: ca.crt
            optional: true
            secretName: argocd-dex-server-tls
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-07-19T17:25:51Z"
      lastUpdateTime: "2024-07-19T17:26:11Z"
      message: ReplicaSet "argocd-server-85f4f7b9f7" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2024-12-23T13:36:23Z"
      lastUpdateTime: "2024-12-23T13:36:23Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "5"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"argocd.argoproj.io/instance":"backend"},"name":"backend","namespace":"backend"},"spec":{"replicas":2,"selector":{"matchLabels":{"app":"backend"}},"template":{"metadata":{"labels":{"app":"backend"}},"spec":{"containers":[{"env":[{"name":"SPRING_CONFIG_LOCATION","value":"/app/config/application.yaml"}],"image":"zicdding0904/zicdding-class-back:latest","imagePullPolicy":"Always","name":"backend","ports":[{"containerPort":3000}],"volumeMounts":[{"mountPath":"/app/config/application.yaml","name":"config-volume","subPath":"application.yaml"}]}],"volumes":[{"configMap":{"name":"backend-config"},"name":"config-volume"}]}}}}
    creationTimestamp: "2024-12-26T14:41:51Z"
    generation: 6
    labels:
      argocd.argoproj.io/instance: backend
    name: backend
    namespace: backend
    resourceVersion: "19414831"
    uid: 7d4a6583-3d4c-4841-8cef-bc2c0edb6f03
  spec:
    progressDeadlineSeconds: 600
    replicas: 2
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: backend
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-01-06T14:43:15+09:00"
        creationTimestamp: null
        labels:
          app: backend
      spec:
        containers:
        - env:
          - name: SPRING_CONFIG_LOCATION
            value: /app/config/application.yaml
          image: zicdding0904/zicdding-class-back:latest
          imagePullPolicy: Always
          name: backend
          ports:
          - containerPort: 3000
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /app/config/application.yaml
            name: config-volume
            subPath: application.yaml
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: backend-config
          name: config-volume
  status:
    availableReplicas: 2
    conditions:
    - lastTransitionTime: "2024-12-30T04:32:08Z"
      lastUpdateTime: "2024-12-30T04:32:08Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2024-12-26T14:41:51Z"
      lastUpdateTime: "2025-01-06T05:43:51Z"
      message: ReplicaSet "backend-5f6bfbb599" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 6
    readyReplicas: 2
    replicas: 2
    updatedReplicas: 2
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "2"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"app.kubernetes.io/component":"controller","app.kubernetes.io/instance":"ingress-nginx","app.kubernetes.io/name":"ingress-nginx"},"name":"ingress-nginx-controller","namespace":"ingress-nginx"},"spec":{"minReadySeconds":0,"revisionHistoryLimit":10,"selector":{"matchLabels":{"app.kubernetes.io/component":"controller","app.kubernetes.io/instance":"ingress-nginx","app.kubernetes.io/name":"ingress-nginx"}},"strategy":{"rollingUpdate":{"maxUnavailable":1},"type":"RollingUpdate"},"template":{"metadata":{"labels":{"app.kubernetes.io/component":"controller","app.kubernetes.io/instance":"ingress-nginx","app.kubernetes.io/name":"ingress-nginx","gcp-auth-skip-secret":"true"}},"spec":{"containers":[{"args":["/nginx-ingress-controller","--election-id=ingress-nginx-leader","--controller-class=k8s.io/ingress-nginx","--watch-ingress-without-class=true","--configmap=$(POD_NAMESPACE)/ingress-nginx-controller","--tcp-services-configmap=$(POD_NAMESPACE)/tcp-services","--udp-services-configmap=$(POD_NAMESPACE)/udp-services","--validating-webhook=:8443","--validating-webhook-certificate=/usr/local/certificates/cert","--validating-webhook-key=/usr/local/certificates/key"],"env":[{"name":"POD_NAME","valueFrom":{"fieldRef":{"fieldPath":"metadata.name"}}},{"name":"POD_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}},{"name":"LD_PRELOAD","value":"/usr/local/lib/libmimalloc.so"}],"image":"registry.k8s.io/ingress-nginx/controller:v1.10.1@sha256:e24f39d3eed6bcc239a56f20098878845f62baa34b9f2be2fd2c38ce9fb0f29e","imagePullPolicy":"IfNotPresent","lifecycle":{"preStop":{"exec":{"command":["/wait-shutdown"]}}},"livenessProbe":{"failureThreshold":5,"httpGet":{"path":"/healthz","port":10254,"scheme":"HTTP"},"initialDelaySeconds":10,"periodSeconds":10,"successThreshold":1,"timeoutSeconds":1},"name":"controller","ports":[{"containerPort":80,"hostPort":80,"name":"http","protocol":"TCP"},{"containerPort":443,"hostPort":443,"name":"https","protocol":"TCP"},{"containerPort":8443,"name":"webhook","protocol":"TCP"}],"readinessProbe":{"failureThreshold":3,"httpGet":{"path":"/healthz","port":10254,"scheme":"HTTP"},"initialDelaySeconds":10,"periodSeconds":10,"successThreshold":1,"timeoutSeconds":1},"resources":{"requests":{"cpu":"100m","memory":"90Mi"}},"securityContext":{"allowPrivilegeEscalation":true,"capabilities":{"add":["NET_BIND_SERVICE"],"drop":["ALL"]},"runAsUser":101},"volumeMounts":[{"mountPath":"/usr/local/certificates/","name":"webhook-cert","readOnly":true}]}],"dnsPolicy":"ClusterFirst","nodeSelector":{"kubernetes.io/os":"linux","minikube.k8s.io/primary":"true"},"serviceAccountName":"ingress-nginx","terminationGracePeriodSeconds":0,"tolerations":[{"effect":"NoSchedule","key":"node-role.kubernetes.io/master","operator":"Equal"}],"volumes":[{"name":"webhook-cert","secret":{"secretName":"ingress-nginx-admission"}}]}}}}
    creationTimestamp: "2024-08-03T05:16:32Z"
    generation: 2
    labels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/name: ingress-nginx
    name: ingress-nginx-controller
    namespace: ingress-nginx
    resourceVersion: "18212289"
    uid: cab11dbc-f1ac-4447-a8d2-7bf192b7720c
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/component: controller
        app.kubernetes.io/instance: ingress-nginx
        app.kubernetes.io/name: ingress-nginx
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 1
      type: RollingUpdate
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2024-12-27T00:22:02+09:00"
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: controller
          app.kubernetes.io/instance: ingress-nginx
          app.kubernetes.io/name: ingress-nginx
          gcp-auth-skip-secret: "true"
      spec:
        containers:
        - args:
          - /nginx-ingress-controller
          - --election-id=ingress-nginx-leader
          - --controller-class=k8s.io/ingress-nginx
          - --watch-ingress-without-class=true
          - --configmap=$(POD_NAMESPACE)/ingress-nginx-controller
          - --tcp-services-configmap=$(POD_NAMESPACE)/tcp-services
          - --udp-services-configmap=$(POD_NAMESPACE)/udp-services
          - --validating-webhook=:8443
          - --validating-webhook-certificate=/usr/local/certificates/cert
          - --validating-webhook-key=/usr/local/certificates/key
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: LD_PRELOAD
            value: /usr/local/lib/libmimalloc.so
          image: registry.k8s.io/ingress-nginx/controller:v1.10.1@sha256:e24f39d3eed6bcc239a56f20098878845f62baa34b9f2be2fd2c38ce9fb0f29e
          imagePullPolicy: IfNotPresent
          lifecycle:
            preStop:
              exec:
                command:
                - /wait-shutdown
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /healthz
              port: 10254
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: controller
          ports:
          - containerPort: 80
            hostPort: 80
            name: http
            protocol: TCP
          - containerPort: 443
            hostPort: 443
            name: https
            protocol: TCP
          - containerPort: 8443
            name: webhook
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 10254
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            requests:
              cpu: 100m
              memory: 90Mi
          securityContext:
            allowPrivilegeEscalation: true
            capabilities:
              add:
              - NET_BIND_SERVICE
              drop:
              - ALL
            runAsUser: 101
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /usr/local/certificates/
            name: webhook-cert
            readOnly: true
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
          minikube.k8s.io/primary: "true"
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: ingress-nginx
        serviceAccountName: ingress-nginx
        terminationGracePeriodSeconds: 0
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Equal
        volumes:
        - name: webhook-cert
          secret:
            defaultMode: 420
            secretName: ingress-nginx-admission
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-08-03T05:16:32Z"
      lastUpdateTime: "2024-08-03T05:16:32Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2024-08-03T05:16:32Z"
      lastUpdateTime: "2024-12-26T15:22:24Z"
      message: ReplicaSet "ingress-nginx-controller-79d9f6f4d6" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 2
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: nginx-ingress
      meta.helm.sh/release-namespace: ingress-nginx
    creationTimestamp: "2024-07-20T01:14:48Z"
    generation: 1
    labels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: nginx-ingress
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: ingress-nginx
      app.kubernetes.io/part-of: ingress-nginx
      app.kubernetes.io/version: 1.11.1
      helm.sh/chart: ingress-nginx-4.11.1
    name: nginx-ingress-ingress-nginx-controller
    namespace: ingress-nginx
    resourceVersion: "17859301"
    uid: dce8927d-d2af-46fe-a22d-205821fb9d60
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/component: controller
        app.kubernetes.io/instance: nginx-ingress
        app.kubernetes.io/name: ingress-nginx
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: controller
          app.kubernetes.io/instance: nginx-ingress
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: ingress-nginx
          app.kubernetes.io/part-of: ingress-nginx
          app.kubernetes.io/version: 1.11.1
          helm.sh/chart: ingress-nginx-4.11.1
      spec:
        containers:
        - args:
          - /nginx-ingress-controller
          - --publish-service=$(POD_NAMESPACE)/nginx-ingress-ingress-nginx-controller
          - --election-id=nginx-ingress-ingress-nginx-leader
          - --controller-class=k8s.io/ingress-nginx
          - --ingress-class=nginx
          - --configmap=$(POD_NAMESPACE)/nginx-ingress-ingress-nginx-controller
          - --validating-webhook=:8443
          - --validating-webhook-certificate=/usr/local/certificates/cert
          - --validating-webhook-key=/usr/local/certificates/key
          - --enable-metrics=false
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: LD_PRELOAD
            value: /usr/local/lib/libmimalloc.so
          image: registry.k8s.io/ingress-nginx/controller:v1.11.1@sha256:e6439a12b52076965928e83b7b56aae6731231677b01e81818bce7fa5c60161a
          imagePullPolicy: IfNotPresent
          lifecycle:
            preStop:
              exec:
                command:
                - /wait-shutdown
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /healthz
              port: 10254
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: controller
          ports:
          - containerPort: 80
            name: http
            protocol: TCP
          - containerPort: 443
            name: https
            protocol: TCP
          - containerPort: 8443
            name: webhook
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 10254
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            requests:
              cpu: 100m
              memory: 90Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              add:
              - NET_BIND_SERVICE
              drop:
              - ALL
            readOnlyRootFilesystem: false
            runAsNonRoot: true
            runAsUser: 101
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /usr/local/certificates/
            name: webhook-cert
            readOnly: true
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: nginx-ingress-ingress-nginx
        serviceAccountName: nginx-ingress-ingress-nginx
        terminationGracePeriodSeconds: 300
        volumes:
        - name: webhook-cert
          secret:
            defaultMode: 420
            secretName: nginx-ingress-ingress-nginx-admission
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-07-20T01:14:48Z"
      lastUpdateTime: "2024-07-20T01:14:59Z"
      message: ReplicaSet "nginx-ingress-ingress-nginx-controller-7855544b44" has
        successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2024-12-23T13:36:37Z"
      lastUpdateTime: "2024-12-23T13:36:37Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2024-07-09T13:40:18Z"
    generation: 2
    labels:
      k8s-app: kube-dns
    name: coredns
    namespace: kube-system
    resourceVersion: "17859177"
    uid: 889549ad-f497-4011-93e5-b8e00c622961
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: kube-dns
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 1
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: kube-dns
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchExpressions:
                  - key: k8s-app
                    operator: In
                    values:
                    - kube-dns
                topologyKey: kubernetes.io/hostname
              weight: 100
        containers:
        - args:
          - -conf
          - /etc/coredns/Corefile
          image: registry.k8s.io/coredns/coredns:v1.11.1
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /health
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: coredns
          ports:
          - containerPort: 53
            name: dns
            protocol: UDP
          - containerPort: 53
            name: dns-tcp
            protocol: TCP
          - containerPort: 9153
            name: metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /ready
              port: 8181
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            limits:
              memory: 170Mi
            requests:
              cpu: 100m
              memory: 70Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              add:
              - NET_BIND_SERVICE
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/coredns
            name: config-volume
            readOnly: true
        dnsPolicy: Default
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: coredns
        serviceAccountName: coredns
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
        volumes:
        - configMap:
            defaultMode: 420
            items:
            - key: Corefile
              path: Corefile
            name: coredns
          name: config-volume
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-07-09T13:40:32Z"
      lastUpdateTime: "2024-07-09T13:40:32Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2024-07-09T13:40:32Z"
      lastUpdateTime: "2024-07-09T13:40:33Z"
      message: ReplicaSet "coredns-7db6d8ff4d" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 2
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "3"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"k8s-app":"metrics-server"},"name":"metrics-server","namespace":"kube-system"},"spec":{"selector":{"matchLabels":{"k8s-app":"metrics-server"}},"strategy":{"rollingUpdate":{"maxUnavailable":0}},"template":{"metadata":{"labels":{"k8s-app":"metrics-server"}},"spec":{"containers":[{"args":["--cert-dir=/tmp","--secure-port=10250","--kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname","--kubelet-use-node-status-port","--metric-resolution=15s"],"image":"registry.k8s.io/metrics-server/metrics-server:v0.7.2","imagePullPolicy":"IfNotPresent","livenessProbe":{"failureThreshold":3,"httpGet":{"path":"/livez","port":"https","scheme":"HTTPS"},"periodSeconds":10},"name":"metrics-server","ports":[{"containerPort":10250,"name":"https","protocol":"TCP"}],"readinessProbe":{"failureThreshold":3,"httpGet":{"path":"/readyz","port":"https","scheme":"HTTPS"},"initialDelaySeconds":20,"periodSeconds":10},"resources":{"requests":{"cpu":"100m","memory":"200Mi"}},"securityContext":{"allowPrivilegeEscalation":false,"capabilities":{"drop":["ALL"]},"readOnlyRootFilesystem":true,"runAsNonRoot":true,"runAsUser":1000,"seccompProfile":{"type":"RuntimeDefault"}},"volumeMounts":[{"mountPath":"/tmp","name":"tmp-dir"}]}],"nodeSelector":{"kubernetes.io/os":"linux"},"priorityClassName":"system-cluster-critical","serviceAccountName":"metrics-server","volumes":[{"emptyDir":{},"name":"tmp-dir"}]}}}}
    creationTimestamp: "2024-12-23T13:40:58Z"
    generation: 3
    labels:
      k8s-app: metrics-server
    name: metrics-server
    namespace: kube-system
    resourceVersion: "22846839"
    uid: 6676e809-6638-4ed0-96fd-05b3487b322c
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: metrics-server
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 0
      type: RollingUpdate
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2024-12-23T22:43:40+09:00"
        creationTimestamp: null
        labels:
          k8s-app: metrics-server
      spec:
        containers:
        - args:
          - --cert-dir=/tmp
          - --secure-port=10250
          - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
          - --kubelet-use-node-status-port
          - --metric-resolution=15s
          - --kubelet-insecure-tls
          - --kubelet-preferred-address-types=InternalIP
          image: registry.k8s.io/metrics-server/metrics-server:v0.7.2
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /livez
              port: https
              scheme: HTTPS
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: metrics-server
          ports:
          - containerPort: 10250
            name: https
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /readyz
              port: https
              scheme: HTTPS
            initialDelaySeconds: 20
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            requests:
              cpu: 100m
              memory: 200Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 1000
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /tmp
            name: tmp-dir
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: metrics-server
        serviceAccountName: metrics-server
        terminationGracePeriodSeconds: 30
        volumes:
        - emptyDir: {}
          name: tmp-dir
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-12-23T13:40:58Z"
      lastUpdateTime: "2024-12-23T13:44:11Z"
      message: ReplicaSet "metrics-server-fc9f6bcf6" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-02-07T06:56:21Z"
      lastUpdateTime: "2025-02-07T06:56:21Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 3
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","k8s-app":"dashboard-metrics-scraper","kubernetes.io/minikube-addons":"dashboard"},"name":"dashboard-metrics-scraper","namespace":"kubernetes-dashboard"},"spec":{"replicas":1,"revisionHistoryLimit":10,"selector":{"matchLabels":{"k8s-app":"dashboard-metrics-scraper"}},"template":{"metadata":{"annotations":{"seccomp.security.alpha.kubernetes.io/pod":"runtime/default"},"labels":{"k8s-app":"dashboard-metrics-scraper"}},"spec":{"containers":[{"image":"docker.io/kubernetesui/metrics-scraper:v1.0.8@sha256:76049887f07a0476dc93efc2d3569b9529bf982b22d29f356092ce206e98765c","livenessProbe":{"httpGet":{"path":"/","port":8000,"scheme":"HTTP"},"initialDelaySeconds":30,"timeoutSeconds":30},"name":"dashboard-metrics-scraper","ports":[{"containerPort":8000,"protocol":"TCP"}],"securityContext":{"allowPrivilegeEscalation":false,"readOnlyRootFilesystem":true,"runAsGroup":2001,"runAsUser":1001},"volumeMounts":[{"mountPath":"/tmp","name":"tmp-volume"}]}],"nodeSelector":{"kubernetes.io/os":"linux"},"serviceAccountName":"kubernetes-dashboard","tolerations":[{"effect":"NoSchedule","key":"node-role.kubernetes.io/master"}],"volumes":[{"emptyDir":{},"name":"tmp-volume"}]}}}}
    creationTimestamp: "2024-08-01T14:13:28Z"
    generation: 1
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      k8s-app: dashboard-metrics-scraper
      kubernetes.io/minikube-addons: dashboard
    name: dashboard-metrics-scraper
    namespace: kubernetes-dashboard
    resourceVersion: "17859158"
    uid: 5679f7a7-46b8-4769-8fff-369500f6175d
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: dashboard-metrics-scraper
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        annotations:
          seccomp.security.alpha.kubernetes.io/pod: runtime/default
        creationTimestamp: null
        labels:
          k8s-app: dashboard-metrics-scraper
      spec:
        containers:
        - image: docker.io/kubernetesui/metrics-scraper:v1.0.8@sha256:76049887f07a0476dc93efc2d3569b9529bf982b22d29f356092ce206e98765c
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 30
          name: dashboard-metrics-scraper
          ports:
          - containerPort: 8000
            protocol: TCP
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsGroup: 2001
            runAsUser: 1001
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /tmp
            name: tmp-volume
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: kubernetes-dashboard
        serviceAccountName: kubernetes-dashboard
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
        volumes:
        - emptyDir: {}
          name: tmp-volume
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-08-01T14:13:41Z"
      lastUpdateTime: "2024-08-01T14:13:43Z"
      message: ReplicaSet "dashboard-metrics-scraper-b5fc48f67" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2024-12-23T13:36:21Z"
      lastUpdateTime: "2024-12-23T13:36:21Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"addonmanager.kubernetes.io/mode":"Reconcile","k8s-app":"kubernetes-dashboard","kubernetes.io/minikube-addons":"dashboard"},"name":"kubernetes-dashboard","namespace":"kubernetes-dashboard"},"spec":{"replicas":1,"revisionHistoryLimit":10,"selector":{"matchLabels":{"k8s-app":"kubernetes-dashboard"}},"template":{"metadata":{"labels":{"gcp-auth-skip-secret":"true","k8s-app":"kubernetes-dashboard"}},"spec":{"containers":[{"args":["--namespace=kubernetes-dashboard","--enable-skip-login","--disable-settings-authorizer"],"image":"docker.io/kubernetesui/dashboard:v2.7.0@sha256:2e500d29e9d5f4a086b908eb8dfe7ecac57d2ab09d65b24f588b1d449841ef93","livenessProbe":{"httpGet":{"path":"/","port":9090},"initialDelaySeconds":30,"timeoutSeconds":30},"name":"kubernetes-dashboard","ports":[{"containerPort":9090,"protocol":"TCP"}],"securityContext":{"allowPrivilegeEscalation":false,"readOnlyRootFilesystem":true,"runAsGroup":2001,"runAsUser":1001},"volumeMounts":[{"mountPath":"/tmp","name":"tmp-volume"}]}],"nodeSelector":{"kubernetes.io/os":"linux"},"serviceAccountName":"kubernetes-dashboard","tolerations":[{"effect":"NoSchedule","key":"node-role.kubernetes.io/master"}],"volumes":[{"emptyDir":{},"name":"tmp-volume"}]}}}}
    creationTimestamp: "2024-08-01T14:13:28Z"
    generation: 1
    labels:
      addonmanager.kubernetes.io/mode: Reconcile
      k8s-app: kubernetes-dashboard
      kubernetes.io/minikube-addons: dashboard
    name: kubernetes-dashboard
    namespace: kubernetes-dashboard
    resourceVersion: "17859138"
    uid: fff5c7f5-00e5-4301-8ac1-a359b831d08c
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        k8s-app: kubernetes-dashboard
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          gcp-auth-skip-secret: "true"
          k8s-app: kubernetes-dashboard
      spec:
        containers:
        - args:
          - --namespace=kubernetes-dashboard
          - --enable-skip-login
          - --disable-settings-authorizer
          image: docker.io/kubernetesui/dashboard:v2.7.0@sha256:2e500d29e9d5f4a086b908eb8dfe7ecac57d2ab09d65b24f588b1d449841ef93
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: 9090
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 30
          name: kubernetes-dashboard
          ports:
          - containerPort: 9090
            protocol: TCP
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsGroup: 2001
            runAsUser: 1001
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /tmp
            name: tmp-volume
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: kubernetes-dashboard
        serviceAccountName: kubernetes-dashboard
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
        volumes:
        - emptyDir: {}
          name: tmp-volume
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-08-01T14:13:41Z"
      lastUpdateTime: "2024-08-01T14:13:43Z"
      message: ReplicaSet "kubernetes-dashboard-779776cb65" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2024-12-23T13:36:20Z"
      lastUpdateTime: "2024-12-23T13:36:20Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "4"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"app":"metallb","component":"controller"},"name":"controller","namespace":"metallb-system"},"spec":{"revisionHistoryLimit":3,"selector":{"matchLabels":{"app":"metallb","component":"controller"}},"template":{"metadata":{"annotations":{"prometheus.io/port":"7472","prometheus.io/scrape":"true"},"labels":{"app":"metallb","component":"controller"}},"spec":{"containers":[{"args":["--port=7472","--config=config"],"image":"quay.io/metallb/controller:v0.9.6@sha256:6932cf255dd7f06f550c7f106b9a206be95f847ab8cb77aafac7acd27def0b00","imagePullPolicy":"IfNotPresent","name":"controller","ports":[{"containerPort":7472,"name":"monitoring"}],"resources":{"limits":{"cpu":"100m","memory":"100Mi"}},"securityContext":{"allowPrivilegeEscalation":false,"capabilities":{"drop":["all"]},"readOnlyRootFilesystem":true}}],"nodeSelector":{"kubernetes.io/os":"linux"},"securityContext":{"runAsNonRoot":true,"runAsUser":65534},"serviceAccountName":"controller","terminationGracePeriodSeconds":0}}}}
    creationTimestamp: "2024-07-19T17:40:40Z"
    generation: 4
    labels:
      app: metallb
      component: controller
    name: controller
    namespace: metallb-system
    resourceVersion: "15278327"
    uid: 8e628965-4f07-41bc-824f-137cafd3d016
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 3
    selector:
      matchLabels:
        app: metallb
        component: controller
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2024-07-20T09:59:49+09:00"
          prometheus.io/port: "7472"
          prometheus.io/scrape: "true"
        creationTimestamp: null
        labels:
          app: metallb
          component: controller
      spec:
        containers:
        - args:
          - --port=7472
          - --config=config
          image: quay.io/metallb/controller:v0.9.6@sha256:6932cf255dd7f06f550c7f106b9a206be95f847ab8cb77aafac7acd27def0b00
          imagePullPolicy: IfNotPresent
          name: controller
          ports:
          - containerPort: 7472
            name: monitoring
            protocol: TCP
          resources:
            limits:
              cpu: 100m
              memory: 100Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - all
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          runAsNonRoot: true
          runAsUser: 65534
        serviceAccount: controller
        serviceAccountName: controller
        terminationGracePeriodSeconds: 0
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-07-19T17:40:40Z"
      lastUpdateTime: "2024-11-19T12:23:19Z"
      message: ReplicaSet "controller-776c4595bf" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2024-12-01T15:01:28Z"
      lastUpdateTime: "2024-12-01T15:01:28Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 4
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "5"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"app.kubernetes.io/instance":"monitoring","app.kubernetes.io/managed-by":"Helm","app.kubernetes.io/name":"grafana","app.kubernetes.io/version":"11.2.2-security-01","argocd.argoproj.io/instance":"monitoring","helm.sh/chart":"grafana-8.5.8"},"name":"monitoring-grafana","namespace":"monitoring"},"spec":{"replicas":1,"revisionHistoryLimit":10,"selector":{"matchLabels":{"app.kubernetes.io/instance":"monitoring","app.kubernetes.io/name":"grafana"}},"strategy":{"type":"RollingUpdate"},"template":{"metadata":{"annotations":{"checksum/config":"0e9cbd0ea8e24e32f7dfca5bab17a2ba05652642f0a09a4882833ae88e4cc4a3","checksum/sc-dashboard-provider-config":"e70bf6a851099d385178a76de9757bb0bef8299da6d8443602590e44f05fdf24","checksum/secret":"42bbcab3a67ca3daa20142f240a2eba96ec843b11984a0cdd14677477a16e751","kubectl.kubernetes.io/default-container":"grafana"},"labels":{"app.kubernetes.io/instance":"monitoring","app.kubernetes.io/name":"grafana"}},"spec":{"automountServiceAccountToken":true,"containers":[{"env":[{"name":"METHOD","value":"WATCH"},{"name":"LABEL","value":"grafana_dashboard"},{"name":"FOLDER","value":"/tmp/dashboards"},{"name":"RESOURCE","value":"both"},{"name":"REQ_USERNAME","valueFrom":{"secretKeyRef":{"key":"admin-user","name":"monitoring-grafana"}}},{"name":"REQ_PASSWORD","valueFrom":{"secretKeyRef":{"key":"admin-password","name":"monitoring-grafana"}}},{"name":"REQ_URL","value":"http://localhost:3000/api/admin/provisioning/dashboards/reload"},{"name":"REQ_METHOD","value":"POST"}],"image":"quay.io/kiwigrid/k8s-sidecar:1.28.0","imagePullPolicy":"IfNotPresent","name":"grafana-sc-dashboard","securityContext":{"allowPrivilegeEscalation":false,"capabilities":{"drop":["ALL"]},"seccompProfile":{"type":"RuntimeDefault"}},"volumeMounts":[{"mountPath":"/tmp/dashboards","name":"sc-dashboard-volume"}]},{"env":[{"name":"METHOD","value":"WATCH"},{"name":"LABEL","value":"grafana_datasource"},{"name":"FOLDER","value":"/etc/grafana/provisioning/datasources"},{"name":"RESOURCE","value":"both"},{"name":"REQ_USERNAME","valueFrom":{"secretKeyRef":{"key":"admin-user","name":"monitoring-grafana"}}},{"name":"REQ_PASSWORD","valueFrom":{"secretKeyRef":{"key":"admin-password","name":"monitoring-grafana"}}},{"name":"REQ_URL","value":"http://localhost:3000/api/admin/provisioning/datasources/reload"},{"name":"REQ_METHOD","value":"POST"}],"image":"quay.io/kiwigrid/k8s-sidecar:1.28.0","imagePullPolicy":"IfNotPresent","name":"grafana-sc-datasources","securityContext":{"allowPrivilegeEscalation":false,"capabilities":{"drop":["ALL"]},"seccompProfile":{"type":"RuntimeDefault"}},"volumeMounts":[{"mountPath":"/etc/grafana/provisioning/datasources","name":"sc-datasources-volume"}]},{"env":[{"name":"POD_IP","valueFrom":{"fieldRef":{"fieldPath":"status.podIP"}}},{"name":"GF_SECURITY_ADMIN_USER","valueFrom":{"secretKeyRef":{"key":"admin-user","name":"monitoring-grafana"}}},{"name":"GF_SECURITY_ADMIN_PASSWORD","valueFrom":{"secretKeyRef":{"key":"admin-password","name":"monitoring-grafana"}}},{"name":"GF_PATHS_DATA","value":"/var/lib/grafana/"},{"name":"GF_PATHS_LOGS","value":"/var/log/grafana"},{"name":"GF_PATHS_PLUGINS","value":"/var/lib/grafana/plugins"},{"name":"GF_PATHS_PROVISIONING","value":"/etc/grafana/provisioning"}],"image":"docker.io/grafana/grafana:11.2.2-security-01","imagePullPolicy":"IfNotPresent","livenessProbe":{"failureThreshold":10,"httpGet":{"path":"/api/health","port":3000},"initialDelaySeconds":60,"timeoutSeconds":30},"name":"grafana","ports":[{"containerPort":3000,"name":"grafana","protocol":"TCP"},{"containerPort":9094,"name":"gossip-tcp","protocol":"TCP"},{"containerPort":9094,"name":"gossip-udp","protocol":"UDP"}],"readinessProbe":{"httpGet":{"path":"/api/health","port":3000}},"securityContext":{"allowPrivilegeEscalation":false,"capabilities":{"drop":["ALL"]},"seccompProfile":{"type":"RuntimeDefault"}},"volumeMounts":[{"mountPath":"/etc/grafana/grafana.ini","name":"config","subPath":"grafana.ini"},{"mountPath":"/var/lib/grafana","name":"storage"},{"mountPath":"/tmp/dashboards","name":"sc-dashboard-volume"},{"mountPath":"/etc/grafana/provisioning/dashboards/sc-dashboardproviders.yaml","name":"sc-dashboard-provider","subPath":"provider.yaml"},{"mountPath":"/etc/grafana/provisioning/datasources","name":"sc-datasources-volume"}]}],"enableServiceLinks":true,"initContainers":[{"command":["chown","-R","472:472","/var/lib/grafana"],"image":"docker.io/library/busybox:1.31.1","imagePullPolicy":"IfNotPresent","name":"init-chown-data","securityContext":{"capabilities":{"add":["CHOWN"]},"runAsNonRoot":false,"runAsUser":0,"seccompProfile":{"type":"RuntimeDefault"}},"volumeMounts":[{"mountPath":"/var/lib/grafana","name":"storage"}]}],"securityContext":{"fsGroup":472,"runAsGroup":472,"runAsNonRoot":true,"runAsUser":472},"serviceAccountName":"monitoring-grafana","volumes":[{"configMap":{"name":"monitoring-grafana"},"name":"config"},{"name":"storage","persistentVolumeClaim":{"claimName":"monitoring-grafana"}},{"emptyDir":{},"name":"sc-dashboard-volume"},{"configMap":{"name":"monitoring-grafana-config-dashboards"},"name":"sc-dashboard-provider"},{"emptyDir":{},"name":"sc-datasources-volume"}]}}}}
    creationTimestamp: "2024-12-29T14:19:33Z"
    generation: 5
    labels:
      app.kubernetes.io/instance: monitoring
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: grafana
      app.kubernetes.io/version: 11.2.2-security-01
      argocd.argoproj.io/instance: monitoring
      helm.sh/chart: grafana-8.5.8
    name: monitoring-grafana
    namespace: monitoring
    resourceVersion: "18746453"
    uid: 002b7df9-3a83-4a03-a166-61b566783821
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/instance: monitoring
        app.kubernetes.io/name: grafana
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        annotations:
          checksum/config: 0e9cbd0ea8e24e32f7dfca5bab17a2ba05652642f0a09a4882833ae88e4cc4a3
          checksum/sc-dashboard-provider-config: e70bf6a851099d385178a76de9757bb0bef8299da6d8443602590e44f05fdf24
          checksum/secret: 42bbcab3a67ca3daa20142f240a2eba96ec843b11984a0cdd14677477a16e751
          kubectl.kubernetes.io/default-container: grafana
          kubectl.kubernetes.io/restartedAt: "2024-12-31T15:48:25+09:00"
        creationTimestamp: null
        labels:
          app.kubernetes.io/instance: monitoring
          app.kubernetes.io/name: grafana
      spec:
        automountServiceAccountToken: true
        containers:
        - env:
          - name: METHOD
            value: WATCH
          - name: LABEL
            value: grafana_dashboard
          - name: FOLDER
            value: /tmp/dashboards
          - name: RESOURCE
            value: both
          - name: REQ_USERNAME
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: monitoring-grafana
          - name: REQ_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: monitoring-grafana
          - name: REQ_URL
            value: http://localhost:3000/api/admin/provisioning/dashboards/reload
          - name: REQ_METHOD
            value: POST
          image: quay.io/kiwigrid/k8s-sidecar:1.28.0
          imagePullPolicy: IfNotPresent
          name: grafana-sc-dashboard
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /tmp/dashboards
            name: sc-dashboard-volume
        - env:
          - name: METHOD
            value: WATCH
          - name: LABEL
            value: grafana_datasource
          - name: FOLDER
            value: /etc/grafana/provisioning/datasources
          - name: RESOURCE
            value: both
          - name: REQ_USERNAME
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: monitoring-grafana
          - name: REQ_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: monitoring-grafana
          - name: REQ_URL
            value: http://localhost:3000/api/admin/provisioning/datasources/reload
          - name: REQ_METHOD
            value: POST
          image: quay.io/kiwigrid/k8s-sidecar:1.28.0
          imagePullPolicy: IfNotPresent
          name: grafana-sc-datasources
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/grafana/provisioning/datasources
            name: sc-datasources-volume
        - env:
          - name: POD_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.podIP
          - name: GF_SECURITY_ADMIN_USER
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: monitoring-grafana
          - name: GF_SECURITY_ADMIN_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: monitoring-grafana
          - name: GF_PATHS_DATA
            value: /var/lib/grafana/
          - name: GF_PATHS_LOGS
            value: /var/log/grafana
          - name: GF_PATHS_PLUGINS
            value: /var/lib/grafana/plugins
          - name: GF_PATHS_PROVISIONING
            value: /etc/grafana/provisioning
          image: docker.io/grafana/grafana:11.2.2-security-01
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 10
            httpGet:
              path: /api/health
              port: 3000
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 30
          name: grafana
          ports:
          - containerPort: 3000
            name: grafana
            protocol: TCP
          - containerPort: 9094
            name: gossip-tcp
            protocol: TCP
          - containerPort: 9094
            name: gossip-udp
            protocol: UDP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /api/health
              port: 3000
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/grafana/grafana.ini
            name: config
            subPath: grafana.ini
          - mountPath: /var/lib/grafana
            name: storage
          - mountPath: /tmp/dashboards
            name: sc-dashboard-volume
          - mountPath: /etc/grafana/provisioning/dashboards/sc-dashboardproviders.yaml
            name: sc-dashboard-provider
            subPath: provider.yaml
          - mountPath: /etc/grafana/provisioning/datasources
            name: sc-datasources-volume
        dnsPolicy: ClusterFirst
        enableServiceLinks: true
        initContainers:
        - command:
          - chown
          - -R
          - 472:472
          - /var/lib/grafana
          image: docker.io/library/busybox:1.31.1
          imagePullPolicy: IfNotPresent
          name: init-chown-data
          resources: {}
          securityContext:
            capabilities:
              add:
              - CHOWN
            runAsNonRoot: false
            runAsUser: 0
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/lib/grafana
            name: storage
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 472
          runAsGroup: 472
          runAsNonRoot: true
          runAsUser: 472
        serviceAccount: monitoring-grafana
        serviceAccountName: monitoring-grafana
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: monitoring-grafana
          name: config
        - name: storage
          persistentVolumeClaim:
            claimName: monitoring-grafana
        - emptyDir: {}
          name: sc-dashboard-volume
        - configMap:
            defaultMode: 420
            name: monitoring-grafana-config-dashboards
          name: sc-dashboard-provider
        - emptyDir: {}
          name: sc-datasources-volume
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-12-30T05:15:16Z"
      lastUpdateTime: "2024-12-30T05:15:16Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    - lastTransitionTime: "2024-12-29T14:19:33Z"
      lastUpdateTime: "2024-12-31T06:48:48Z"
      message: ReplicaSet "monitoring-grafana-7cbb8f4465" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    observedGeneration: 5
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-10-21T12:53:19Z"
    generation: 1
    labels:
      app.kubernetes.io/component: metrics
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kube-state-metrics
      app.kubernetes.io/part-of: kube-state-metrics
      app.kubernetes.io/version: 2.13.0
      helm.sh/chart: kube-state-metrics-5.25.1
    name: prometheus-kube-state-metrics
    namespace: monitoring
    resourceVersion: "22856128"
    uid: 5cef9e05-52ad-409e-9176-ea99cdfa6cd1
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/instance: prometheus
        app.kubernetes.io/name: kube-state-metrics
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: metrics
          app.kubernetes.io/instance: prometheus
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: kube-state-metrics
          app.kubernetes.io/part-of: kube-state-metrics
          app.kubernetes.io/version: 2.13.0
          helm.sh/chart: kube-state-metrics-5.25.1
      spec:
        automountServiceAccountToken: true
        containers:
        - args:
          - --port=8080
          - --resources=certificatesigningrequests,configmaps,cronjobs,daemonsets,deployments,endpoints,horizontalpodautoscalers,ingresses,jobs,leases,limitranges,mutatingwebhookconfigurations,namespaces,networkpolicies,nodes,persistentvolumeclaims,persistentvolumes,poddisruptionbudgets,pods,replicasets,replicationcontrollers,resourcequotas,secrets,services,statefulsets,storageclasses,validatingwebhookconfigurations,volumeattachments
          image: registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.13.0
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /livez
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: kube-state-metrics
          ports:
          - containerPort: 8080
            name: http
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /readyz
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          runAsGroup: 65534
          runAsNonRoot: true
          runAsUser: 65534
          seccompProfile:
            type: RuntimeDefault
        serviceAccount: prometheus-kube-state-metrics
        serviceAccountName: prometheus-kube-state-metrics
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-10-21T12:53:19Z"
      lastUpdateTime: "2024-10-21T12:53:45Z"
      message: ReplicaSet "prometheus-kube-state-metrics-74cdb59bff" has successfully
        progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2025-02-07T09:00:57Z"
      lastUpdateTime: "2025-02-07T09:00:57Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-10-21T12:53:19Z"
    generation: 1
    labels:
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: prometheus-pushgateway
      app.kubernetes.io/version: v1.9.0
      helm.sh/chart: prometheus-pushgateway-2.14.0
    name: prometheus-prometheus-pushgateway
    namespace: monitoring
    resourceVersion: "17859274"
    uid: e50843ed-3937-435b-9fe4-c1e595a3dac6
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/instance: prometheus
        app.kubernetes.io/name: prometheus-pushgateway
    strategy:
      type: Recreate
    template:
      metadata:
        creationTimestamp: null
        labels:
          app.kubernetes.io/instance: prometheus
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: prometheus-pushgateway
          app.kubernetes.io/version: v1.9.0
          helm.sh/chart: prometheus-pushgateway-2.14.0
      spec:
        automountServiceAccountToken: true
        containers:
        - image: quay.io/prometheus/pushgateway:v1.9.0
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /-/healthy
              port: 9091
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 10
          name: pushgateway
          ports:
          - containerPort: 9091
            name: metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /-/ready
              port: 9091
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 10
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /data
            name: storage-volume
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          runAsNonRoot: true
          runAsUser: 65534
        serviceAccount: prometheus-prometheus-pushgateway
        serviceAccountName: prometheus-prometheus-pushgateway
        terminationGracePeriodSeconds: 30
        volumes:
        - emptyDir: {}
          name: storage-volume
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-10-21T12:53:19Z"
      lastUpdateTime: "2024-10-21T12:53:52Z"
      message: ReplicaSet "prometheus-prometheus-pushgateway-66fc55f8d" has successfully
        progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2024-12-23T13:36:27Z"
      lastUpdateTime: "2024-12-23T13:36:27Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-10-21T12:53:19Z"
    generation: 1
    labels:
      app.kubernetes.io/component: server
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: prometheus
      app.kubernetes.io/part-of: prometheus
      app.kubernetes.io/version: v2.54.1
      helm.sh/chart: prometheus-25.27.0
    name: prometheus-server
    namespace: monitoring
    resourceVersion: "17859382"
    uid: af0e1c6e-0b6a-4a92-8c07-bf782b5326a2
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/component: server
        app.kubernetes.io/instance: prometheus
        app.kubernetes.io/name: prometheus
    strategy:
      type: Recreate
    template:
      metadata:
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: server
          app.kubernetes.io/instance: prometheus
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: prometheus
          app.kubernetes.io/part-of: prometheus
          app.kubernetes.io/version: v2.54.1
          helm.sh/chart: prometheus-25.27.0
      spec:
        containers:
        - args:
          - --watched-dir=/etc/config
          - --listen-address=0.0.0.0:8080
          - --reload-url=http://127.0.0.1:9090/-/reload
          image: quay.io/prometheus-operator/prometheus-config-reloader:v0.76.0
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: metrics
              scheme: HTTP
            initialDelaySeconds: 2
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: prometheus-server-configmap-reload
          ports:
          - containerPort: 8080
            name: metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: metrics
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/config
            name: config-volume
            readOnly: true
        - args:
          - --storage.tsdb.retention.time=15d
          - --config.file=/etc/config/prometheus.yml
          - --storage.tsdb.path=/data
          - --web.console.libraries=/etc/prometheus/console_libraries
          - --web.console.templates=/etc/prometheus/consoles
          - --web.enable-lifecycle
          image: quay.io/prometheus/prometheus:v2.54.1
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /-/healthy
              port: 9090
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 15
            successThreshold: 1
            timeoutSeconds: 10
          name: prometheus-server
          ports:
          - containerPort: 9090
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /-/ready
              port: 9090
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 4
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/config
            name: config-volume
          - mountPath: /data
            name: storage-volume
        dnsPolicy: ClusterFirst
        enableServiceLinks: true
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          runAsGroup: 65534
          runAsNonRoot: true
          runAsUser: 65534
        serviceAccount: prometheus-server
        serviceAccountName: prometheus-server
        terminationGracePeriodSeconds: 300
        volumes:
        - configMap:
            defaultMode: 420
            name: prometheus-server
          name: config-volume
        - name: storage-volume
          persistentVolumeClaim:
            claimName: prometheus-server
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-10-21T12:53:19Z"
      lastUpdateTime: "2024-10-21T12:54:37Z"
      message: ReplicaSet "prometheus-server-dd484f8d9" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2024-12-23T13:37:33Z"
      lastUpdateTime: "2024-12-23T13:37:33Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: Deployment
  metadata:
    annotations:
      deployment.kubernetes.io/revision: "1"
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"labels":{"app":"front-app","argocd.argoproj.io/instance":"zicdding-front-app"},"name":"zicdding-front-app","namespace":"zicdding"},"spec":{"replicas":1,"selector":{"matchLabels":{"app":"front-app"}},"template":{"metadata":{"labels":{"app":"front-app"}},"spec":{"containers":[{"image":"zicdding0904/zicdding-front:0.0.1","name":"zicdding-front-app","ports":[{"containerPort":3000}]}]}}}}
    creationTimestamp: "2024-08-16T13:06:18Z"
    generation: 1
    labels:
      app: front-app
      argocd.argoproj.io/instance: zicdding-front-app
    name: zicdding-front-app
    namespace: zicdding
    resourceVersion: "17859167"
    uid: 77fa48ab-082f-4631-b013-c6902753e2a3
  spec:
    progressDeadlineSeconds: 600
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: front-app
    strategy:
      rollingUpdate:
        maxSurge: 25%
        maxUnavailable: 25%
      type: RollingUpdate
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: front-app
      spec:
        containers:
        - image: zicdding0904/zicdding-front:0.0.1
          imagePullPolicy: IfNotPresent
          name: zicdding-front-app
          ports:
          - containerPort: 3000
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    conditions:
    - lastTransitionTime: "2024-08-16T13:06:18Z"
      lastUpdateTime: "2024-08-16T13:06:20Z"
      message: ReplicaSet "zicdding-front-app-569d9cf59b" has successfully progressed.
      reason: NewReplicaSetAvailable
      status: "True"
      type: Progressing
    - lastTransitionTime: "2024-12-23T13:36:21Z"
      lastUpdateTime: "2024-12-23T13:36:21Z"
      message: Deployment has minimum availability.
      reason: MinimumReplicasAvailable
      status: "True"
      type: Available
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: argocd
      meta.helm.sh/release-namespace: argocd
    creationTimestamp: "2024-07-19T17:25:51Z"
    generation: 1
    labels:
      app.kubernetes.io/component: applicationset-controller
      app.kubernetes.io/instance: argocd
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: argocd-applicationset-controller
      app.kubernetes.io/part-of: argocd
      app.kubernetes.io/version: v2.11.5
      helm.sh/chart: argo-cd-7.3.9
      pod-template-hash: 56d4d6458b
    name: argocd-applicationset-controller-56d4d6458b
    namespace: argocd
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: argocd-applicationset-controller
      uid: b9249080-f1c3-49d2-9e3f-823c701b3fc5
    resourceVersion: "17859116"
    uid: 85e1a1a4-44c7-4049-be7c-dccb964c4dfe
  spec:
    replicas: 1
    selector:
      matchLabels:
        app.kubernetes.io/instance: argocd
        app.kubernetes.io/name: argocd-applicationset-controller
        pod-template-hash: 56d4d6458b
    template:
      metadata:
        annotations:
          checksum/cmd-params: bcbb2496303699a508a41b49a033d6f92d273aba139ec132105f461a1d84fa46
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: applicationset-controller
          app.kubernetes.io/instance: argocd
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: argocd-applicationset-controller
          app.kubernetes.io/part-of: argocd
          app.kubernetes.io/version: v2.11.5
          helm.sh/chart: argo-cd-7.3.9
          pod-template-hash: 56d4d6458b
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: argocd-applicationset-controller
                topologyKey: kubernetes.io/hostname
              weight: 100
        automountServiceAccountToken: true
        containers:
        - args:
          - /usr/local/bin/argocd-applicationset-controller
          - --metrics-addr=:8080
          - --probe-addr=:8081
          - --webhook-addr=:7000
          env:
          - name: NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_GLOBAL_PRESERVED_ANNOTATIONS
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.global.preserved.annotations
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_GLOBAL_PRESERVED_LABELS
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.global.preserved.labels
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_LEADER_ELECTION
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.enable.leader.election
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER
            valueFrom:
              configMapKeyRef:
                key: repo.server
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_POLICY
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.policy
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_POLICY_OVERRIDE
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.enable.policy.override
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_DEBUG
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.debug
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_LOGFORMAT
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.log.format
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_LOGLEVEL
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.log.level
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_DRY_RUN
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.dryrun
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_GIT_MODULES_ENABLED
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.enable.git.submodule
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_PROGRESSIVE_SYNCS
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.enable.progressive.syncs
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_NEW_GIT_FILE_GLOBBING
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.enable.new.git.file.globbing
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_PLAINTEXT
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.repo.server.plaintext
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_STRICT_TLS
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.repo.server.strict.tls
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_REPO_SERVER_TIMEOUT_SECONDS
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.repo.server.timeout.seconds
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_CONCURRENT_RECONCILIATIONS
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.concurrent.reconciliations.max
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_NAMESPACES
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.namespaces
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_SCM_ROOT_CA_PATH
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.scm.root.ca.path
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_ALLOWED_SCM_PROVIDERS
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.allowed.scm.providers
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATIONSET_CONTROLLER_ENABLE_SCM_PROVIDERS
            valueFrom:
              configMapKeyRef:
                key: applicationsetcontroller.enable.scm.providers
                name: argocd-cmd-params-cm
                optional: true
          image: quay.io/argoproj/argocd:v2.11.5
          imagePullPolicy: IfNotPresent
          name: applicationset-controller
          ports:
          - containerPort: 8080
            name: metrics
            protocol: TCP
          - containerPort: 8081
            name: probe
            protocol: TCP
          - containerPort: 7000
            name: webhook
            protocol: TCP
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /app/config/ssh
            name: ssh-known-hosts
          - mountPath: /app/config/tls
            name: tls-certs
          - mountPath: /app/config/gpg/source
            name: gpg-keys
          - mountPath: /app/config/gpg/keys
            name: gpg-keyring
          - mountPath: /app/config/reposerver/tls
            name: argocd-repo-server-tls
          - mountPath: /tmp
            name: tmp
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: argocd-applicationset-controller
        serviceAccountName: argocd-applicationset-controller
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: argocd-ssh-known-hosts-cm
          name: ssh-known-hosts
        - configMap:
            defaultMode: 420
            name: argocd-tls-certs-cm
          name: tls-certs
        - configMap:
            defaultMode: 420
            name: argocd-gpg-keys-cm
          name: gpg-keys
        - emptyDir: {}
          name: gpg-keyring
        - emptyDir: {}
          name: tmp
        - name: argocd-repo-server-tls
          secret:
            defaultMode: 420
            items:
            - key: tls.crt
              path: tls.crt
            - key: tls.key
              path: tls.key
            - key: ca.crt
              path: ca.crt
            optional: true
            secretName: argocd-repo-server-tls
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: argocd
      meta.helm.sh/release-namespace: argocd
    creationTimestamp: "2024-07-19T17:25:51Z"
    generation: 1
    labels:
      app.kubernetes.io/component: dex-server
      app.kubernetes.io/instance: argocd
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: argocd-dex-server
      app.kubernetes.io/part-of: argocd
      app.kubernetes.io/version: v2.11.5
      helm.sh/chart: argo-cd-7.3.9
      pod-template-hash: 7db6876989
    name: argocd-dex-server-7db6876989
    namespace: argocd
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: argocd-dex-server
      uid: 898e47f3-4a6d-49dc-837e-c37edb298f9f
    resourceVersion: "17859285"
    uid: bba8b4d4-7c02-454a-b3ea-2f7b4e350ea6
  spec:
    replicas: 1
    selector:
      matchLabels:
        app.kubernetes.io/instance: argocd
        app.kubernetes.io/name: argocd-dex-server
        pod-template-hash: 7db6876989
    template:
      metadata:
        annotations:
          checksum/cmd-params: bcbb2496303699a508a41b49a033d6f92d273aba139ec132105f461a1d84fa46
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: dex-server
          app.kubernetes.io/instance: argocd
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: argocd-dex-server
          app.kubernetes.io/part-of: argocd
          app.kubernetes.io/version: v2.11.5
          helm.sh/chart: argo-cd-7.3.9
          pod-template-hash: 7db6876989
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: argocd-dex-server
                topologyKey: kubernetes.io/hostname
              weight: 100
        automountServiceAccountToken: true
        containers:
        - args:
          - rundex
          command:
          - /shared/argocd-dex
          - --logformat=text
          - --loglevel=info
          env:
          - name: ARGOCD_DEX_SERVER_DISABLE_TLS
            valueFrom:
              configMapKeyRef:
                key: dexserver.disable.tls
                name: argocd-cmd-params-cm
                optional: true
          image: ghcr.io/dexidp/dex:v2.38.0
          imagePullPolicy: IfNotPresent
          name: dex-server
          ports:
          - containerPort: 5556
            name: http
            protocol: TCP
          - containerPort: 5557
            name: grpc
            protocol: TCP
          - containerPort: 5558
            name: metrics
            protocol: TCP
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /shared
            name: static-files
          - mountPath: /tmp
            name: dexconfig
          - mountPath: /tls
            name: argocd-dex-server-tls
        dnsPolicy: ClusterFirst
        initContainers:
        - command:
          - /bin/cp
          - -n
          - /usr/local/bin/argocd
          - /shared/argocd-dex
          image: quay.io/argoproj/argocd:v2.11.5
          imagePullPolicy: IfNotPresent
          name: copyutil
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /shared
            name: static-files
          - mountPath: /tmp
            name: dexconfig
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: argocd-dex-server
        serviceAccountName: argocd-dex-server
        terminationGracePeriodSeconds: 30
        volumes:
        - emptyDir: {}
          name: static-files
        - emptyDir: {}
          name: dexconfig
        - name: argocd-dex-server-tls
          secret:
            defaultMode: 420
            items:
            - key: tls.crt
              path: tls.crt
            - key: tls.key
              path: tls.key
            - key: ca.crt
              path: ca.crt
            optional: true
            secretName: argocd-dex-server-tls
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "1"
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: argocd
      meta.helm.sh/release-namespace: argocd
    creationTimestamp: "2024-07-19T17:25:51Z"
    generation: 1
    labels:
      app.kubernetes.io/component: notifications-controller
      app.kubernetes.io/instance: argocd
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: argocd-notifications-controller
      app.kubernetes.io/part-of: argocd
      app.kubernetes.io/version: v2.11.5
      helm.sh/chart: argo-cd-7.3.9
      pod-template-hash: 5c8658678f
    name: argocd-notifications-controller-5c8658678f
    namespace: argocd
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: argocd-notifications-controller
      uid: a7e0541c-ef85-484a-9493-ec6d0cd5266b
    resourceVersion: "15278031"
    uid: 8b9f5444-40e4-42fd-9188-9e1246a5b76d
  spec:
    replicas: 1
    selector:
      matchLabels:
        app.kubernetes.io/instance: argocd
        app.kubernetes.io/name: argocd-notifications-controller
        pod-template-hash: 5c8658678f
    template:
      metadata:
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: notifications-controller
          app.kubernetes.io/instance: argocd
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: argocd-notifications-controller
          app.kubernetes.io/part-of: argocd
          app.kubernetes.io/version: v2.11.5
          helm.sh/chart: argo-cd-7.3.9
          pod-template-hash: 5c8658678f
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: argocd-notifications-controller
                topologyKey: kubernetes.io/hostname
              weight: 100
        automountServiceAccountToken: true
        containers:
        - args:
          - /usr/local/bin/argocd-notifications
          - --metrics-port=9001
          - --loglevel=info
          - --logformat=text
          - --namespace=argocd
          - --argocd-repo-server=argocd-repo-server:8081
          - --secret-name=argocd-notifications-secret
          env:
          - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGLEVEL
            valueFrom:
              configMapKeyRef:
                key: notificationscontroller.log.level
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_NOTIFICATIONS_CONTROLLER_LOGFORMAT
            valueFrom:
              configMapKeyRef:
                key: notificationscontroller.log.format
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATION_NAMESPACES
            valueFrom:
              configMapKeyRef:
                key: application.namespaces
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_NOTIFICATION_CONTROLLER_SELF_SERVICE_NOTIFICATION_ENABLED
            valueFrom:
              configMapKeyRef:
                key: notificationscontroller.selfservice.enabled
                name: argocd-cmd-params-cm
                optional: true
          image: quay.io/argoproj/argocd:v2.11.5
          imagePullPolicy: IfNotPresent
          name: notifications-controller
          ports:
          - containerPort: 9001
            name: metrics
            protocol: TCP
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /app/config/tls
            name: tls-certs
          - mountPath: /app/config/reposerver/tls
            name: argocd-repo-server-tls
          workingDir: /app
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: argocd-notifications-controller
        serviceAccountName: argocd-notifications-controller
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: argocd-tls-certs-cm
          name: tls-certs
        - name: argocd-repo-server-tls
          secret:
            defaultMode: 420
            items:
            - key: tls.crt
              path: tls.crt
            - key: tls.key
              path: tls.key
            - key: ca.crt
              path: ca.crt
            optional: true
            secretName: argocd-repo-server-tls
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: argocd
      meta.helm.sh/release-namespace: argocd
    creationTimestamp: "2024-07-19T17:25:51Z"
    generation: 1
    labels:
      app.kubernetes.io/component: redis
      app.kubernetes.io/instance: argocd
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: argocd-redis
      app.kubernetes.io/part-of: argocd
      app.kubernetes.io/version: v2.11.5
      helm.sh/chart: argo-cd-7.3.9
      pod-template-hash: 6d9f6dc894
    name: argocd-redis-6d9f6dc894
    namespace: argocd
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: argocd-redis
      uid: 45324268-5269-4eed-9708-a4af5b18ebb7
    resourceVersion: "15278138"
    uid: 811c81f3-5f29-4fb9-b308-a603f40593d3
  spec:
    replicas: 1
    selector:
      matchLabels:
        app.kubernetes.io/name: argocd-redis
        pod-template-hash: 6d9f6dc894
    template:
      metadata:
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: redis
          app.kubernetes.io/instance: argocd
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: argocd-redis
          app.kubernetes.io/part-of: argocd
          app.kubernetes.io/version: v2.11.5
          helm.sh/chart: argo-cd-7.3.9
          pod-template-hash: 6d9f6dc894
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: argocd-redis
                topologyKey: kubernetes.io/hostname
              weight: 100
        automountServiceAccountToken: true
        containers:
        - args:
          - --save
          - ""
          - --appendonly
          - "no"
          - --requirepass $(REDIS_PASSWORD)
          env:
          - name: REDIS_PASSWORD
            valueFrom:
              secretKeyRef:
                key: auth
                name: argocd-redis
          image: public.ecr.aws/docker/library/redis:7.2.4-alpine
          imagePullPolicy: IfNotPresent
          name: redis
          ports:
          - containerPort: 6379
            name: redis
            protocol: TCP
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /health
            name: health
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          runAsNonRoot: true
          runAsUser: 999
          seccompProfile:
            type: RuntimeDefault
        serviceAccount: default
        serviceAccountName: default
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 493
            name: argocd-redis-health-configmap
          name: health
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: argocd
      meta.helm.sh/release-namespace: argocd
    creationTimestamp: "2024-07-19T17:25:51Z"
    generation: 1
    labels:
      app.kubernetes.io/component: repo-server
      app.kubernetes.io/instance: argocd
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: argocd-repo-server
      app.kubernetes.io/part-of: argocd
      app.kubernetes.io/version: v2.11.5
      helm.sh/chart: argo-cd-7.3.9
      pod-template-hash: 6b5cdc488b
    name: argocd-repo-server-6b5cdc488b
    namespace: argocd
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: argocd-repo-server
      uid: fcf6fcc7-f3d1-4ceb-90b4-9514b00c396b
    resourceVersion: "22846814"
    uid: 354e4fe0-2efa-4b08-b890-debb92b9e056
  spec:
    replicas: 1
    selector:
      matchLabels:
        app.kubernetes.io/instance: argocd
        app.kubernetes.io/name: argocd-repo-server
        pod-template-hash: 6b5cdc488b
    template:
      metadata:
        annotations:
          checksum/cm: 9156c689cecc9c1147df3672959659693b08b4c335adc717836ea9bc0cc75160
          checksum/cmd-params: bcbb2496303699a508a41b49a033d6f92d273aba139ec132105f461a1d84fa46
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: repo-server
          app.kubernetes.io/instance: argocd
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: argocd-repo-server
          app.kubernetes.io/part-of: argocd
          app.kubernetes.io/version: v2.11.5
          helm.sh/chart: argo-cd-7.3.9
          pod-template-hash: 6b5cdc488b
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: argocd-repo-server
                topologyKey: kubernetes.io/hostname
              weight: 100
        automountServiceAccountToken: true
        containers:
        - args:
          - /usr/local/bin/argocd-repo-server
          - --port=8081
          - --metrics-port=8084
          env:
          - name: ARGOCD_REPO_SERVER_NAME
            value: argocd-repo-server
          - name: ARGOCD_RECONCILIATION_TIMEOUT
            valueFrom:
              configMapKeyRef:
                key: timeout.reconciliation
                name: argocd-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_LOGFORMAT
            valueFrom:
              configMapKeyRef:
                key: reposerver.log.format
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_LOGLEVEL
            valueFrom:
              configMapKeyRef:
                key: reposerver.log.level
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_PARALLELISM_LIMIT
            valueFrom:
              configMapKeyRef:
                key: reposerver.parallelism.limit
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_LISTEN_ADDRESS
            valueFrom:
              configMapKeyRef:
                key: reposerver.listen.address
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_LISTEN_METRICS_ADDRESS
            valueFrom:
              configMapKeyRef:
                key: reposerver.metrics.listen.address
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_DISABLE_TLS
            valueFrom:
              configMapKeyRef:
                key: reposerver.disable.tls
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_TLS_MIN_VERSION
            valueFrom:
              configMapKeyRef:
                key: reposerver.tls.minversion
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_TLS_MAX_VERSION
            valueFrom:
              configMapKeyRef:
                key: reposerver.tls.maxversion
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_TLS_CIPHERS
            valueFrom:
              configMapKeyRef:
                key: reposerver.tls.ciphers
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_CACHE_EXPIRATION
            valueFrom:
              configMapKeyRef:
                key: reposerver.repo.cache.expiration
                name: argocd-cmd-params-cm
                optional: true
          - name: REDIS_SERVER
            valueFrom:
              configMapKeyRef:
                key: redis.server
                name: argocd-cmd-params-cm
                optional: true
          - name: REDIS_COMPRESSION
            valueFrom:
              configMapKeyRef:
                key: redis.compression
                name: argocd-cmd-params-cm
                optional: true
          - name: REDISDB
            valueFrom:
              configMapKeyRef:
                key: redis.db
                name: argocd-cmd-params-cm
                optional: true
          - name: REDIS_USERNAME
            valueFrom:
              secretKeyRef:
                key: redis-username
                name: argocd-redis
                optional: true
          - name: REDIS_PASSWORD
            valueFrom:
              secretKeyRef:
                key: auth
                name: argocd-redis
                optional: true
          - name: REDIS_SENTINEL_USERNAME
            valueFrom:
              secretKeyRef:
                key: redis-sentinel-username
                name: argocd-redis
                optional: true
          - name: REDIS_SENTINEL_PASSWORD
            valueFrom:
              secretKeyRef:
                key: redis-sentinel-password
                name: argocd-redis
                optional: true
          - name: ARGOCD_DEFAULT_CACHE_EXPIRATION
            valueFrom:
              configMapKeyRef:
                key: reposerver.default.cache.expiration
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_OTLP_ADDRESS
            valueFrom:
              configMapKeyRef:
                key: otlp.address
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_OTLP_INSECURE
            valueFrom:
              configMapKeyRef:
                key: otlp.insecure
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_OTLP_HEADERS
            valueFrom:
              configMapKeyRef:
                key: otlp.headers
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_MAX_COMBINED_DIRECTORY_MANIFESTS_SIZE
            valueFrom:
              configMapKeyRef:
                key: reposerver.max.combined.directory.manifests.size
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_PLUGIN_TAR_EXCLUSIONS
            valueFrom:
              configMapKeyRef:
                key: reposerver.plugin.tar.exclusions
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_ALLOW_OUT_OF_BOUNDS_SYMLINKS
            valueFrom:
              configMapKeyRef:
                key: reposerver.allow.oob.symlinks
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_TAR_SIZE
            valueFrom:
              configMapKeyRef:
                key: reposerver.streamed.manifest.max.tar.size
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_STREAMED_MANIFEST_MAX_EXTRACTED_SIZE
            valueFrom:
              configMapKeyRef:
                key: reposerver.streamed.manifest.max.extracted.size
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_HELM_MANIFEST_MAX_EXTRACTED_SIZE
            valueFrom:
              configMapKeyRef:
                key: reposerver.helm.manifest.max.extracted.size
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REPO_SERVER_DISABLE_HELM_MANIFEST_MAX_EXTRACTED_SIZE
            valueFrom:
              configMapKeyRef:
                key: reposerver.disable.helm.manifest.max.extracted.size
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_GIT_MODULES_ENABLED
            valueFrom:
              configMapKeyRef:
                key: reposerver.enable.git.submodule
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_GIT_LS_REMOTE_PARALLELISM_LIMIT
            valueFrom:
              configMapKeyRef:
                key: reposerver.git.lsremote.parallelism.limit
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_GIT_REQUEST_TIMEOUT
            valueFrom:
              configMapKeyRef:
                key: reposerver.git.request.timeout
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_REVISION_CACHE_LOCK_TIMEOUT
            valueFrom:
              configMapKeyRef:
                key: reposerver.revision.cache.lock.timeout
                name: argocd-cmd-params-cm
                optional: true
          - name: HELM_CACHE_HOME
            value: /helm-working-dir
          - name: HELM_CONFIG_HOME
            value: /helm-working-dir
          - name: HELM_DATA_HOME
            value: /helm-working-dir
          image: quay.io/argoproj/argocd:v2.11.5
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz?full=true
              port: metrics
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: repo-server
          ports:
          - containerPort: 8081
            name: repo-server
            protocol: TCP
          - containerPort: 8084
            name: metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: metrics
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /app/config/ssh
            name: ssh-known-hosts
          - mountPath: /app/config/tls
            name: tls-certs
          - mountPath: /app/config/gpg/source
            name: gpg-keys
          - mountPath: /app/config/gpg/keys
            name: gpg-keyring
          - mountPath: /app/config/reposerver/tls
            name: argocd-repo-server-tls
          - mountPath: /helm-working-dir
            name: helm-working-dir
          - mountPath: /home/argocd/cmp-server/plugins
            name: plugins
          - mountPath: /tmp
            name: tmp
        dnsPolicy: ClusterFirst
        initContainers:
        - command:
          - /bin/cp
          - -n
          - /usr/local/bin/argocd
          - /var/run/argocd/argocd-cmp-server
          image: quay.io/argoproj/argocd:v2.11.5
          imagePullPolicy: IfNotPresent
          name: copyutil
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/run/argocd
            name: var-files
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: argocd-repo-server
        serviceAccountName: argocd-repo-server
        terminationGracePeriodSeconds: 30
        volumes:
        - emptyDir: {}
          name: helm-working-dir
        - emptyDir: {}
          name: plugins
        - emptyDir: {}
          name: var-files
        - emptyDir: {}
          name: tmp
        - configMap:
            defaultMode: 420
            name: argocd-ssh-known-hosts-cm
          name: ssh-known-hosts
        - configMap:
            defaultMode: 420
            name: argocd-tls-certs-cm
          name: tls-certs
        - configMap:
            defaultMode: 420
            name: argocd-gpg-keys-cm
          name: gpg-keys
        - emptyDir: {}
          name: gpg-keyring
        - name: argocd-repo-server-tls
          secret:
            defaultMode: 420
            items:
            - key: tls.crt
              path: tls.crt
            - key: tls.key
              path: tls.key
            - key: ca.crt
              path: ca.crt
            optional: true
            secretName: argocd-repo-server-tls
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: argocd
      meta.helm.sh/release-namespace: argocd
    creationTimestamp: "2024-07-19T17:25:51Z"
    generation: 1
    labels:
      app.kubernetes.io/component: server
      app.kubernetes.io/instance: argocd
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: argocd-server
      app.kubernetes.io/part-of: argocd
      app.kubernetes.io/version: v2.11.5
      helm.sh/chart: argo-cd-7.3.9
      pod-template-hash: 85f4f7b9f7
    name: argocd-server-85f4f7b9f7
    namespace: argocd
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: argocd-server
      uid: e5c14ca8-810a-4d27-9307-998878397073
    resourceVersion: "17859223"
    uid: 5a8a7973-a730-40b8-a50c-5210f6f350b8
  spec:
    replicas: 1
    selector:
      matchLabels:
        app.kubernetes.io/instance: argocd
        app.kubernetes.io/name: argocd-server
        pod-template-hash: 85f4f7b9f7
    template:
      metadata:
        annotations:
          checksum/cm: 9156c689cecc9c1147df3672959659693b08b4c335adc717836ea9bc0cc75160
          checksum/cmd-params: bcbb2496303699a508a41b49a033d6f92d273aba139ec132105f461a1d84fa46
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: server
          app.kubernetes.io/instance: argocd
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: argocd-server
          app.kubernetes.io/part-of: argocd
          app.kubernetes.io/version: v2.11.5
          helm.sh/chart: argo-cd-7.3.9
          pod-template-hash: 85f4f7b9f7
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: argocd-server
                topologyKey: kubernetes.io/hostname
              weight: 100
        automountServiceAccountToken: true
        containers:
        - args:
          - /usr/local/bin/argocd-server
          - --port=8080
          - --metrics-port=8083
          - --rootpath
          - /argocd
          env:
          - name: ARGOCD_SERVER_NAME
            value: argocd-server
          - name: ARGOCD_SERVER_INSECURE
            valueFrom:
              configMapKeyRef:
                key: server.insecure
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_BASEHREF
            valueFrom:
              configMapKeyRef:
                key: server.basehref
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_ROOTPATH
            valueFrom:
              configMapKeyRef:
                key: server.rootpath
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_LOGFORMAT
            valueFrom:
              configMapKeyRef:
                key: server.log.format
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_LOG_LEVEL
            valueFrom:
              configMapKeyRef:
                key: server.log.level
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_REPO_SERVER
            valueFrom:
              configMapKeyRef:
                key: repo.server
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_DEX_SERVER
            valueFrom:
              configMapKeyRef:
                key: server.dex.server
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_DISABLE_AUTH
            valueFrom:
              configMapKeyRef:
                key: server.disable.auth
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_ENABLE_GZIP
            valueFrom:
              configMapKeyRef:
                key: server.enable.gzip
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_REPO_SERVER_TIMEOUT_SECONDS
            valueFrom:
              configMapKeyRef:
                key: server.repo.server.timeout.seconds
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_X_FRAME_OPTIONS
            valueFrom:
              configMapKeyRef:
                key: server.x.frame.options
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_CONTENT_SECURITY_POLICY
            valueFrom:
              configMapKeyRef:
                key: server.content.security.policy
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_REPO_SERVER_PLAINTEXT
            valueFrom:
              configMapKeyRef:
                key: server.repo.server.plaintext
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_REPO_SERVER_STRICT_TLS
            valueFrom:
              configMapKeyRef:
                key: server.repo.server.strict.tls
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_DEX_SERVER_PLAINTEXT
            valueFrom:
              configMapKeyRef:
                key: server.dex.server.plaintext
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_DEX_SERVER_STRICT_TLS
            valueFrom:
              configMapKeyRef:
                key: server.dex.server.strict.tls
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_TLS_MIN_VERSION
            valueFrom:
              configMapKeyRef:
                key: server.tls.minversion
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_TLS_MAX_VERSION
            valueFrom:
              configMapKeyRef:
                key: server.tls.maxversion
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_TLS_CIPHERS
            valueFrom:
              configMapKeyRef:
                key: server.tls.ciphers
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_CONNECTION_STATUS_CACHE_EXPIRATION
            valueFrom:
              configMapKeyRef:
                key: server.connection.status.cache.expiration
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_OIDC_CACHE_EXPIRATION
            valueFrom:
              configMapKeyRef:
                key: server.oidc.cache.expiration
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_LOGIN_ATTEMPTS_EXPIRATION
            valueFrom:
              configMapKeyRef:
                key: server.login.attempts.expiration
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_STATIC_ASSETS
            valueFrom:
              configMapKeyRef:
                key: server.staticassets
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APP_STATE_CACHE_EXPIRATION
            valueFrom:
              configMapKeyRef:
                key: server.app.state.cache.expiration
                name: argocd-cmd-params-cm
                optional: true
          - name: REDIS_SERVER
            valueFrom:
              configMapKeyRef:
                key: redis.server
                name: argocd-cmd-params-cm
                optional: true
          - name: REDIS_COMPRESSION
            valueFrom:
              configMapKeyRef:
                key: redis.compression
                name: argocd-cmd-params-cm
                optional: true
          - name: REDISDB
            valueFrom:
              configMapKeyRef:
                key: redis.db
                name: argocd-cmd-params-cm
                optional: true
          - name: REDIS_USERNAME
            valueFrom:
              secretKeyRef:
                key: redis-username
                name: argocd-redis
                optional: true
          - name: REDIS_PASSWORD
            valueFrom:
              secretKeyRef:
                key: auth
                name: argocd-redis
                optional: true
          - name: REDIS_SENTINEL_USERNAME
            valueFrom:
              secretKeyRef:
                key: redis-sentinel-username
                name: argocd-redis
                optional: true
          - name: REDIS_SENTINEL_PASSWORD
            valueFrom:
              secretKeyRef:
                key: redis-sentinel-password
                name: argocd-redis
                optional: true
          - name: ARGOCD_DEFAULT_CACHE_EXPIRATION
            valueFrom:
              configMapKeyRef:
                key: server.default.cache.expiration
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_MAX_COOKIE_NUMBER
            valueFrom:
              configMapKeyRef:
                key: server.http.cookie.maxnumber
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_LISTEN_ADDRESS
            valueFrom:
              configMapKeyRef:
                key: server.listen.address
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_METRICS_LISTEN_ADDRESS
            valueFrom:
              configMapKeyRef:
                key: server.metrics.listen.address
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_OTLP_ADDRESS
            valueFrom:
              configMapKeyRef:
                key: otlp.address
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_OTLP_INSECURE
            valueFrom:
              configMapKeyRef:
                key: otlp.insecure
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_OTLP_HEADERS
            valueFrom:
              configMapKeyRef:
                key: otlp.headers
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATION_NAMESPACES
            valueFrom:
              configMapKeyRef:
                key: application.namespaces
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_SERVER_ENABLE_PROXY_EXTENSION
            valueFrom:
              configMapKeyRef:
                key: server.enable.proxy.extension
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_K8SCLIENT_RETRY_MAX
            valueFrom:
              configMapKeyRef:
                key: server.k8sclient.retry.max
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_K8SCLIENT_RETRY_BASE_BACKOFF
            valueFrom:
              configMapKeyRef:
                key: server.k8sclient.retry.base.backoff
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_API_CONTENT_TYPES
            valueFrom:
              configMapKeyRef:
                key: server.api.content.types
                name: argocd-cmd-params-cm
                optional: true
          image: quay.io/argoproj/argocd:v2.11.5
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz?full=true
              port: server
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: server
          ports:
          - containerPort: 8080
            name: server
            protocol: TCP
          - containerPort: 8083
            name: metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: server
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /app/config/ssh
            name: ssh-known-hosts
          - mountPath: /app/config/tls
            name: tls-certs
          - mountPath: /app/config/server/tls
            name: argocd-repo-server-tls
          - mountPath: /app/config/dex/tls
            name: argocd-dex-server-tls
          - mountPath: /home/argocd
            name: plugins-home
          - mountPath: /shared/app/custom
            name: styles
          - mountPath: /tmp
            name: tmp
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: argocd-server
        serviceAccountName: argocd-server
        terminationGracePeriodSeconds: 30
        volumes:
        - emptyDir: {}
          name: plugins-home
        - emptyDir: {}
          name: tmp
        - configMap:
            defaultMode: 420
            name: argocd-ssh-known-hosts-cm
          name: ssh-known-hosts
        - configMap:
            defaultMode: 420
            name: argocd-tls-certs-cm
          name: tls-certs
        - configMap:
            defaultMode: 420
            name: argocd-styles-cm
            optional: true
          name: styles
        - name: argocd-repo-server-tls
          secret:
            defaultMode: 420
            items:
            - key: tls.crt
              path: tls.crt
            - key: tls.key
              path: tls.key
            - key: ca.crt
              path: ca.crt
            optional: true
            secretName: argocd-repo-server-tls
        - name: argocd-dex-server-tls
          secret:
            defaultMode: 420
            items:
            - key: tls.crt
              path: tls.crt
            - key: ca.crt
              path: ca.crt
            optional: true
            secretName: argocd-dex-server-tls
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "2"
      deployment.kubernetes.io/max-replicas: "3"
      deployment.kubernetes.io/revision: "3"
    creationTimestamp: "2024-12-30T04:32:00Z"
    generation: 4
    labels:
      app: backend
      pod-template-hash: 58859b4ccd
    name: backend-58859b4ccd
    namespace: backend
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: backend
      uid: 7d4a6583-3d4c-4841-8cef-bc2c0edb6f03
    resourceVersion: "18994790"
    uid: 1fbc5fc7-3f01-4771-811c-a0a8586dfc45
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: backend
        pod-template-hash: 58859b4ccd
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2024-12-30T13:32:00+09:00"
        creationTimestamp: null
        labels:
          app: backend
          pod-template-hash: 58859b4ccd
      spec:
        containers:
        - env:
          - name: SPRING_CONFIG_LOCATION
            value: /app/config/application.yaml
          image: zicdding0904/zicdding-class-back:latest
          imagePullPolicy: Always
          name: backend
          ports:
          - containerPort: 3000
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /app/config/application.yaml
            name: config-volume
            subPath: application.yaml
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: backend-config
          name: config-volume
  status:
    observedGeneration: 4
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "2"
      deployment.kubernetes.io/max-replicas: "3"
      deployment.kubernetes.io/revision: "4"
      deployment.kubernetes.io/revision-history: "1"
    creationTimestamp: "2024-12-26T14:41:51Z"
    generation: 7
    labels:
      app: backend
      pod-template-hash: 5978dddc8d
    name: backend-5978dddc8d
    namespace: backend
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: backend
      uid: 7d4a6583-3d4c-4841-8cef-bc2c0edb6f03
    resourceVersion: "19414830"
    uid: 022e6120-93ca-4170-8ce0-0f8633f837d0
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: backend
        pod-template-hash: 5978dddc8d
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: backend
          pod-template-hash: 5978dddc8d
      spec:
        containers:
        - env:
          - name: SPRING_CONFIG_LOCATION
            value: /app/config/application.yaml
          image: zicdding0904/zicdding-class-back:latest
          imagePullPolicy: Always
          name: backend
          ports:
          - containerPort: 3000
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /app/config/application.yaml
            name: config-volume
            subPath: application.yaml
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: backend-config
          name: config-volume
  status:
    observedGeneration: 7
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "2"
      deployment.kubernetes.io/max-replicas: "3"
      deployment.kubernetes.io/revision: "5"
    creationTimestamp: "2025-01-06T05:43:15Z"
    generation: 2
    labels:
      app: backend
      pod-template-hash: 5f6bfbb599
    name: backend-5f6bfbb599
    namespace: backend
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: backend
      uid: 7d4a6583-3d4c-4841-8cef-bc2c0edb6f03
    resourceVersion: "19414819"
    uid: d00d5309-28fb-41c6-a86d-0b74a1158708
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: backend
        pod-template-hash: 5f6bfbb599
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2025-01-06T14:43:15+09:00"
        creationTimestamp: null
        labels:
          app: backend
          pod-template-hash: 5f6bfbb599
      spec:
        containers:
        - env:
          - name: SPRING_CONFIG_LOCATION
            value: /app/config/application.yaml
          image: zicdding0904/zicdding-class-back:latest
          imagePullPolicy: Always
          name: backend
          ports:
          - containerPort: 3000
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /app/config/application.yaml
            name: config-volume
            subPath: application.yaml
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: backend-config
          name: config-volume
  status:
    availableReplicas: 2
    fullyLabeledReplicas: 2
    observedGeneration: 2
    readyReplicas: 2
    replicas: 2
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "2"
      deployment.kubernetes.io/max-replicas: "3"
      deployment.kubernetes.io/revision: "2"
    creationTimestamp: "2024-12-30T04:26:24Z"
    generation: 4
    labels:
      app: backend
      pod-template-hash: 64f95bcd4c
    name: backend-64f95bcd4c
    namespace: backend
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: backend
      uid: 7d4a6583-3d4c-4841-8cef-bc2c0edb6f03
    resourceVersion: "18621836"
    uid: 65d07275-98b0-431c-b193-dd70dc0d326b
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: backend
        pod-template-hash: 64f95bcd4c
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2024-12-30T13:26:24+09:00"
        creationTimestamp: null
        labels:
          app: backend
          pod-template-hash: 64f95bcd4c
      spec:
        containers:
        - env:
          - name: SPRING_CONFIG_LOCATION
            value: /app/config/application.yaml
          image: zicdding0904/zicdding-class-back:latest
          imagePullPolicy: Always
          name: backend
          ports:
          - containerPort: 3000
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /app/config/application.yaml
            name: config-volume
            subPath: application.yaml
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: backend-config
          name: config-volume
  status:
    observedGeneration: 4
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2024-08-03T05:16:32Z"
    generation: 2
    labels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/name: ingress-nginx
      gcp-auth-skip-secret: "true"
      pod-template-hash: 768f948f8f
    name: ingress-nginx-controller-768f948f8f
    namespace: ingress-nginx
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: ingress-nginx-controller
      uid: cab11dbc-f1ac-4447-a8d2-7bf192b7720c
    resourceVersion: "18212218"
    uid: 200640f3-45a9-4ea5-ae54-150f12e8612e
  spec:
    replicas: 0
    selector:
      matchLabels:
        app.kubernetes.io/component: controller
        app.kubernetes.io/instance: ingress-nginx
        app.kubernetes.io/name: ingress-nginx
        pod-template-hash: 768f948f8f
    template:
      metadata:
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: controller
          app.kubernetes.io/instance: ingress-nginx
          app.kubernetes.io/name: ingress-nginx
          gcp-auth-skip-secret: "true"
          pod-template-hash: 768f948f8f
      spec:
        containers:
        - args:
          - /nginx-ingress-controller
          - --election-id=ingress-nginx-leader
          - --controller-class=k8s.io/ingress-nginx
          - --watch-ingress-without-class=true
          - --configmap=$(POD_NAMESPACE)/ingress-nginx-controller
          - --tcp-services-configmap=$(POD_NAMESPACE)/tcp-services
          - --udp-services-configmap=$(POD_NAMESPACE)/udp-services
          - --validating-webhook=:8443
          - --validating-webhook-certificate=/usr/local/certificates/cert
          - --validating-webhook-key=/usr/local/certificates/key
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: LD_PRELOAD
            value: /usr/local/lib/libmimalloc.so
          image: registry.k8s.io/ingress-nginx/controller:v1.10.1@sha256:e24f39d3eed6bcc239a56f20098878845f62baa34b9f2be2fd2c38ce9fb0f29e
          imagePullPolicy: IfNotPresent
          lifecycle:
            preStop:
              exec:
                command:
                - /wait-shutdown
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /healthz
              port: 10254
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: controller
          ports:
          - containerPort: 80
            hostPort: 80
            name: http
            protocol: TCP
          - containerPort: 443
            hostPort: 443
            name: https
            protocol: TCP
          - containerPort: 8443
            name: webhook
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 10254
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            requests:
              cpu: 100m
              memory: 90Mi
          securityContext:
            allowPrivilegeEscalation: true
            capabilities:
              add:
              - NET_BIND_SERVICE
              drop:
              - ALL
            runAsUser: 101
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /usr/local/certificates/
            name: webhook-cert
            readOnly: true
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
          minikube.k8s.io/primary: "true"
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: ingress-nginx
        serviceAccountName: ingress-nginx
        terminationGracePeriodSeconds: 0
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Equal
        volumes:
        - name: webhook-cert
          secret:
            defaultMode: 420
            secretName: ingress-nginx-admission
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "2"
    creationTimestamp: "2024-12-26T15:22:02Z"
    generation: 1
    labels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/name: ingress-nginx
      gcp-auth-skip-secret: "true"
      pod-template-hash: 79d9f6f4d6
    name: ingress-nginx-controller-79d9f6f4d6
    namespace: ingress-nginx
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: ingress-nginx-controller
      uid: cab11dbc-f1ac-4447-a8d2-7bf192b7720c
    resourceVersion: "18212288"
    uid: e7fcb5ac-82e6-4102-9bbc-241dc5e3ecd7
  spec:
    replicas: 1
    selector:
      matchLabels:
        app.kubernetes.io/component: controller
        app.kubernetes.io/instance: ingress-nginx
        app.kubernetes.io/name: ingress-nginx
        pod-template-hash: 79d9f6f4d6
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2024-12-27T00:22:02+09:00"
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: controller
          app.kubernetes.io/instance: ingress-nginx
          app.kubernetes.io/name: ingress-nginx
          gcp-auth-skip-secret: "true"
          pod-template-hash: 79d9f6f4d6
      spec:
        containers:
        - args:
          - /nginx-ingress-controller
          - --election-id=ingress-nginx-leader
          - --controller-class=k8s.io/ingress-nginx
          - --watch-ingress-without-class=true
          - --configmap=$(POD_NAMESPACE)/ingress-nginx-controller
          - --tcp-services-configmap=$(POD_NAMESPACE)/tcp-services
          - --udp-services-configmap=$(POD_NAMESPACE)/udp-services
          - --validating-webhook=:8443
          - --validating-webhook-certificate=/usr/local/certificates/cert
          - --validating-webhook-key=/usr/local/certificates/key
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: LD_PRELOAD
            value: /usr/local/lib/libmimalloc.so
          image: registry.k8s.io/ingress-nginx/controller:v1.10.1@sha256:e24f39d3eed6bcc239a56f20098878845f62baa34b9f2be2fd2c38ce9fb0f29e
          imagePullPolicy: IfNotPresent
          lifecycle:
            preStop:
              exec:
                command:
                - /wait-shutdown
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /healthz
              port: 10254
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: controller
          ports:
          - containerPort: 80
            hostPort: 80
            name: http
            protocol: TCP
          - containerPort: 443
            hostPort: 443
            name: https
            protocol: TCP
          - containerPort: 8443
            name: webhook
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 10254
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            requests:
              cpu: 100m
              memory: 90Mi
          securityContext:
            allowPrivilegeEscalation: true
            capabilities:
              add:
              - NET_BIND_SERVICE
              drop:
              - ALL
            runAsUser: 101
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /usr/local/certificates/
            name: webhook-cert
            readOnly: true
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
          minikube.k8s.io/primary: "true"
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: ingress-nginx
        serviceAccountName: ingress-nginx
        terminationGracePeriodSeconds: 0
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
          operator: Equal
        volumes:
        - name: webhook-cert
          secret:
            defaultMode: 420
            secretName: ingress-nginx-admission
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: nginx-ingress
      meta.helm.sh/release-namespace: ingress-nginx
    creationTimestamp: "2024-07-20T01:14:48Z"
    generation: 1
    labels:
      app.kubernetes.io/component: controller
      app.kubernetes.io/instance: nginx-ingress
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: ingress-nginx
      app.kubernetes.io/part-of: ingress-nginx
      app.kubernetes.io/version: 1.11.1
      helm.sh/chart: ingress-nginx-4.11.1
      pod-template-hash: 7855544b44
    name: nginx-ingress-ingress-nginx-controller-7855544b44
    namespace: ingress-nginx
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: nginx-ingress-ingress-nginx-controller
      uid: dce8927d-d2af-46fe-a22d-205821fb9d60
    resourceVersion: "17859299"
    uid: ca98a617-f851-403a-b21d-00c8e3200a74
  spec:
    replicas: 1
    selector:
      matchLabels:
        app.kubernetes.io/component: controller
        app.kubernetes.io/instance: nginx-ingress
        app.kubernetes.io/name: ingress-nginx
        pod-template-hash: 7855544b44
    template:
      metadata:
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: controller
          app.kubernetes.io/instance: nginx-ingress
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: ingress-nginx
          app.kubernetes.io/part-of: ingress-nginx
          app.kubernetes.io/version: 1.11.1
          helm.sh/chart: ingress-nginx-4.11.1
          pod-template-hash: 7855544b44
      spec:
        containers:
        - args:
          - /nginx-ingress-controller
          - --publish-service=$(POD_NAMESPACE)/nginx-ingress-ingress-nginx-controller
          - --election-id=nginx-ingress-ingress-nginx-leader
          - --controller-class=k8s.io/ingress-nginx
          - --ingress-class=nginx
          - --configmap=$(POD_NAMESPACE)/nginx-ingress-ingress-nginx-controller
          - --validating-webhook=:8443
          - --validating-webhook-certificate=/usr/local/certificates/cert
          - --validating-webhook-key=/usr/local/certificates/key
          - --enable-metrics=false
          env:
          - name: POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: LD_PRELOAD
            value: /usr/local/lib/libmimalloc.so
          image: registry.k8s.io/ingress-nginx/controller:v1.11.1@sha256:e6439a12b52076965928e83b7b56aae6731231677b01e81818bce7fa5c60161a
          imagePullPolicy: IfNotPresent
          lifecycle:
            preStop:
              exec:
                command:
                - /wait-shutdown
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /healthz
              port: 10254
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: controller
          ports:
          - containerPort: 80
            name: http
            protocol: TCP
          - containerPort: 443
            name: https
            protocol: TCP
          - containerPort: 8443
            name: webhook
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 10254
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            requests:
              cpu: 100m
              memory: 90Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              add:
              - NET_BIND_SERVICE
              drop:
              - ALL
            readOnlyRootFilesystem: false
            runAsNonRoot: true
            runAsUser: 101
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /usr/local/certificates/
            name: webhook-cert
            readOnly: true
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: nginx-ingress-ingress-nginx
        serviceAccountName: nginx-ingress-ingress-nginx
        terminationGracePeriodSeconds: 300
        volumes:
        - name: webhook-cert
          secret:
            defaultMode: 420
            secretName: nginx-ingress-ingress-nginx-admission
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2024-07-09T13:40:32Z"
    generation: 1
    labels:
      k8s-app: kube-dns
      pod-template-hash: 7db6d8ff4d
    name: coredns-7db6d8ff4d
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: coredns
      uid: 889549ad-f497-4011-93e5-b8e00c622961
    resourceVersion: "17859176"
    uid: 14eea68f-ba1d-4906-b9de-a1cfa8a1d252
  spec:
    replicas: 1
    selector:
      matchLabels:
        k8s-app: kube-dns
        pod-template-hash: 7db6d8ff4d
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: kube-dns
          pod-template-hash: 7db6d8ff4d
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchExpressions:
                  - key: k8s-app
                    operator: In
                    values:
                    - kube-dns
                topologyKey: kubernetes.io/hostname
              weight: 100
        containers:
        - args:
          - -conf
          - /etc/coredns/Corefile
          image: registry.k8s.io/coredns/coredns:v1.11.1
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /health
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: coredns
          ports:
          - containerPort: 53
            name: dns
            protocol: UDP
          - containerPort: 53
            name: dns-tcp
            protocol: TCP
          - containerPort: 9153
            name: metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /ready
              port: 8181
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            limits:
              memory: 170Mi
            requests:
              cpu: 100m
              memory: 70Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              add:
              - NET_BIND_SERVICE
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/coredns
            name: config-volume
            readOnly: true
        dnsPolicy: Default
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: coredns
        serviceAccountName: coredns
        terminationGracePeriodSeconds: 30
        tolerations:
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
        volumes:
        - configMap:
            defaultMode: 420
            items:
            - key: Corefile
              path: Corefile
            name: coredns
          name: config-volume
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "2"
    creationTimestamp: "2024-12-23T13:43:32Z"
    generation: 2
    labels:
      k8s-app: metrics-server
      pod-template-hash: 6d97fd69d6
    name: metrics-server-6d97fd69d6
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: metrics-server
      uid: 6676e809-6638-4ed0-96fd-05b3487b322c
    resourceVersion: "17860147"
    uid: 702ecad5-2688-4e93-b93d-70bc7e10e2c1
  spec:
    replicas: 0
    selector:
      matchLabels:
        k8s-app: metrics-server
        pod-template-hash: 6d97fd69d6
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: metrics-server
          pod-template-hash: 6d97fd69d6
      spec:
        containers:
        - args:
          - --cert-dir=/tmp
          - --secure-port=10250
          - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
          - --kubelet-use-node-status-port
          - --metric-resolution=15s
          - --kubelet-insecure-tls
          - --kubelet-preferred-address-types=InternalIP
          image: registry.k8s.io/metrics-server/metrics-server:v0.7.2
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /livez
              port: https
              scheme: HTTPS
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: metrics-server
          ports:
          - containerPort: 10250
            name: https
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /readyz
              port: https
              scheme: HTTPS
            initialDelaySeconds: 20
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            requests:
              cpu: 100m
              memory: 200Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 1000
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /tmp
            name: tmp-dir
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: metrics-server
        serviceAccountName: metrics-server
        terminationGracePeriodSeconds: 30
        volumes:
        - emptyDir: {}
          name: tmp-dir
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2024-12-23T13:40:58Z"
    generation: 2
    labels:
      k8s-app: metrics-server
      pod-template-hash: d5865ff47
    name: metrics-server-d5865ff47
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: metrics-server
      uid: 6676e809-6638-4ed0-96fd-05b3487b322c
    resourceVersion: "17860071"
    uid: a01af645-53b8-4240-a5dc-7d4e8cef64ee
  spec:
    replicas: 0
    selector:
      matchLabels:
        k8s-app: metrics-server
        pod-template-hash: d5865ff47
    template:
      metadata:
        creationTimestamp: null
        labels:
          k8s-app: metrics-server
          pod-template-hash: d5865ff47
      spec:
        containers:
        - args:
          - --cert-dir=/tmp
          - --secure-port=10250
          - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
          - --kubelet-use-node-status-port
          - --metric-resolution=15s
          image: registry.k8s.io/metrics-server/metrics-server:v0.7.2
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /livez
              port: https
              scheme: HTTPS
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: metrics-server
          ports:
          - containerPort: 10250
            name: https
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /readyz
              port: https
              scheme: HTTPS
            initialDelaySeconds: 20
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            requests:
              cpu: 100m
              memory: 200Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 1000
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /tmp
            name: tmp-dir
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: metrics-server
        serviceAccountName: metrics-server
        terminationGracePeriodSeconds: 30
        volumes:
        - emptyDir: {}
          name: tmp-dir
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "3"
    creationTimestamp: "2024-12-23T13:43:40Z"
    generation: 2
    labels:
      k8s-app: metrics-server
      pod-template-hash: fc9f6bcf6
    name: metrics-server-fc9f6bcf6
    namespace: kube-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: metrics-server
      uid: 6676e809-6638-4ed0-96fd-05b3487b322c
    resourceVersion: "22846837"
    uid: cb6b57e2-b4d4-49ea-ba45-d064dd1c87b1
  spec:
    replicas: 1
    selector:
      matchLabels:
        k8s-app: metrics-server
        pod-template-hash: fc9f6bcf6
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2024-12-23T22:43:40+09:00"
        creationTimestamp: null
        labels:
          k8s-app: metrics-server
          pod-template-hash: fc9f6bcf6
      spec:
        containers:
        - args:
          - --cert-dir=/tmp
          - --secure-port=10250
          - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
          - --kubelet-use-node-status-port
          - --metric-resolution=15s
          - --kubelet-insecure-tls
          - --kubelet-preferred-address-types=InternalIP
          image: registry.k8s.io/metrics-server/metrics-server:v0.7.2
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /livez
              port: https
              scheme: HTTPS
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: metrics-server
          ports:
          - containerPort: 10250
            name: https
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /readyz
              port: https
              scheme: HTTPS
            initialDelaySeconds: 20
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            requests:
              cpu: 100m
              memory: 200Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 1000
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /tmp
            name: tmp-dir
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        priorityClassName: system-cluster-critical
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: metrics-server
        serviceAccountName: metrics-server
        terminationGracePeriodSeconds: 30
        volumes:
        - emptyDir: {}
          name: tmp-dir
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 2
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2024-08-01T14:13:41Z"
    generation: 1
    labels:
      k8s-app: dashboard-metrics-scraper
      pod-template-hash: b5fc48f67
    name: dashboard-metrics-scraper-b5fc48f67
    namespace: kubernetes-dashboard
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: dashboard-metrics-scraper
      uid: 5679f7a7-46b8-4769-8fff-369500f6175d
    resourceVersion: "17859151"
    uid: 7a05aea7-c992-44c2-b06c-56a5f52e87f5
  spec:
    replicas: 1
    selector:
      matchLabels:
        k8s-app: dashboard-metrics-scraper
        pod-template-hash: b5fc48f67
    template:
      metadata:
        annotations:
          seccomp.security.alpha.kubernetes.io/pod: runtime/default
        creationTimestamp: null
        labels:
          k8s-app: dashboard-metrics-scraper
          pod-template-hash: b5fc48f67
      spec:
        containers:
        - image: docker.io/kubernetesui/metrics-scraper:v1.0.8@sha256:76049887f07a0476dc93efc2d3569b9529bf982b22d29f356092ce206e98765c
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: 8000
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 30
          name: dashboard-metrics-scraper
          ports:
          - containerPort: 8000
            protocol: TCP
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsGroup: 2001
            runAsUser: 1001
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /tmp
            name: tmp-volume
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: kubernetes-dashboard
        serviceAccountName: kubernetes-dashboard
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
        volumes:
        - emptyDir: {}
          name: tmp-volume
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2024-08-01T14:13:41Z"
    generation: 1
    labels:
      gcp-auth-skip-secret: "true"
      k8s-app: kubernetes-dashboard
      pod-template-hash: 779776cb65
    name: kubernetes-dashboard-779776cb65
    namespace: kubernetes-dashboard
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: kubernetes-dashboard
      uid: fff5c7f5-00e5-4301-8ac1-a359b831d08c
    resourceVersion: "17859097"
    uid: 4bce2e0f-e72e-4252-8ed3-bbfaa052e36d
  spec:
    replicas: 1
    selector:
      matchLabels:
        k8s-app: kubernetes-dashboard
        pod-template-hash: 779776cb65
    template:
      metadata:
        creationTimestamp: null
        labels:
          gcp-auth-skip-secret: "true"
          k8s-app: kubernetes-dashboard
          pod-template-hash: 779776cb65
      spec:
        containers:
        - args:
          - --namespace=kubernetes-dashboard
          - --enable-skip-login
          - --disable-settings-authorizer
          image: docker.io/kubernetesui/dashboard:v2.7.0@sha256:2e500d29e9d5f4a086b908eb8dfe7ecac57d2ab09d65b24f588b1d449841ef93
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: 9090
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 30
          name: kubernetes-dashboard
          ports:
          - containerPort: 9090
            protocol: TCP
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            runAsGroup: 2001
            runAsUser: 1001
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /tmp
            name: tmp-volume
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: kubernetes-dashboard
        serviceAccountName: kubernetes-dashboard
        terminationGracePeriodSeconds: 30
        tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
        volumes:
        - emptyDir: {}
          name: tmp-volume
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "2"
    creationTimestamp: "2024-07-19T17:50:21Z"
    generation: 2
    labels:
      app: metallb
      component: controller
      pod-template-hash: 55c47f855c
    name: controller-55c47f855c
    namespace: metallb-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: controller
      uid: 8e628965-4f07-41bc-824f-137cafd3d016
    resourceVersion: "763614"
    uid: 5dbefd44-0a8b-4d67-a1df-affd66e9ba14
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: metallb
        component: controller
        pod-template-hash: 55c47f855c
    template:
      metadata:
        annotations:
          prometheus.io/port: "7472"
          prometheus.io/scrape: "true"
        creationTimestamp: null
        labels:
          app: metallb
          component: controller
          pod-template-hash: 55c47f855c
      spec:
        containers:
        - args:
          - --port=7472
          - --config=config
          - --log-level=info
          env:
          - name: METALLB_ML_SECRET_NAME
            value: memberlist
          - name: METALLB_DEPLOYMENT
            value: controller
          image: quay.io/metallb/controller:v0.12.1
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /metrics
              port: monitoring
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: controller
          ports:
          - containerPort: 7472
            name: monitoring
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /metrics
              port: monitoring
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - all
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          runAsNonRoot: true
          runAsUser: 65534
        serviceAccount: controller
        serviceAccountName: controller
        terminationGracePeriodSeconds: 0
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2024-07-19T17:40:40Z"
    generation: 2
    labels:
      app: metallb
      component: controller
      pod-template-hash: 6fb578df7f
    name: controller-6fb578df7f
    namespace: metallb-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: controller
      uid: 8e628965-4f07-41bc-824f-137cafd3d016
    resourceVersion: "739146"
    uid: a8864043-6a8b-4104-95c0-91f341c16add
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: metallb
        component: controller
        pod-template-hash: 6fb578df7f
    template:
      metadata:
        annotations:
          prometheus.io/port: "7472"
          prometheus.io/scrape: "true"
        creationTimestamp: null
        labels:
          app: metallb
          component: controller
          pod-template-hash: 6fb578df7f
      spec:
        containers:
        - args:
          - --port=7472
          - --log-level=info
          env:
          - name: METALLB_ML_SECRET_NAME
            value: memberlist
          - name: METALLB_DEPLOYMENT
            value: controller
          image: quay.io/metallb/controller:v0.13.7
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /metrics
              port: monitoring
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: controller
          ports:
          - containerPort: 7472
            name: monitoring
            protocol: TCP
          - containerPort: 9443
            name: webhook-server
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /metrics
              port: monitoring
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - all
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /tmp/k8s-webhook-server/serving-certs
            name: cert
            readOnly: true
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          runAsNonRoot: true
          runAsUser: 65534
        serviceAccount: controller
        serviceAccountName: controller
        terminationGracePeriodSeconds: 0
        volumes:
        - name: cert
          secret:
            defaultMode: 420
            secretName: webhook-server-cert
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "4"
    creationTimestamp: "2024-11-19T12:23:16Z"
    generation: 1
    labels:
      app: metallb
      component: controller
      pod-template-hash: 776c4595bf
    name: controller-776c4595bf
    namespace: metallb-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: controller
      uid: 8e628965-4f07-41bc-824f-137cafd3d016
    resourceVersion: "15278323"
    uid: a4111e10-5941-485c-b675-4519b5b77da8
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: metallb
        component: controller
        pod-template-hash: 776c4595bf
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2024-07-20T09:59:49+09:00"
          prometheus.io/port: "7472"
          prometheus.io/scrape: "true"
        creationTimestamp: null
        labels:
          app: metallb
          component: controller
          pod-template-hash: 776c4595bf
      spec:
        containers:
        - args:
          - --port=7472
          - --config=config
          image: quay.io/metallb/controller:v0.9.6@sha256:6932cf255dd7f06f550c7f106b9a206be95f847ab8cb77aafac7acd27def0b00
          imagePullPolicy: IfNotPresent
          name: controller
          ports:
          - containerPort: 7472
            name: monitoring
            protocol: TCP
          resources:
            limits:
              cpu: 100m
              memory: 100Mi
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - all
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          runAsNonRoot: true
          runAsUser: 65534
        serviceAccount: controller
        serviceAccountName: controller
        terminationGracePeriodSeconds: 0
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "3"
    creationTimestamp: "2024-07-20T00:59:49Z"
    generation: 2
    labels:
      app: metallb
      component: controller
      pod-template-hash: bdbbfc774
    name: controller-bdbbfc774
    namespace: metallb-system
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: controller
      uid: 8e628965-4f07-41bc-824f-137cafd3d016
    resourceVersion: "13870478"
    uid: cd2bec8f-776c-4672-af36-aa24bcb9faa9
  spec:
    replicas: 0
    selector:
      matchLabels:
        app: metallb
        component: controller
        pod-template-hash: bdbbfc774
    template:
      metadata:
        annotations:
          kubectl.kubernetes.io/restartedAt: "2024-07-20T09:59:49+09:00"
          prometheus.io/port: "7472"
          prometheus.io/scrape: "true"
        creationTimestamp: null
        labels:
          app: metallb
          component: controller
          pod-template-hash: bdbbfc774
      spec:
        containers:
        - args:
          - --port=7472
          - --config=config
          - --log-level=info
          env:
          - name: METALLB_ML_SECRET_NAME
            value: memberlist
          - name: METALLB_DEPLOYMENT
            value: controller
          image: quay.io/metallb/controller:v0.12.1
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /metrics
              port: monitoring
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: controller
          ports:
          - containerPort: 7472
            name: monitoring
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /metrics
              port: monitoring
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - all
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          runAsNonRoot: true
          runAsUser: 65534
        serviceAccount: controller
        serviceAccountName: controller
        terminationGracePeriodSeconds: 0
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "4"
    creationTimestamp: "2024-12-29T14:48:02Z"
    generation: 2
    labels:
      app.kubernetes.io/instance: monitoring
      app.kubernetes.io/name: grafana
      pod-template-hash: 5cc95b86cd
    name: monitoring-grafana-5cc95b86cd
    namespace: monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: monitoring-grafana
      uid: 002b7df9-3a83-4a03-a166-61b566783821
    resourceVersion: "18746452"
    uid: 634daa67-a53e-48a1-bd92-d1b6a6ad33a2
  spec:
    replicas: 0
    selector:
      matchLabels:
        app.kubernetes.io/instance: monitoring
        app.kubernetes.io/name: grafana
        pod-template-hash: 5cc95b86cd
    template:
      metadata:
        annotations:
          checksum/config: 0e9cbd0ea8e24e32f7dfca5bab17a2ba05652642f0a09a4882833ae88e4cc4a3
          checksum/sc-dashboard-provider-config: e70bf6a851099d385178a76de9757bb0bef8299da6d8443602590e44f05fdf24
          checksum/secret: 42bbcab3a67ca3daa20142f240a2eba96ec843b11984a0cdd14677477a16e751
          kubectl.kubernetes.io/default-container: grafana
          kubectl.kubernetes.io/restartedAt: "2024-12-29T23:43:29+09:00"
        creationTimestamp: null
        labels:
          app.kubernetes.io/instance: monitoring
          app.kubernetes.io/name: grafana
          pod-template-hash: 5cc95b86cd
      spec:
        automountServiceAccountToken: true
        containers:
        - env:
          - name: METHOD
            value: WATCH
          - name: LABEL
            value: grafana_dashboard
          - name: FOLDER
            value: /tmp/dashboards
          - name: RESOURCE
            value: both
          - name: REQ_USERNAME
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: monitoring-grafana
          - name: REQ_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: monitoring-grafana
          - name: REQ_URL
            value: http://localhost:3000/api/admin/provisioning/dashboards/reload
          - name: REQ_METHOD
            value: POST
          image: quay.io/kiwigrid/k8s-sidecar:1.28.0
          imagePullPolicy: IfNotPresent
          name: grafana-sc-dashboard
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /tmp/dashboards
            name: sc-dashboard-volume
        - env:
          - name: METHOD
            value: WATCH
          - name: LABEL
            value: grafana_datasource
          - name: FOLDER
            value: /etc/grafana/provisioning/datasources
          - name: RESOURCE
            value: both
          - name: REQ_USERNAME
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: monitoring-grafana
          - name: REQ_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: monitoring-grafana
          - name: REQ_URL
            value: http://localhost:3000/api/admin/provisioning/datasources/reload
          - name: REQ_METHOD
            value: POST
          image: quay.io/kiwigrid/k8s-sidecar:1.28.0
          imagePullPolicy: IfNotPresent
          name: grafana-sc-datasources
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/grafana/provisioning/datasources
            name: sc-datasources-volume
        - env:
          - name: POD_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.podIP
          - name: GF_SECURITY_ADMIN_USER
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: monitoring-grafana
          - name: GF_SECURITY_ADMIN_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: monitoring-grafana
          - name: GF_PATHS_DATA
            value: /var/lib/grafana/
          - name: GF_PATHS_LOGS
            value: /var/log/grafana
          - name: GF_PATHS_PLUGINS
            value: /var/lib/grafana/plugins
          - name: GF_PATHS_PROVISIONING
            value: /etc/grafana/provisioning
          image: docker.io/grafana/grafana:11.2.2-security-01
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 10
            httpGet:
              path: /api/health
              port: 3000
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 30
          name: grafana
          ports:
          - containerPort: 3000
            name: grafana
            protocol: TCP
          - containerPort: 9094
            name: gossip-tcp
            protocol: TCP
          - containerPort: 9094
            name: gossip-udp
            protocol: UDP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /api/health
              port: 3000
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/grafana/grafana.ini
            name: config
            subPath: grafana.ini
          - mountPath: /var/lib/grafana
            name: storage
          - mountPath: /tmp/dashboards
            name: sc-dashboard-volume
          - mountPath: /etc/grafana/provisioning/dashboards/sc-dashboardproviders.yaml
            name: sc-dashboard-provider
            subPath: provider.yaml
          - mountPath: /etc/grafana/provisioning/datasources
            name: sc-datasources-volume
        dnsPolicy: ClusterFirst
        enableServiceLinks: true
        initContainers:
        - command:
          - chown
          - -R
          - 472:472
          - /var/lib/grafana
          image: docker.io/library/busybox:1.31.1
          imagePullPolicy: IfNotPresent
          name: init-chown-data
          resources: {}
          securityContext:
            capabilities:
              add:
              - CHOWN
            runAsNonRoot: false
            runAsUser: 0
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/lib/grafana
            name: storage
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 472
          runAsGroup: 472
          runAsNonRoot: true
          runAsUser: 472
        serviceAccount: monitoring-grafana
        serviceAccountName: monitoring-grafana
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: monitoring-grafana
          name: config
        - name: storage
          persistentVolumeClaim:
            claimName: monitoring-grafana
        - emptyDir: {}
          name: sc-dashboard-volume
        - configMap:
            defaultMode: 420
            name: monitoring-grafana-config-dashboards
          name: sc-dashboard-provider
        - emptyDir: {}
          name: sc-datasources-volume
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "3"
    creationTimestamp: "2024-12-29T14:43:29Z"
    generation: 2
    labels:
      app.kubernetes.io/instance: monitoring
      app.kubernetes.io/name: grafana
      pod-template-hash: 65dd949898
    name: monitoring-grafana-65dd949898
    namespace: monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: monitoring-grafana
      uid: 002b7df9-3a83-4a03-a166-61b566783821
    resourceVersion: "18556418"
    uid: fa69dd2c-984c-4f1e-be39-6ae9e07dcc2a
  spec:
    replicas: 0
    selector:
      matchLabels:
        app.kubernetes.io/instance: monitoring
        app.kubernetes.io/name: grafana
        pod-template-hash: 65dd949898
    template:
      metadata:
        annotations:
          checksum/config: 0e9cbd0ea8e24e32f7dfca5bab17a2ba05652642f0a09a4882833ae88e4cc4a3
          checksum/sc-dashboard-provider-config: e70bf6a851099d385178a76de9757bb0bef8299da6d8443602590e44f05fdf24
          kubectl.kubernetes.io/default-container: grafana
          kubectl.kubernetes.io/restartedAt: "2024-12-29T23:43:29+09:00"
        creationTimestamp: null
        labels:
          app.kubernetes.io/instance: monitoring
          app.kubernetes.io/name: grafana
          pod-template-hash: 65dd949898
      spec:
        automountServiceAccountToken: true
        containers:
        - env:
          - name: METHOD
            value: WATCH
          - name: LABEL
            value: grafana_dashboard
          - name: FOLDER
            value: /tmp/dashboards
          - name: RESOURCE
            value: both
          - name: REQ_USERNAME
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: grafana-admin-secret
          - name: REQ_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: grafana-admin-secret
          - name: REQ_URL
            value: http://localhost:3000/api/admin/provisioning/dashboards/reload
          - name: REQ_METHOD
            value: POST
          image: quay.io/kiwigrid/k8s-sidecar:1.28.0
          imagePullPolicy: IfNotPresent
          name: grafana-sc-dashboard
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /tmp/dashboards
            name: sc-dashboard-volume
        - env:
          - name: METHOD
            value: WATCH
          - name: LABEL
            value: grafana_datasource
          - name: FOLDER
            value: /etc/grafana/provisioning/datasources
          - name: RESOURCE
            value: both
          - name: REQ_USERNAME
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: grafana-admin-secret
          - name: REQ_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: grafana-admin-secret
          - name: REQ_URL
            value: http://localhost:3000/api/admin/provisioning/datasources/reload
          - name: REQ_METHOD
            value: POST
          image: quay.io/kiwigrid/k8s-sidecar:1.28.0
          imagePullPolicy: IfNotPresent
          name: grafana-sc-datasources
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/grafana/provisioning/datasources
            name: sc-datasources-volume
        - env:
          - name: POD_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.podIP
          - name: GF_SECURITY_ADMIN_USER
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: grafana-admin-secret
          - name: GF_SECURITY_ADMIN_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: grafana-admin-secret
          - name: GF_PATHS_DATA
            value: /var/lib/grafana/
          - name: GF_PATHS_LOGS
            value: /var/log/grafana
          - name: GF_PATHS_PLUGINS
            value: /var/lib/grafana/plugins
          - name: GF_PATHS_PROVISIONING
            value: /etc/grafana/provisioning
          image: docker.io/grafana/grafana:11.2.2-security-01
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 10
            httpGet:
              path: /api/health
              port: 3000
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 30
          name: grafana
          ports:
          - containerPort: 3000
            name: grafana
            protocol: TCP
          - containerPort: 9094
            name: gossip-tcp
            protocol: TCP
          - containerPort: 9094
            name: gossip-udp
            protocol: UDP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /api/health
              port: 3000
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/grafana/grafana.ini
            name: config
            subPath: grafana.ini
          - mountPath: /var/lib/grafana
            name: storage
          - mountPath: /tmp/dashboards
            name: sc-dashboard-volume
          - mountPath: /etc/grafana/provisioning/dashboards/sc-dashboardproviders.yaml
            name: sc-dashboard-provider
            subPath: provider.yaml
          - mountPath: /etc/grafana/provisioning/datasources
            name: sc-datasources-volume
        dnsPolicy: ClusterFirst
        enableServiceLinks: true
        initContainers:
        - command:
          - chown
          - -R
          - 472:472
          - /var/lib/grafana
          image: docker.io/library/busybox:1.31.1
          imagePullPolicy: IfNotPresent
          name: init-chown-data
          resources: {}
          securityContext:
            capabilities:
              add:
              - CHOWN
            runAsNonRoot: false
            runAsUser: 0
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/lib/grafana
            name: storage
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 472
          runAsGroup: 472
          runAsNonRoot: true
          runAsUser: 472
        serviceAccount: monitoring-grafana
        serviceAccountName: monitoring-grafana
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: monitoring-grafana
          name: config
        - name: storage
          persistentVolumeClaim:
            claimName: monitoring-grafana
        - emptyDir: {}
          name: sc-dashboard-volume
        - configMap:
            defaultMode: 420
            name: monitoring-grafana-config-dashboards
          name: sc-dashboard-provider
        - emptyDir: {}
          name: sc-datasources-volume
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "2"
    creationTimestamp: "2024-12-29T14:29:23Z"
    generation: 2
    labels:
      app.kubernetes.io/instance: monitoring
      app.kubernetes.io/name: grafana
      pod-template-hash: 688994f4cf
    name: monitoring-grafana-688994f4cf
    namespace: monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: monitoring-grafana
      uid: 002b7df9-3a83-4a03-a166-61b566783821
    resourceVersion: "18555961"
    uid: d1ca3c00-d645-4dae-a893-fb5be0257eb4
  spec:
    replicas: 0
    selector:
      matchLabels:
        app.kubernetes.io/instance: monitoring
        app.kubernetes.io/name: grafana
        pod-template-hash: 688994f4cf
    template:
      metadata:
        annotations:
          checksum/config: 0e9cbd0ea8e24e32f7dfca5bab17a2ba05652642f0a09a4882833ae88e4cc4a3
          checksum/sc-dashboard-provider-config: e70bf6a851099d385178a76de9757bb0bef8299da6d8443602590e44f05fdf24
          kubectl.kubernetes.io/default-container: grafana
        creationTimestamp: null
        labels:
          app.kubernetes.io/instance: monitoring
          app.kubernetes.io/name: grafana
          pod-template-hash: 688994f4cf
      spec:
        automountServiceAccountToken: true
        containers:
        - env:
          - name: METHOD
            value: WATCH
          - name: LABEL
            value: grafana_dashboard
          - name: FOLDER
            value: /tmp/dashboards
          - name: RESOURCE
            value: both
          - name: REQ_USERNAME
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: grafana-admin-secret
          - name: REQ_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: grafana-admin-secret
          - name: REQ_URL
            value: http://localhost:3000/api/admin/provisioning/dashboards/reload
          - name: REQ_METHOD
            value: POST
          image: quay.io/kiwigrid/k8s-sidecar:1.28.0
          imagePullPolicy: IfNotPresent
          name: grafana-sc-dashboard
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /tmp/dashboards
            name: sc-dashboard-volume
        - env:
          - name: METHOD
            value: WATCH
          - name: LABEL
            value: grafana_datasource
          - name: FOLDER
            value: /etc/grafana/provisioning/datasources
          - name: RESOURCE
            value: both
          - name: REQ_USERNAME
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: grafana-admin-secret
          - name: REQ_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: grafana-admin-secret
          - name: REQ_URL
            value: http://localhost:3000/api/admin/provisioning/datasources/reload
          - name: REQ_METHOD
            value: POST
          image: quay.io/kiwigrid/k8s-sidecar:1.28.0
          imagePullPolicy: IfNotPresent
          name: grafana-sc-datasources
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/grafana/provisioning/datasources
            name: sc-datasources-volume
        - env:
          - name: POD_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.podIP
          - name: GF_SECURITY_ADMIN_USER
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: grafana-admin-secret
          - name: GF_SECURITY_ADMIN_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: grafana-admin-secret
          - name: GF_PATHS_DATA
            value: /var/lib/grafana/
          - name: GF_PATHS_LOGS
            value: /var/log/grafana
          - name: GF_PATHS_PLUGINS
            value: /var/lib/grafana/plugins
          - name: GF_PATHS_PROVISIONING
            value: /etc/grafana/provisioning
          image: docker.io/grafana/grafana:11.2.2-security-01
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 10
            httpGet:
              path: /api/health
              port: 3000
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 30
          name: grafana
          ports:
          - containerPort: 3000
            name: grafana
            protocol: TCP
          - containerPort: 9094
            name: gossip-tcp
            protocol: TCP
          - containerPort: 9094
            name: gossip-udp
            protocol: UDP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /api/health
              port: 3000
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/grafana/grafana.ini
            name: config
            subPath: grafana.ini
          - mountPath: /var/lib/grafana
            name: storage
          - mountPath: /tmp/dashboards
            name: sc-dashboard-volume
          - mountPath: /etc/grafana/provisioning/dashboards/sc-dashboardproviders.yaml
            name: sc-dashboard-provider
            subPath: provider.yaml
          - mountPath: /etc/grafana/provisioning/datasources
            name: sc-datasources-volume
        dnsPolicy: ClusterFirst
        enableServiceLinks: true
        initContainers:
        - command:
          - chown
          - -R
          - 472:472
          - /var/lib/grafana
          image: docker.io/library/busybox:1.31.1
          imagePullPolicy: IfNotPresent
          name: init-chown-data
          resources: {}
          securityContext:
            capabilities:
              add:
              - CHOWN
            runAsNonRoot: false
            runAsUser: 0
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/lib/grafana
            name: storage
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 472
          runAsGroup: 472
          runAsNonRoot: true
          runAsUser: 472
        serviceAccount: monitoring-grafana
        serviceAccountName: monitoring-grafana
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: monitoring-grafana
          name: config
        - name: storage
          persistentVolumeClaim:
            claimName: monitoring-grafana
        - emptyDir: {}
          name: sc-dashboard-volume
        - configMap:
            defaultMode: 420
            name: monitoring-grafana-config-dashboards
          name: sc-dashboard-provider
        - emptyDir: {}
          name: sc-datasources-volume
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2024-12-29T14:19:33Z"
    generation: 2
    labels:
      app.kubernetes.io/instance: monitoring
      app.kubernetes.io/name: grafana
      pod-template-hash: 74d9b8d6cd
    name: monitoring-grafana-74d9b8d6cd
    namespace: monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: monitoring-grafana
      uid: 002b7df9-3a83-4a03-a166-61b566783821
    resourceVersion: "18554809"
    uid: 1e6bef40-5c09-42b2-963d-8b8ceb671cfa
  spec:
    replicas: 0
    selector:
      matchLabels:
        app.kubernetes.io/instance: monitoring
        app.kubernetes.io/name: grafana
        pod-template-hash: 74d9b8d6cd
    template:
      metadata:
        annotations:
          checksum/config: 0e9cbd0ea8e24e32f7dfca5bab17a2ba05652642f0a09a4882833ae88e4cc4a3
          checksum/sc-dashboard-provider-config: e70bf6a851099d385178a76de9757bb0bef8299da6d8443602590e44f05fdf24
          checksum/secret: d43ac3625f6300674801a9f52fde5ccd1db29237af84fdef717137048273d54a
          kubectl.kubernetes.io/default-container: grafana
        creationTimestamp: null
        labels:
          app.kubernetes.io/instance: monitoring
          app.kubernetes.io/name: grafana
          pod-template-hash: 74d9b8d6cd
      spec:
        automountServiceAccountToken: true
        containers:
        - env:
          - name: METHOD
            value: WATCH
          - name: LABEL
            value: grafana_dashboard
          - name: FOLDER
            value: /tmp/dashboards
          - name: RESOURCE
            value: both
          - name: REQ_USERNAME
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: monitoring-grafana
          - name: REQ_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: monitoring-grafana
          - name: REQ_URL
            value: http://localhost:3000/api/admin/provisioning/dashboards/reload
          - name: REQ_METHOD
            value: POST
          image: quay.io/kiwigrid/k8s-sidecar:1.28.0
          imagePullPolicy: IfNotPresent
          name: grafana-sc-dashboard
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /tmp/dashboards
            name: sc-dashboard-volume
        - env:
          - name: METHOD
            value: WATCH
          - name: LABEL
            value: grafana_datasource
          - name: FOLDER
            value: /etc/grafana/provisioning/datasources
          - name: RESOURCE
            value: both
          - name: REQ_USERNAME
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: monitoring-grafana
          - name: REQ_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: monitoring-grafana
          - name: REQ_URL
            value: http://localhost:3000/api/admin/provisioning/datasources/reload
          - name: REQ_METHOD
            value: POST
          image: quay.io/kiwigrid/k8s-sidecar:1.28.0
          imagePullPolicy: IfNotPresent
          name: grafana-sc-datasources
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/grafana/provisioning/datasources
            name: sc-datasources-volume
        - env:
          - name: POD_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.podIP
          - name: GF_SECURITY_ADMIN_USER
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: monitoring-grafana
          - name: GF_SECURITY_ADMIN_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: monitoring-grafana
          - name: GF_PATHS_DATA
            value: /var/lib/grafana/
          - name: GF_PATHS_LOGS
            value: /var/log/grafana
          - name: GF_PATHS_PLUGINS
            value: /var/lib/grafana/plugins
          - name: GF_PATHS_PROVISIONING
            value: /etc/grafana/provisioning
          image: docker.io/grafana/grafana:11.2.2-security-01
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 10
            httpGet:
              path: /api/health
              port: 3000
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 30
          name: grafana
          ports:
          - containerPort: 3000
            name: grafana
            protocol: TCP
          - containerPort: 9094
            name: gossip-tcp
            protocol: TCP
          - containerPort: 9094
            name: gossip-udp
            protocol: UDP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /api/health
              port: 3000
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/grafana/grafana.ini
            name: config
            subPath: grafana.ini
          - mountPath: /var/lib/grafana
            name: storage
          - mountPath: /tmp/dashboards
            name: sc-dashboard-volume
          - mountPath: /etc/grafana/provisioning/dashboards/sc-dashboardproviders.yaml
            name: sc-dashboard-provider
            subPath: provider.yaml
          - mountPath: /etc/grafana/provisioning/datasources
            name: sc-datasources-volume
        dnsPolicy: ClusterFirst
        enableServiceLinks: true
        initContainers:
        - command:
          - chown
          - -R
          - 472:472
          - /var/lib/grafana
          image: docker.io/library/busybox:1.31.1
          imagePullPolicy: IfNotPresent
          name: init-chown-data
          resources: {}
          securityContext:
            capabilities:
              add:
              - CHOWN
            runAsNonRoot: false
            runAsUser: 0
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/lib/grafana
            name: storage
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 472
          runAsGroup: 472
          runAsNonRoot: true
          runAsUser: 472
        serviceAccount: monitoring-grafana
        serviceAccountName: monitoring-grafana
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: monitoring-grafana
          name: config
        - name: storage
          persistentVolumeClaim:
            claimName: monitoring-grafana
        - emptyDir: {}
          name: sc-dashboard-volume
        - configMap:
            defaultMode: 420
            name: monitoring-grafana-config-dashboards
          name: sc-dashboard-provider
        - emptyDir: {}
          name: sc-datasources-volume
  status:
    observedGeneration: 2
    replicas: 0
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "5"
    creationTimestamp: "2024-12-31T06:48:26Z"
    generation: 1
    labels:
      app.kubernetes.io/instance: monitoring
      app.kubernetes.io/name: grafana
      pod-template-hash: 7cbb8f4465
    name: monitoring-grafana-7cbb8f4465
    namespace: monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: monitoring-grafana
      uid: 002b7df9-3a83-4a03-a166-61b566783821
    resourceVersion: "18746438"
    uid: f52249c5-80f4-42d5-a4e8-f15e9cbb01a7
  spec:
    replicas: 1
    selector:
      matchLabels:
        app.kubernetes.io/instance: monitoring
        app.kubernetes.io/name: grafana
        pod-template-hash: 7cbb8f4465
    template:
      metadata:
        annotations:
          checksum/config: 0e9cbd0ea8e24e32f7dfca5bab17a2ba05652642f0a09a4882833ae88e4cc4a3
          checksum/sc-dashboard-provider-config: e70bf6a851099d385178a76de9757bb0bef8299da6d8443602590e44f05fdf24
          checksum/secret: 42bbcab3a67ca3daa20142f240a2eba96ec843b11984a0cdd14677477a16e751
          kubectl.kubernetes.io/default-container: grafana
          kubectl.kubernetes.io/restartedAt: "2024-12-31T15:48:25+09:00"
        creationTimestamp: null
        labels:
          app.kubernetes.io/instance: monitoring
          app.kubernetes.io/name: grafana
          pod-template-hash: 7cbb8f4465
      spec:
        automountServiceAccountToken: true
        containers:
        - env:
          - name: METHOD
            value: WATCH
          - name: LABEL
            value: grafana_dashboard
          - name: FOLDER
            value: /tmp/dashboards
          - name: RESOURCE
            value: both
          - name: REQ_USERNAME
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: monitoring-grafana
          - name: REQ_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: monitoring-grafana
          - name: REQ_URL
            value: http://localhost:3000/api/admin/provisioning/dashboards/reload
          - name: REQ_METHOD
            value: POST
          image: quay.io/kiwigrid/k8s-sidecar:1.28.0
          imagePullPolicy: IfNotPresent
          name: grafana-sc-dashboard
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /tmp/dashboards
            name: sc-dashboard-volume
        - env:
          - name: METHOD
            value: WATCH
          - name: LABEL
            value: grafana_datasource
          - name: FOLDER
            value: /etc/grafana/provisioning/datasources
          - name: RESOURCE
            value: both
          - name: REQ_USERNAME
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: monitoring-grafana
          - name: REQ_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: monitoring-grafana
          - name: REQ_URL
            value: http://localhost:3000/api/admin/provisioning/datasources/reload
          - name: REQ_METHOD
            value: POST
          image: quay.io/kiwigrid/k8s-sidecar:1.28.0
          imagePullPolicy: IfNotPresent
          name: grafana-sc-datasources
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/grafana/provisioning/datasources
            name: sc-datasources-volume
        - env:
          - name: POD_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.podIP
          - name: GF_SECURITY_ADMIN_USER
            valueFrom:
              secretKeyRef:
                key: admin-user
                name: monitoring-grafana
          - name: GF_SECURITY_ADMIN_PASSWORD
            valueFrom:
              secretKeyRef:
                key: admin-password
                name: monitoring-grafana
          - name: GF_PATHS_DATA
            value: /var/lib/grafana/
          - name: GF_PATHS_LOGS
            value: /var/log/grafana
          - name: GF_PATHS_PLUGINS
            value: /var/lib/grafana/plugins
          - name: GF_PATHS_PROVISIONING
            value: /etc/grafana/provisioning
          image: docker.io/grafana/grafana:11.2.2-security-01
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 10
            httpGet:
              path: /api/health
              port: 3000
              scheme: HTTP
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 30
          name: grafana
          ports:
          - containerPort: 3000
            name: grafana
            protocol: TCP
          - containerPort: 9094
            name: gossip-tcp
            protocol: TCP
          - containerPort: 9094
            name: gossip-udp
            protocol: UDP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /api/health
              port: 3000
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/grafana/grafana.ini
            name: config
            subPath: grafana.ini
          - mountPath: /var/lib/grafana
            name: storage
          - mountPath: /tmp/dashboards
            name: sc-dashboard-volume
          - mountPath: /etc/grafana/provisioning/dashboards/sc-dashboardproviders.yaml
            name: sc-dashboard-provider
            subPath: provider.yaml
          - mountPath: /etc/grafana/provisioning/datasources
            name: sc-datasources-volume
        dnsPolicy: ClusterFirst
        enableServiceLinks: true
        initContainers:
        - command:
          - chown
          - -R
          - 472:472
          - /var/lib/grafana
          image: docker.io/library/busybox:1.31.1
          imagePullPolicy: IfNotPresent
          name: init-chown-data
          resources: {}
          securityContext:
            capabilities:
              add:
              - CHOWN
            runAsNonRoot: false
            runAsUser: 0
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /var/lib/grafana
            name: storage
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 472
          runAsGroup: 472
          runAsNonRoot: true
          runAsUser: 472
        serviceAccount: monitoring-grafana
        serviceAccountName: monitoring-grafana
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: monitoring-grafana
          name: config
        - name: storage
          persistentVolumeClaim:
            claimName: monitoring-grafana
        - emptyDir: {}
          name: sc-dashboard-volume
        - configMap:
            defaultMode: 420
            name: monitoring-grafana-config-dashboards
          name: sc-dashboard-provider
        - emptyDir: {}
          name: sc-datasources-volume
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-10-21T12:53:19Z"
    generation: 1
    labels:
      app.kubernetes.io/component: metrics
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kube-state-metrics
      app.kubernetes.io/part-of: kube-state-metrics
      app.kubernetes.io/version: 2.13.0
      helm.sh/chart: kube-state-metrics-5.25.1
      pod-template-hash: 74cdb59bff
    name: prometheus-kube-state-metrics-74cdb59bff
    namespace: monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: prometheus-kube-state-metrics
      uid: 5cef9e05-52ad-409e-9176-ea99cdfa6cd1
    resourceVersion: "22856127"
    uid: e4212076-aa08-43c4-9515-f7f9fde6f6b0
  spec:
    replicas: 1
    selector:
      matchLabels:
        app.kubernetes.io/instance: prometheus
        app.kubernetes.io/name: kube-state-metrics
        pod-template-hash: 74cdb59bff
    template:
      metadata:
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: metrics
          app.kubernetes.io/instance: prometheus
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: kube-state-metrics
          app.kubernetes.io/part-of: kube-state-metrics
          app.kubernetes.io/version: 2.13.0
          helm.sh/chart: kube-state-metrics-5.25.1
          pod-template-hash: 74cdb59bff
      spec:
        automountServiceAccountToken: true
        containers:
        - args:
          - --port=8080
          - --resources=certificatesigningrequests,configmaps,cronjobs,daemonsets,deployments,endpoints,horizontalpodautoscalers,ingresses,jobs,leases,limitranges,mutatingwebhookconfigurations,namespaces,networkpolicies,nodes,persistentvolumeclaims,persistentvolumes,poddisruptionbudgets,pods,replicasets,replicationcontrollers,resourcequotas,secrets,services,statefulsets,storageclasses,validatingwebhookconfigurations,volumeattachments
          image: registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.13.0
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /livez
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          name: kube-state-metrics
          ports:
          - containerPort: 8080
            name: http
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /readyz
              port: 8080
              scheme: HTTP
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          runAsGroup: 65534
          runAsNonRoot: true
          runAsUser: 65534
          seccompProfile:
            type: RuntimeDefault
        serviceAccount: prometheus-kube-state-metrics
        serviceAccountName: prometheus-kube-state-metrics
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "1"
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-10-21T12:53:19Z"
    generation: 1
    labels:
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: prometheus-pushgateway
      app.kubernetes.io/version: v1.9.0
      helm.sh/chart: prometheus-pushgateway-2.14.0
      pod-template-hash: 66fc55f8d
    name: prometheus-prometheus-pushgateway-66fc55f8d
    namespace: monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: prometheus-prometheus-pushgateway
      uid: e50843ed-3937-435b-9fe4-c1e595a3dac6
    resourceVersion: "17859272"
    uid: 430663db-2554-483d-810c-1f65e1908fd0
  spec:
    replicas: 1
    selector:
      matchLabels:
        app.kubernetes.io/instance: prometheus
        app.kubernetes.io/name: prometheus-pushgateway
        pod-template-hash: 66fc55f8d
    template:
      metadata:
        creationTimestamp: null
        labels:
          app.kubernetes.io/instance: prometheus
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: prometheus-pushgateway
          app.kubernetes.io/version: v1.9.0
          helm.sh/chart: prometheus-pushgateway-2.14.0
          pod-template-hash: 66fc55f8d
      spec:
        automountServiceAccountToken: true
        containers:
        - image: quay.io/prometheus/pushgateway:v1.9.0
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /-/healthy
              port: 9091
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 10
          name: pushgateway
          ports:
          - containerPort: 9091
            name: metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /-/ready
              port: 9091
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 10
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /data
            name: storage-volume
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          runAsNonRoot: true
          runAsUser: 65534
        serviceAccount: prometheus-prometheus-pushgateway
        serviceAccountName: prometheus-prometheus-pushgateway
        terminationGracePeriodSeconds: 30
        volumes:
        - emptyDir: {}
          name: storage-volume
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "1"
      deployment.kubernetes.io/revision: "1"
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-10-21T12:53:19Z"
    generation: 1
    labels:
      app.kubernetes.io/component: server
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: prometheus
      app.kubernetes.io/part-of: prometheus
      app.kubernetes.io/version: v2.54.1
      helm.sh/chart: prometheus-25.27.0
      pod-template-hash: dd484f8d9
    name: prometheus-server-dd484f8d9
    namespace: monitoring
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: prometheus-server
      uid: af0e1c6e-0b6a-4a92-8c07-bf782b5326a2
    resourceVersion: "17859379"
    uid: f910c7f0-e328-4e55-bc71-0898c1cf528a
  spec:
    replicas: 1
    selector:
      matchLabels:
        app.kubernetes.io/component: server
        app.kubernetes.io/instance: prometheus
        app.kubernetes.io/name: prometheus
        pod-template-hash: dd484f8d9
    template:
      metadata:
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: server
          app.kubernetes.io/instance: prometheus
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: prometheus
          app.kubernetes.io/part-of: prometheus
          app.kubernetes.io/version: v2.54.1
          helm.sh/chart: prometheus-25.27.0
          pod-template-hash: dd484f8d9
      spec:
        containers:
        - args:
          - --watched-dir=/etc/config
          - --listen-address=0.0.0.0:8080
          - --reload-url=http://127.0.0.1:9090/-/reload
          image: quay.io/prometheus-operator/prometheus-config-reloader:v0.76.0
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: metrics
              scheme: HTTP
            initialDelaySeconds: 2
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: prometheus-server-configmap-reload
          ports:
          - containerPort: 8080
            name: metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: metrics
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/config
            name: config-volume
            readOnly: true
        - args:
          - --storage.tsdb.retention.time=15d
          - --config.file=/etc/config/prometheus.yml
          - --storage.tsdb.path=/data
          - --web.console.libraries=/etc/prometheus/console_libraries
          - --web.console.templates=/etc/prometheus/consoles
          - --web.enable-lifecycle
          image: quay.io/prometheus/prometheus:v2.54.1
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /-/healthy
              port: 9090
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 15
            successThreshold: 1
            timeoutSeconds: 10
          name: prometheus-server
          ports:
          - containerPort: 9090
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /-/ready
              port: 9090
              scheme: HTTP
            initialDelaySeconds: 30
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 4
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/config
            name: config-volume
          - mountPath: /data
            name: storage-volume
        dnsPolicy: ClusterFirst
        enableServiceLinks: true
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          runAsGroup: 65534
          runAsNonRoot: true
          runAsUser: 65534
        serviceAccount: prometheus-server
        serviceAccountName: prometheus-server
        terminationGracePeriodSeconds: 300
        volumes:
        - configMap:
            defaultMode: 420
            name: prometheus-server
          name: config-volume
        - name: storage-volume
          persistentVolumeClaim:
            claimName: prometheus-server
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2024-08-16T13:06:18Z"
    generation: 1
    labels:
      app: front-app
      pod-template-hash: 569d9cf59b
    name: zicdding-front-app-569d9cf59b
    namespace: zicdding
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: Deployment
      name: zicdding-front-app
      uid: 77fa48ab-082f-4631-b013-c6902753e2a3
    resourceVersion: "17859163"
    uid: cf8b56b4-290d-4ed3-9387-49ad74b9ecce
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: front-app
        pod-template-hash: 569d9cf59b
    template:
      metadata:
        creationTimestamp: null
        labels:
          app: front-app
          pod-template-hash: 569d9cf59b
      spec:
        containers:
        - image: zicdding0904/zicdding-front:0.0.1
          imagePullPolicy: IfNotPresent
          name: zicdding-front-app
          ports:
          - containerPort: 3000
            protocol: TCP
          resources: {}
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        terminationGracePeriodSeconds: 30
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
- apiVersion: apps/v1
  kind: StatefulSet
  metadata:
    annotations:
      meta.helm.sh/release-name: argocd
      meta.helm.sh/release-namespace: argocd
    creationTimestamp: "2024-07-19T17:25:51Z"
    generation: 1
    labels:
      app.kubernetes.io/component: application-controller
      app.kubernetes.io/instance: argocd
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: argocd-application-controller
      app.kubernetes.io/part-of: argocd
      app.kubernetes.io/version: v2.11.5
      helm.sh/chart: argo-cd-7.3.9
    name: argocd-application-controller
    namespace: argocd
    resourceVersion: "17859228"
    uid: c144e4db-249f-4ac8-a0e9-112d85b17cc3
  spec:
    persistentVolumeClaimRetentionPolicy:
      whenDeleted: Retain
      whenScaled: Retain
    podManagementPolicy: OrderedReady
    replicas: 1
    revisionHistoryLimit: 5
    selector:
      matchLabels:
        app.kubernetes.io/instance: argocd
        app.kubernetes.io/name: argocd-application-controller
    serviceName: argocd-application-controller
    template:
      metadata:
        annotations:
          checksum/cm: 9156c689cecc9c1147df3672959659693b08b4c335adc717836ea9bc0cc75160
          checksum/cmd-params: bcbb2496303699a508a41b49a033d6f92d273aba139ec132105f461a1d84fa46
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: application-controller
          app.kubernetes.io/instance: argocd
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: argocd-application-controller
          app.kubernetes.io/part-of: argocd
          app.kubernetes.io/version: v2.11.5
          helm.sh/chart: argo-cd-7.3.9
      spec:
        affinity:
          podAntiAffinity:
            preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: argocd-application-controller
                topologyKey: kubernetes.io/hostname
              weight: 100
        automountServiceAccountToken: true
        containers:
        - args:
          - /usr/local/bin/argocd-application-controller
          - --metrics-port=8082
          env:
          - name: ARGOCD_CONTROLLER_REPLICAS
            value: "1"
          - name: ARGOCD_APPLICATION_CONTROLLER_NAME
            value: argocd-application-controller
          - name: ARGOCD_RECONCILIATION_TIMEOUT
            valueFrom:
              configMapKeyRef:
                key: timeout.reconciliation
                name: argocd-cm
                optional: true
          - name: ARGOCD_HARD_RECONCILIATION_TIMEOUT
            valueFrom:
              configMapKeyRef:
                key: timeout.hard.reconciliation
                name: argocd-cm
                optional: true
          - name: ARGOCD_RECONCILIATION_JITTER
            valueFrom:
              configMapKeyRef:
                key: timeout.reconciliation.jitter
                name: argocd-cm
                optional: true
          - name: ARGOCD_REPO_ERROR_GRACE_PERIOD_SECONDS
            valueFrom:
              configMapKeyRef:
                key: controller.repo.error.grace.period.seconds
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER
            valueFrom:
              configMapKeyRef:
                key: repo.server
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_TIMEOUT_SECONDS
            valueFrom:
              configMapKeyRef:
                key: controller.repo.server.timeout.seconds
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATION_CONTROLLER_STATUS_PROCESSORS
            valueFrom:
              configMapKeyRef:
                key: controller.status.processors
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATION_CONTROLLER_OPERATION_PROCESSORS
            valueFrom:
              configMapKeyRef:
                key: controller.operation.processors
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATION_CONTROLLER_LOGFORMAT
            valueFrom:
              configMapKeyRef:
                key: controller.log.format
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATION_CONTROLLER_LOGLEVEL
            valueFrom:
              configMapKeyRef:
                key: controller.log.level
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATION_CONTROLLER_METRICS_CACHE_EXPIRATION
            valueFrom:
              configMapKeyRef:
                key: controller.metrics.cache.expiration
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATION_CONTROLLER_SELF_HEAL_TIMEOUT_SECONDS
            valueFrom:
              configMapKeyRef:
                key: controller.self.heal.timeout.seconds
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_PLAINTEXT
            valueFrom:
              configMapKeyRef:
                key: controller.repo.server.plaintext
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATION_CONTROLLER_REPO_SERVER_STRICT_TLS
            valueFrom:
              configMapKeyRef:
                key: controller.repo.server.strict.tls
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATION_CONTROLLER_PERSIST_RESOURCE_HEALTH
            valueFrom:
              configMapKeyRef:
                key: controller.resource.health.persist
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APP_STATE_CACHE_EXPIRATION
            valueFrom:
              configMapKeyRef:
                key: controller.app.state.cache.expiration
                name: argocd-cmd-params-cm
                optional: true
          - name: REDIS_SERVER
            valueFrom:
              configMapKeyRef:
                key: redis.server
                name: argocd-cmd-params-cm
                optional: true
          - name: REDIS_COMPRESSION
            valueFrom:
              configMapKeyRef:
                key: redis.compression
                name: argocd-cmd-params-cm
                optional: true
          - name: REDISDB
            valueFrom:
              configMapKeyRef:
                key: redis.db
                name: argocd-cmd-params-cm
                optional: true
          - name: REDIS_USERNAME
            valueFrom:
              secretKeyRef:
                key: redis-username
                name: argocd-redis
                optional: true
          - name: REDIS_PASSWORD
            valueFrom:
              secretKeyRef:
                key: auth
                name: argocd-redis
                optional: true
          - name: REDIS_SENTINEL_USERNAME
            valueFrom:
              secretKeyRef:
                key: redis-sentinel-username
                name: argocd-redis
                optional: true
          - name: REDIS_SENTINEL_PASSWORD
            valueFrom:
              secretKeyRef:
                key: redis-sentinel-password
                name: argocd-redis
                optional: true
          - name: ARGOCD_DEFAULT_CACHE_EXPIRATION
            valueFrom:
              configMapKeyRef:
                key: controller.default.cache.expiration
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_ADDRESS
            valueFrom:
              configMapKeyRef:
                key: otlp.address
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_INSECURE
            valueFrom:
              configMapKeyRef:
                key: otlp.insecure
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATION_CONTROLLER_OTLP_HEADERS
            valueFrom:
              configMapKeyRef:
                key: otlp.headers
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATION_NAMESPACES
            valueFrom:
              configMapKeyRef:
                key: application.namespaces
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_CONTROLLER_SHARDING_ALGORITHM
            valueFrom:
              configMapKeyRef:
                key: controller.sharding.algorithm
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATION_CONTROLLER_KUBECTL_PARALLELISM_LIMIT
            valueFrom:
              configMapKeyRef:
                key: controller.kubectl.parallelism.limit
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_K8SCLIENT_RETRY_MAX
            valueFrom:
              configMapKeyRef:
                key: controller.k8sclient.retry.max
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_K8SCLIENT_RETRY_BASE_BACKOFF
            valueFrom:
              configMapKeyRef:
                key: controller.k8sclient.retry.base.backoff
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_APPLICATION_CONTROLLER_SERVER_SIDE_DIFF
            valueFrom:
              configMapKeyRef:
                key: controller.diff.server.side
                name: argocd-cmd-params-cm
                optional: true
          - name: ARGOCD_IGNORE_NORMALIZER_JQ_TIMEOUT
            valueFrom:
              configMapKeyRef:
                key: controller.ignore.normalizer.jq.timeout
                name: argocd-cmd-params-cm
                optional: true
          image: quay.io/argoproj/argocd:v2.11.5
          imagePullPolicy: IfNotPresent
          name: application-controller
          ports:
          - containerPort: 8082
            name: metrics
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: metrics
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /app/config/controller/tls
            name: argocd-repo-server-tls
          - mountPath: /home/argocd
            name: argocd-home
          workingDir: /home/argocd
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: argocd-application-controller
        serviceAccountName: argocd-application-controller
        terminationGracePeriodSeconds: 30
        volumes:
        - emptyDir: {}
          name: argocd-home
        - name: argocd-repo-server-tls
          secret:
            defaultMode: 420
            items:
            - key: tls.crt
              path: tls.crt
            - key: tls.key
              path: tls.key
            - key: ca.crt
              path: ca.crt
            optional: true
            secretName: argocd-repo-server-tls
    updateStrategy:
      rollingUpdate:
        partition: 0
      type: RollingUpdate
  status:
    availableReplicas: 1
    collisionCount: 0
    currentReplicas: 1
    currentRevision: argocd-application-controller-5f449f6b88
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updateRevision: argocd-application-controller-5f449f6b88
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: StatefulSet
  metadata:
    annotations:
      meta.helm.sh/release-name: loki
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-10-21T12:56:07Z"
    generation: 3
    labels:
      app: loki
      app.kubernetes.io/managed-by: Helm
      chart: loki-2.16.0
      heritage: Helm
      release: loki
    name: loki
    namespace: monitoring
    resourceVersion: "17859491"
    uid: 4001f9e0-3e7a-4c2d-8314-9330e444634a
  spec:
    persistentVolumeClaimRetentionPolicy:
      whenDeleted: Retain
      whenScaled: Retain
    podManagementPolicy: OrderedReady
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app: loki
        release: loki
    serviceName: loki-headless
    template:
      metadata:
        annotations:
          checksum/config: 8543d68a9795066423a4ce0ff28f2c56950acfa1bac20e850c016a4fd91a9300
          kubectl.kubernetes.io/restartedAt: "2024-11-04T12:52:04+09:00"
          prometheus.io/port: http-metrics
          prometheus.io/scrape: "true"
        creationTimestamp: null
        labels:
          app: loki
          name: loki
          release: loki
      spec:
        affinity: {}
        containers:
        - args:
          - -config.file=/etc/loki/loki.yaml
          image: grafana/loki:2.9.3
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /ready
              port: http-metrics
              scheme: HTTP
            initialDelaySeconds: 45
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: loki
          ports:
          - containerPort: 3100
            name: http-metrics
            protocol: TCP
          - containerPort: 9095
            name: grpc
            protocol: TCP
          - containerPort: 7946
            name: memberlist-port
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /ready
              port: http-metrics
              scheme: HTTP
            initialDelaySeconds: 45
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            readOnlyRootFilesystem: true
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /tmp
            name: tmp
          - mountPath: /etc/loki
            name: config
          - mountPath: /data
            name: storage
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 10001
          runAsGroup: 10001
          runAsNonRoot: true
          runAsUser: 10001
        serviceAccount: loki
        serviceAccountName: loki
        terminationGracePeriodSeconds: 4800
        volumes:
        - emptyDir: {}
          name: tmp
        - name: config
          secret:
            defaultMode: 420
            secretName: loki
        - emptyDir: {}
          name: storage
    updateStrategy:
      type: RollingUpdate
  status:
    availableReplicas: 1
    collisionCount: 0
    currentReplicas: 1
    currentRevision: loki-55dbb5b75c
    observedGeneration: 3
    readyReplicas: 1
    replicas: 1
    updateRevision: loki-55dbb5b75c
    updatedReplicas: 1
- apiVersion: apps/v1
  kind: StatefulSet
  metadata:
    annotations:
      meta.helm.sh/release-name: prometheus
      meta.helm.sh/release-namespace: monitoring
    creationTimestamp: "2024-10-21T12:53:19Z"
    generation: 1
    labels:
      app.kubernetes.io/instance: prometheus
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: alertmanager
      app.kubernetes.io/version: v0.27.0
      helm.sh/chart: alertmanager-1.12.0
    name: prometheus-alertmanager
    namespace: monitoring
    resourceVersion: "17859200"
    uid: 07a73890-ac41-4b44-9865-d76da15082c4
  spec:
    persistentVolumeClaimRetentionPolicy:
      whenDeleted: Retain
      whenScaled: Retain
    podManagementPolicy: OrderedReady
    replicas: 1
    revisionHistoryLimit: 10
    selector:
      matchLabels:
        app.kubernetes.io/instance: prometheus
        app.kubernetes.io/name: alertmanager
    serviceName: prometheus-alertmanager-headless
    template:
      metadata:
        annotations:
          checksum/config: 195883ecd2ee641260040a4479e9ef202bcac4f1146b5f55dcae7155de43bcc8
        creationTimestamp: null
        labels:
          app.kubernetes.io/instance: prometheus
          app.kubernetes.io/name: alertmanager
      spec:
        automountServiceAccountToken: true
        containers:
        - args:
          - --storage.path=/alertmanager
          - --config.file=/etc/alertmanager/alertmanager.yml
          env:
          - name: POD_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.podIP
          image: quay.io/prometheus/alertmanager:v0.27.0
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: http
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          name: alertmanager
          ports:
          - containerPort: 9093
            name: http
            protocol: TCP
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /
              port: http
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          resources: {}
          securityContext:
            runAsGroup: 65534
            runAsNonRoot: true
            runAsUser: 65534
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
          volumeMounts:
          - mountPath: /etc/alertmanager
            name: config
          - mountPath: /alertmanager
            name: storage
        dnsPolicy: ClusterFirst
        restartPolicy: Always
        schedulerName: default-scheduler
        securityContext:
          fsGroup: 65534
          runAsGroup: 65534
          runAsNonRoot: true
          runAsUser: 65534
        serviceAccount: prometheus-alertmanager
        serviceAccountName: prometheus-alertmanager
        terminationGracePeriodSeconds: 30
        volumes:
        - configMap:
            defaultMode: 420
            name: prometheus-alertmanager
          name: config
    updateStrategy:
      rollingUpdate:
        partition: 0
      type: RollingUpdate
    volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        creationTimestamp: null
        name: storage
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 2Gi
        volumeMode: Filesystem
      status:
        phase: Pending
  status:
    availableReplicas: 1
    collisionCount: 0
    currentReplicas: 1
    currentRevision: prometheus-alertmanager-fcbc844b6
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
    updateRevision: prometheus-alertmanager-fcbc844b6
    updatedReplicas: 1
- apiVersion: batch/v1
  kind: Job
  metadata:
    annotations:
      helm.sh/hook: pre-install,pre-upgrade
      helm.sh/hook-delete-policy: before-hook-creation
    creationTimestamp: "2024-07-19T17:25:47Z"
    generation: 1
    labels:
      app.kubernetes.io/component: redis-secret-init
      app.kubernetes.io/instance: argocd
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: argocd-redis-secret-init
      app.kubernetes.io/part-of: argocd
      app.kubernetes.io/version: v2.11.5
      helm.sh/chart: argo-cd-7.3.9
    name: argocd-redis-secret-init
    namespace: argocd
    resourceVersion: "721782"
    uid: b9e5519c-6ef0-4988-9fd9-517301a7d897
  spec:
    backoffLimit: 6
    completionMode: NonIndexed
    completions: 1
    manualSelector: false
    parallelism: 1
    podReplacementPolicy: TerminatingOrFailed
    selector:
      matchLabels:
        batch.kubernetes.io/controller-uid: b9e5519c-6ef0-4988-9fd9-517301a7d897
    suspend: false
    template:
      metadata:
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: redis-secret-init
          app.kubernetes.io/instance: argocd
          app.kubernetes.io/managed-by: Helm
          app.kubernetes.io/name: argocd-redis-secret-init
          app.kubernetes.io/part-of: argocd
          app.kubernetes.io/version: v2.11.5
          batch.kubernetes.io/controller-uid: b9e5519c-6ef0-4988-9fd9-517301a7d897
          batch.kubernetes.io/job-name: argocd-redis-secret-init
          controller-uid: b9e5519c-6ef0-4988-9fd9-517301a7d897
          helm.sh/chart: argo-cd-7.3.9
          job-name: argocd-redis-secret-init
      spec:
        containers:
        - command:
          - argocd
          - admin
          - redis-initial-password
          image: quay.io/argoproj/argocd:v2.11.5
          imagePullPolicy: IfNotPresent
          name: secret-init
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            seccompProfile:
              type: RuntimeDefault
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        restartPolicy: OnFailure
        schedulerName: default-scheduler
        securityContext: {}
        serviceAccount: argocd-redis-secret-init
        serviceAccountName: argocd-redis-secret-init
        terminationGracePeriodSeconds: 30
  status:
    completionTime: "2024-07-19T17:25:50Z"
    conditions:
    - lastProbeTime: "2024-07-19T17:25:50Z"
      lastTransitionTime: "2024-07-19T17:25:50Z"
      status: "True"
      type: Complete
    ready: 0
    startTime: "2024-07-19T17:25:47Z"
    succeeded: 1
    terminating: 0
    uncountedTerminatedPods: {}
- apiVersion: batch/v1
  kind: Job
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"batch/v1","kind":"Job","metadata":{"annotations":{},"labels":{"app.kubernetes.io/component":"admission-webhook","app.kubernetes.io/instance":"ingress-nginx","app.kubernetes.io/name":"ingress-nginx"},"name":"ingress-nginx-admission-create","namespace":"ingress-nginx"},"spec":{"template":{"metadata":{"labels":{"app.kubernetes.io/component":"admission-webhook","app.kubernetes.io/instance":"ingress-nginx","app.kubernetes.io/name":"ingress-nginx"},"name":"ingress-nginx-admission-create"},"spec":{"containers":[{"args":["create","--host=ingress-nginx-controller-admission,ingress-nginx-controller-admission.$(POD_NAMESPACE).svc","--namespace=$(POD_NAMESPACE)","--secret-name=ingress-nginx-admission"],"env":[{"name":"POD_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}}],"image":"registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.4.1@sha256:36d05b4077fb8e3d13663702fa337f124675ba8667cbd949c03a8e8ea6fa4366","imagePullPolicy":"IfNotPresent","name":"create","securityContext":{"allowPrivilegeEscalation":false}}],"nodeSelector":{"kubernetes.io/os":"linux","minikube.k8s.io/primary":"true"},"restartPolicy":"OnFailure","securityContext":{"runAsNonRoot":true,"runAsUser":2000},"serviceAccountName":"ingress-nginx-admission"}}}}
    creationTimestamp: "2024-08-03T05:16:32Z"
    generation: 1
    labels:
      app.kubernetes.io/component: admission-webhook
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/name: ingress-nginx
    name: ingress-nginx-admission-create
    namespace: ingress-nginx
    resourceVersion: "1865402"
    uid: 348142fc-f5a7-42fb-a4e3-9ff3eb4c1647
  spec:
    backoffLimit: 6
    completionMode: NonIndexed
    completions: 1
    manualSelector: false
    parallelism: 1
    podReplacementPolicy: TerminatingOrFailed
    selector:
      matchLabels:
        batch.kubernetes.io/controller-uid: 348142fc-f5a7-42fb-a4e3-9ff3eb4c1647
    suspend: false
    template:
      metadata:
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: admission-webhook
          app.kubernetes.io/instance: ingress-nginx
          app.kubernetes.io/name: ingress-nginx
          batch.kubernetes.io/controller-uid: 348142fc-f5a7-42fb-a4e3-9ff3eb4c1647
          batch.kubernetes.io/job-name: ingress-nginx-admission-create
          controller-uid: 348142fc-f5a7-42fb-a4e3-9ff3eb4c1647
          job-name: ingress-nginx-admission-create
        name: ingress-nginx-admission-create
      spec:
        containers:
        - args:
          - create
          - --host=ingress-nginx-controller-admission,ingress-nginx-controller-admission.$(POD_NAMESPACE).svc
          - --namespace=$(POD_NAMESPACE)
          - --secret-name=ingress-nginx-admission
          env:
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.4.1@sha256:36d05b4077fb8e3d13663702fa337f124675ba8667cbd949c03a8e8ea6fa4366
          imagePullPolicy: IfNotPresent
          name: create
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
          minikube.k8s.io/primary: "true"
        restartPolicy: OnFailure
        schedulerName: default-scheduler
        securityContext:
          runAsNonRoot: true
          runAsUser: 2000
        serviceAccount: ingress-nginx-admission
        serviceAccountName: ingress-nginx-admission
        terminationGracePeriodSeconds: 30
  status:
    completionTime: "2024-08-03T05:16:36Z"
    conditions:
    - lastProbeTime: "2024-08-03T05:16:36Z"
      lastTransitionTime: "2024-08-03T05:16:36Z"
      status: "True"
      type: Complete
    ready: 0
    startTime: "2024-08-03T05:16:32Z"
    succeeded: 1
    terminating: 0
    uncountedTerminatedPods: {}
- apiVersion: batch/v1
  kind: Job
  metadata:
    annotations:
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"batch/v1","kind":"Job","metadata":{"annotations":{},"labels":{"app.kubernetes.io/component":"admission-webhook","app.kubernetes.io/instance":"ingress-nginx","app.kubernetes.io/name":"ingress-nginx"},"name":"ingress-nginx-admission-patch","namespace":"ingress-nginx"},"spec":{"template":{"metadata":{"labels":{"app.kubernetes.io/component":"admission-webhook","app.kubernetes.io/instance":"ingress-nginx","app.kubernetes.io/name":"ingress-nginx"},"name":"ingress-nginx-admission-patch"},"spec":{"containers":[{"args":["patch","--webhook-name=ingress-nginx-admission","--namespace=$(POD_NAMESPACE)","--patch-mutating=false","--secret-name=ingress-nginx-admission","--patch-failure-policy=Fail"],"env":[{"name":"POD_NAMESPACE","valueFrom":{"fieldRef":{"fieldPath":"metadata.namespace"}}}],"image":"registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.4.1@sha256:36d05b4077fb8e3d13663702fa337f124675ba8667cbd949c03a8e8ea6fa4366","imagePullPolicy":"IfNotPresent","name":"patch","securityContext":{"allowPrivilegeEscalation":false}}],"nodeSelector":{"kubernetes.io/os":"linux","minikube.k8s.io/primary":"true"},"restartPolicy":"OnFailure","securityContext":{"runAsNonRoot":true,"runAsUser":2000},"serviceAccountName":"ingress-nginx-admission"}}}}
    creationTimestamp: "2024-08-03T05:16:32Z"
    generation: 1
    labels:
      app.kubernetes.io/component: admission-webhook
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/name: ingress-nginx
    name: ingress-nginx-admission-patch
    namespace: ingress-nginx
    resourceVersion: "1865409"
    uid: c1abac12-b362-44f2-ba9d-e12ff629ccc9
  spec:
    backoffLimit: 6
    completionMode: NonIndexed
    completions: 1
    manualSelector: false
    parallelism: 1
    podReplacementPolicy: TerminatingOrFailed
    selector:
      matchLabels:
        batch.kubernetes.io/controller-uid: c1abac12-b362-44f2-ba9d-e12ff629ccc9
    suspend: false
    template:
      metadata:
        creationTimestamp: null
        labels:
          app.kubernetes.io/component: admission-webhook
          app.kubernetes.io/instance: ingress-nginx
          app.kubernetes.io/name: ingress-nginx
          batch.kubernetes.io/controller-uid: c1abac12-b362-44f2-ba9d-e12ff629ccc9
          batch.kubernetes.io/job-name: ingress-nginx-admission-patch
          controller-uid: c1abac12-b362-44f2-ba9d-e12ff629ccc9
          job-name: ingress-nginx-admission-patch
        name: ingress-nginx-admission-patch
      spec:
        containers:
        - args:
          - patch
          - --webhook-name=ingress-nginx-admission
          - --namespace=$(POD_NAMESPACE)
          - --patch-mutating=false
          - --secret-name=ingress-nginx-admission
          - --patch-failure-policy=Fail
          env:
          - name: POD_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          image: registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.4.1@sha256:36d05b4077fb8e3d13663702fa337f124675ba8667cbd949c03a8e8ea6fa4366
          imagePullPolicy: IfNotPresent
          name: patch
          resources: {}
          securityContext:
            allowPrivilegeEscalation: false
          terminationMessagePath: /dev/termination-log
          terminationMessagePolicy: File
        dnsPolicy: ClusterFirst
        nodeSelector:
          kubernetes.io/os: linux
          minikube.k8s.io/primary: "true"
        restartPolicy: OnFailure
        schedulerName: default-scheduler
        securityContext:
          runAsNonRoot: true
          runAsUser: 2000
        serviceAccount: ingress-nginx-admission
        serviceAccountName: ingress-nginx-admission
        terminationGracePeriodSeconds: 30
  status:
    completionTime: "2024-08-03T05:16:37Z"
    conditions:
    - lastProbeTime: "2024-08-03T05:16:37Z"
      lastTransitionTime: "2024-08-03T05:16:37Z"
      status: "True"
      type: Complete
    ready: 0
    startTime: "2024-08-03T05:16:32Z"
    succeeded: 1
    terminating: 0
    uncountedTerminatedPods: {}
kind: List
metadata:
  resourceVersion: ""
